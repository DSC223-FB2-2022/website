[
  {
    "objectID": "ae/ae-01a-un-votes/unvotes.html",
    "href": "ae/ae-01a-un-votes/unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes <- un_votes %>%\n  inner_join(un_roll_calls, by = \"rcid\") %>%\n  inner_join(un_roll_call_issues, by = \"rcid\")"
  },
  {
    "objectID": "ae/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "href": "ae/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualisation that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes %>%\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) %>%\n  mutate(year = year(date)) %>%\n  group_by(country, year, issue) %>%\n  summarize(percent_yes = mean(vote == \"yes\")) %>%\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "ae/ae-01a-un-votes/unvotes.html#references",
    "href": "ae/ae-01a-un-votes/unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nDavid Robinson (2017). unvotes: United Nations General Assembly Voting Data. R package version 0.2.0.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-01a-un-votes/unvotes.html#appendix",
    "href": "ae/ae-01a-un-votes/unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "ae/ae-01b-covid/covid.html",
    "href": "ae/ae-01b-covid/covid.html",
    "title": "Cumulative deaths from COVID-19",
    "section": "",
    "text": "Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries.\nThe data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily.\nFor our analysis, in addition to the coronavirus package, we will use the following packages for data wrangling and visualisation.\n\ntidyverse for data wrangling and visualization\nlubridate package for handling dates\nglue package for constructing text strings\nscales package for formatting axis labels\nggrepel package for pretty printing of country labels\n\nWe will make use of the DT package for interactive display of tabular output in the Appendix.\n\nlibrary(coronavirus) # devtools::install_github(\"RamiKrispin/coronavirus\")\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(DT)"
  },
  {
    "objectID": "ae/ae-01b-covid/covid.html#data-prep",
    "href": "ae/ae-01b-covid/covid.html#data-prep",
    "title": "Cumulative deaths from COVID-19",
    "section": "Data prep",
    "text": "Data prep\nThe data frame called coronavirus in the coronavirus package provides a daily summary of the Coronavirus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). A full list of the countries in the data frame is provided in the Appendix. Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. For this report, we will focus on the deaths.\nWe will start by making our selection for the countries we want to explore.\n\ncountries <- c(\n  \"China\",\n  \"France\",\n  \"United Kingdom\",\n  \"US\",\n  \"Turkey\"\n)\n\nIn the following code chunk we filter the data frame for deaths in the countries we specified above and calculate cumulative number of deaths. We will only visualise data since 10th confirmed death.\n\ncountry_data <- coronavirus %>%\n  # filter for deaths in countries of interest\n  filter(\n    type == \"death\",\n    country %in% countries\n  ) %>%\n  # fix county labels for pretty plotting\n  mutate(\n    country = case_when(\n      country == \"United Kingdom\" ~ \"UK\",\n      TRUE ~ country\n    )\n  ) %>%\n  # calculate number of total cases for each country and date\n  group_by(country, date) %>%\n  summarise(tot_cases = sum(cases)) %>%\n  # arrange by date in ascending order\n  arrange(date) %>%\n  # record daily cumulative cases as cumulative_cases\n  mutate(cumulative_cases = cumsum(tot_cases)) %>%\n  # only use days since the 10th confirmed death\n  filter(cumulative_cases > 9) %>%\n  # record days elapsed, end date, and end label\n  mutate(\n    days_elapsed = as.numeric(date - min(date)),\n    end_date     = if_else(date == max(date), TRUE, FALSE),\n    end_label    = if_else(end_date, country, NULL)\n  ) %>%\n  # ungroup\n  ungroup()\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\nWe also need to take a note of the “as of date” for the data so that we can properly label our visualisation.\n\nas_of_date <- country_data %>% \n  summarise(max(date)) %>% \n  pull()\n\nas_of_date_formatted <- glue(\"{wday(as_of_date, label = TRUE)}, {month(as_of_date, label = TRUE)} {day(as_of_date)}, {year(as_of_date)}\")\n\nThese data are as of Thu, Jun 23, 2022."
  },
  {
    "objectID": "ae/ae-01b-covid/covid.html#visualisation",
    "href": "ae/ae-01b-covid/covid.html#visualisation",
    "title": "Cumulative deaths from COVID-19",
    "section": "Visualisation",
    "text": "Visualisation\nThe following visualisation shows the number of cumulative cases vs. days elapsed since the 10th confirmed death in each country. The time span plotted for each country varies since some countries started seeing (and reporting) deaths from COVID-19 much later than others.\n\nggplot(data = country_data,\n       mapping = aes(x = days_elapsed, \n                     y = cumulative_cases, \n                     color = country, \n                     label = end_label)) +\n  # represent cumulative cases with lines\n  geom_line(size = 0.7, alpha = 0.8) +\n  # add points to line endings\n  geom_point(data = country_data %>% filter(end_date)) +\n  # add country labels, nudged above the lines\n  geom_label_repel(nudge_y = 1, direction = \"y\", hjust = 1) + \n  # turn off legend\n  guides(color = \"none\") +\n  # use pretty colors\n  scale_color_viridis_d() +\n  # better formatting for y-axis\n  scale_y_continuous(labels = label_comma()) +\n  # use minimal theme\n  theme_minimal() +\n  # customize labels\n  labs(\n    x = \"Days since 10th confirmed death\",\n    y = \"Cumulative number of deaths\",\n    title = \"Cumulative deaths from COVID-19, selected countries\",\n    subtitle = glue(\"Data as of\", as_of_date_formatted, .sep = \" \"),\n    caption = \"Source: github.com/RamiKrispin/coronavirus\"\n  )"
  },
  {
    "objectID": "ae/ae-01b-covid/covid.html#appendix",
    "href": "ae/ae-01b-covid/covid.html#appendix",
    "title": "Cumulative deaths from COVID-19",
    "section": "Appendix",
    "text": "Appendix\nA list of countries in the coronavirus data frame is provided below."
  },
  {
    "objectID": "ae/ae-02-bechdel-rmarkdown/bechdel.html",
    "href": "ae/ae-02-bechdel-rmarkdown/bechdel.html",
    "title": "Bechdel",
    "section": "",
    "text": "In this mini analysis we work with the data used in the FiveThirtyEight story titled “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”. Your task is to fill in the blanks denoted by ___."
  },
  {
    "objectID": "ae/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "href": "ae/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "title": "Bechdel",
    "section": "Data and packages",
    "text": "Data and packages\nWe start with loading the packages we’ll use.\n\nlibrary(fivethirtyeight)\nlibrary(tidyverse)\n\nThe dataset contains information on 1794 movies released between 1970 and 2013. However we’ll focus our analysis on movies released between 1990 and 2013.\n\nbechdel90_13 <- bechdel %>% \n  filter(between(year, 1990, 2013))\n\nThere are ___ such movies.\nThe financial variables we’ll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars\ndomgross_2013: Domestic gross (US) in 2013 inflation adjusted dollars\nintgross_2013: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars\n\nAnd we’ll also use the binary and clean_test variables for grouping."
  },
  {
    "objectID": "ae/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "href": "ae/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "title": "Bechdel",
    "section": "Analysis",
    "text": "Analysis\nLet’s take a look at how median budget and gross vary by whether the movie passed the Bechdel test, which is stored in the binary variable.\n\nbechdel90_13 %>%\n  group_by(binary) %>%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 2 x 4\n  binary med_budget med_domgross med_intgross\n  <chr>       <dbl>        <dbl>        <dbl>\n1 FAIL    48385984.    57318606.    104475669\n2 PASS    31070724     45330446.     80124349\n\n\nNext, let’s take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result. This information is stored in the clean_test variable, which takes on the following values:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\n\nbechdel90_13 %>%\n  #group_by(___) %>%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 1 x 3\n  med_budget med_domgross med_intgross\n       <int>        <dbl>        <dbl>\n1   37878971     52270207     93523336\n\n\nIn order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we’ll first create a new variable called roi as the ratio of the gross to budget.\n\nbechdel90_13 <- bechdel90_13 %>%\n  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)\n\nLet’s see which movies have the highest return on investment.\n\nbechdel90_13 %>%\n  arrange(desc(roi)) %>% \n  select(title, roi, year)\n\n# A tibble: 1,615 x 3\n   title                     roi  year\n   <chr>                   <dbl> <int>\n 1 Paranormal Activity      671.  2007\n 2 The Blair Witch Project  648.  1999\n 3 El Mariachi              583.  1992\n 4 Clerks.                  258.  1994\n 5 In the Company of Men    231.  1997\n 6 Napoleon Dynamite        227.  2004\n 7 Once                     190.  2006\n 8 The Devil Inside         155.  2012\n 9 Primer                   142.  2004\n10 Fireproof                134.  2008\n# ... with 1,605 more rows\n\n\nBelow is a visualization of the return on investment by test result, however it’s difficult to see the distributions due to a few extreme observations.\n\nggplot(data = bechdel90_13, \n       mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"___\",\n    color = \"Binary Bechdel result\"\n    )\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel90_13 %>%\n  filter(roi > 400) %>%\n  select(title, budget_2013, domgross_2013, year)\n\n# A tibble: 3 x 4\n  title                   budget_2013 domgross_2013  year\n  <chr>                         <int>         <dbl> <int>\n1 Paranormal Activity          505595     121251476  2007\n2 The Blair Witch Project      839077     196538593  1999\n3 El Mariachi                   11622       3388636  1992\n\n\nZooming in on the movies with roi < ___ provides a better view of how the medians across the categories compare:\n\nggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    subtitle = \"___\", # Something about zooming in to a certain level\n    x = \"Detailed Bechdel result\",\n    y = \"Return on investment\",\n    color = \"Binary Bechdel result\"\n    ) +\n  coord_cartesian(ylim = c(0, 15))"
  },
  {
    "objectID": "ae/ae-03-starwars-dataviz/starwars.html",
    "href": "ae/ae-03-starwars-dataviz/starwars.html",
    "title": "Visualizing Starwars characters",
    "section": "",
    "text": "glimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       <chr> \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or~\n$ height     <int> 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2~\n$ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.~\n$ hair_color <chr> \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N~\n$ skin_color <chr> \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"~\n$ eye_color  <chr> \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",~\n$ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, ~\n$ sex        <chr> \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",~\n$ gender     <chr> \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini~\n$ homeworld  <chr> \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T~\n$ species    <chr> \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma~\n$ films      <list> <\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return~\n$ vehicles   <list> <\"Snowspeeder\", \"Imperial Speeder Bike\">, <>, <>, <>, \"Imp~\n$ starships  <list> <\"X-wing\", \"Imperial shuttle\">, <>, <>, \"TIE Advanced x1\",~\n\n\n\nModify the following plot to change the color of all points to \"pink\".\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"pink\")\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\nAdd labels for title, x and y axes, and size of points. Uncomment to see the effect.\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"#30509C\") +\n  labs(\n    #title = \"___\",\n    #x = \"___\", \n    #y = \"___\",\n    #___\n    )\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\nPick a single numerical variable and make a histogram of it. Select a reasonable binwidth for it.\n\n(A little bit of starter code is provided below, and the code chunk is set to not be evaluated with eval: false because the current code in there is not valid code and hence the document wouldn’t knit. Once you replace the code with valid code, set the chunk option to eval: true, or remove the eval option altogether since it’s set to true by default.)\n\nggplot(starwars, aes(___)) +\n  geom___\n\n\nPick a numerical variable and a categorical variable and make a visualization (you pick the type!) to visualization the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here…\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\n\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here…\n\nPick two numerical variables and two categorical variables and make a visualization that incorporates all of them and provide an interpretation with your answer.\n\n(This time no starter code is provided, you’re on your own!)\n\n\n\nInterpretation goes here…"
  },
  {
    "objectID": "ae/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "href": "ae/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "title": "Hotel bookings - data wrangling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)"
  },
  {
    "objectID": "ae/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "href": "ae/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "title": "Hotel bookings - data wrangling",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.\nWarm up! Take a look at an overview of the data with the skim() function.\nNote: I already gave you the answer to this exercise. You just need to knit the document and view the output. A definition of all variables is given in the Data dictionary section at the end, though you don’t need to familiarize yourself with all variables in order to work through these exercises.\n\nskim(hotels)\n\n\nData summary\n\n\nName\nhotels\n\n\nNumber of rows\n119390\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n1\n\n\nnumeric\n18\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n178\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n334\n0\n\n\ncompany\n0\n1\n1\n4\n0\n353\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nreservation_status\n0\n1\n7\n9\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\n\n\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\n\n\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\n\n\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\n\n\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\n\n\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nExercise 2.\nAre people traveling on a whim? Let’s see…\nFill in the blanks for filtering for hotel bookings where the guest is not from the US (country code \"USA\") and the lead_time is less than 1 day.\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %>%\n  filter(\n    country ____ \"USA\", \n    lead_time ____ ____\n    )\n\n\n\nExercise 3.\nHow many bookings involve at least 1 child or baby?\nIn the following chunk, replace\n\n[AT LEAST] with the logical operator for “at least” (in two places)\n[OR] with the logical operator for “or”\n\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %>%\n  filter(\n    children [AT LEAST] 1 [OR] babies [AT LEAST] 1\n    )\n\n\n\nExercise 4.\nDo you think it’s more likely to find bookings with children or babies in city hotels or resort hotels? Test your intuition. Using filter() determine the number of bookings in resort hotels that have more than 1 child or baby in the room? Then, do the same for city hotels, and compare the numbers of rows in the resulting filtered data frames.\n\n# add code here\n# pay attention to correctness and code style\n\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 5.\nCreate a frequency table of the number of adults in a booking. Display the results in descending order so the most common observation is on top. What is the most common number of adults in bookings in this dataset? Are there any surprising results?\nNote: Don’t forget to label your R chunk as well (where it says label-me-1). Your label should be short, informative, and shouldn’t include spaces. It also shouldn’t repeat a previous label, otherwise R Markdown will give you an error about repeated R chunk labels.\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 6.\nRepeat Exercise 5, once for canceled bookings (is_canceled coded as 1) and once for not canceled bookings (is_canceled coded as 0). What does this reveal about the surprising results you spotted in the previous exercise?\nNote: Don’t forget to label your R chunk as well (where it says label-me-2).\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 7.\nCalculate minimum, mean, median, and maximum average daily rate (adr) grouped by hotel type so that you can get these statistics separately for resort and city hotels. Which type of hotel is higher, on average?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 8.\nWe observe two unusual values in the summary statistics above – a negative minimum, and a very high maximum). What types of hotels are these? Locate these observations in the dataset and find out the arrival date (year and month) as well as how many people (adults, children, and babies) stayed in the room. You can investigate the data in the viewer to locate these values, but preferably you should identify them in a reproducible way with some code.\nHint: For example, you can filter for the given adr amounts and select the relevant columns.\n\n# add code here\n# pay attention to correctness and code style"
  },
  {
    "objectID": "ae/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "href": "ae/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "title": "Hotel bookings - data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the full data dictionary. Note that it is long (there are lots of variables in the data), but we will be using a limited set of the variables for our analysis.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:  Undefined/SC – no meal package;BB – Bed & Breakfast;  HB – Half board (breakfast and one other meal – usually dinner);  FB – Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155–3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:No Deposit – no deposit was made;Non Refund – a deposit was made in the value of the total stay cost;Refundable – a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:Contract - when the booking has an allotment or other type of contract associated to it;Group – when the booking is associated to a group;Transient – when the booking is not part of a group or contract, and is not associated to other transient booking;Transient-party – when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g. twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:Canceled – booking was canceled by the customer;Check-Out – customer has checked in but already departed;No-Show – customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "ae/ae-05-hotels-datatypes/hotels-forcats.html",
    "href": "ae/ae-05-hotels-datatypes/hotels-forcats.html",
    "title": "Hotel bookings - factors",
    "section": "",
    "text": "# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nFirst, knit the document and view the following visualisation. How are the months ordered? What would be a better order? Then, reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\nhotels %>%\n  group_by(hotel, arrival_date_month) %>%   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr)) %>%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n    )\n\n`summarise()` has grouped output by 'hotel'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "ae/ae-05-hotels-datatypes/type-coercion.html",
    "href": "ae/ae-05-hotels-datatypes/type-coercion.html",
    "title": "Type coercion",
    "section": "",
    "text": "c(1, 1L, \"C\")\n\n[1] \"1\" \"1\" \"C\"\n\n\n\n1\n\n[1] 1\n\n1L\n\n[1] 1\n\n\"C\"\n\n[1] \"C\"\n\n\n\n#typeof(c(1, 1L, \"C\"))\n\n\nc(1L / 0, \"A\")\n\n\nc(1L / 0, \"A\")\n\n[1] \"Inf\" \"A\"  \n\n\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L/0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n\n\n#typeof(c(1L / 0, \"A\"))\n\n\nc(1:3, 5)\n\n\nc(1:3, 5)\n\n[1] 1 2 3 5\n\n\n\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n\n\n#typeof(c(1:3, 5))\n\n\nc(3, \"3+\")\n\n\nc(3, \"3+\")\n\n[1] \"3\"  \"3+\"\n\n\n\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n\n\n#typeof(c(3, \"3+\"))\n\n\nc(NA, TRUE)\n\n\nc(NA, TRUE)\n\n[1]   NA TRUE\n\n\n\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n#typeof(c(NA, TRUE))"
  },
  {
    "objectID": "ae/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "href": "ae/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "title": "Nobel winners",
    "section": "",
    "text": "Let’s first load the data:\n\nnobel <- ___(___)\n\nThen let’s split the data into two:\n\n# stem laureates\n___ <- nobel %>%\n  filter(___)\n\n# non-steam laureates\n___ <- nobel %>%\n  filter(___)\n\nAnd finally write out the data:\n\n# add code for writing out the two data frames here"
  },
  {
    "objectID": "ae/ae-06-nobels-sales-dataimport/sales-excel.html",
    "href": "ae/ae-06-nobels-sales-dataimport/sales-excel.html",
    "title": "Sales",
    "section": "",
    "text": "Read in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\n\n\n\n\n\n\n\n\nStretch goal: Manipulate the sales data such such that it looks like the following."
  },
  {
    "objectID": "ae/ae-07-brexit-story-dataviz/brexit.html",
    "href": "ae/ae-07-brexit-story-dataviz/brexit.html",
    "title": "Brexit",
    "section": "",
    "text": "In September 2019, YouGov survey asked 1,639 GB adults the following question:\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon’t know\n\n\nThe data from the survey is in data/brexit.csv.\n\nbrexit <- read_csv(\"data/brexit.csv\")\n\nIn the course video we made the following visualisation.\n\nbrexit <- brexit %>%\n  mutate(\n    region = fct_relevel(region, \"london\", \"rest_of_south\", \"midlands_wales\", \"north\", \"scot\"),\n    region = fct_recode(region, London = \"london\", `Rest of South` = \"rest_of_south\", `Midlands / Wales` = \"midlands_wales\", North = \"north\", Scotland = \"scot\")\n  )\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\nIn this application exercise we tell different stories with the same data.\n\nExercise 1 - Free scales\nAdd scales = \"free_x\" as an argument to the facet_wrap() function. How does the visualisation change? How is the story this visualisation telling different than the story the original plot tells?\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region,\n    nrow = 1, labeller = label_wrap_gen(width = 12),\n    # ___\n  ) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\n\n\nExercise 2 - Comparing proportions across facets\nFirst, calculate the proportion of wrong, right, and don’t know answers in each category and then plot these proportions (rather than the counts) and then improve axis labeling. How is the story this visualisation telling different than the story the original plot tells? Hint: You’ll need the scales package to improve axis labeling, which means you’ll need to load it on top of the document as well.\n\n# code goes here\n\n\n\nExercise 3 - Comparing proportions across bars\nRecreate the same visualisation from the previous exercise, this time dodging the bars for opinion proportions for each region, rather than faceting by region and then improve the legend. How is the story this visualisation telling different than the story the previous plot tells?\n\n# code goes here"
  },
  {
    "objectID": "ae/ae-09-feat-eng-cv/theoffice-solution.html",
    "href": "ae/ae-09-feat-eng-cv/theoffice-solution.html",
    "title": "The Office - Solution",
    "section": "",
    "text": "Use theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16~\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",~\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis~\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky~\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha~\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6~\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,~\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-~\n\n\nFix air_date for later use.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don’t match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %>%\n  distinct(season, episode)\n\n# A tibble: 186 x 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# ... with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\noffice_lines <- theoffice %>%\n  group_by(season, episode) %>%\n  mutate(\n    n_lines = n(),\n    lines_jim = sum(character == \"Jim\") / n_lines,\n    lines_pam = sum(character == \"Pam\") / n_lines,\n    lines_michael = sum(character == \"Michael\") / n_lines,\n    lines_dwight = sum(character == \"Dwight\") / n_lines,\n  ) %>%\n  ungroup() %>%\n  select(season, episode, episode_name, contains(\"lines_\")) %>%\n  distinct(season, episode, episode_name, .keep_all = TRUE)\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine’s Day, and Christmas.\n\ntheoffice <- theoffice %>%\n  mutate(text = tolower(text))\n\nhalloween_episodes <- theoffice %>%\n  filter(str_detect(text, \"halloween\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(halloween = 1) %>%\n  select(-n)\n\nvalentine_episodes <- theoffice %>%\n  filter(str_detect(text, \"valentine\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(valentine = 1) %>%\n  select(-n)\n\nchristmas_episodes <- theoffice %>%\n  filter(str_detect(text, \"christmas\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(christmas = 1) %>%\n  select(-n)\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you’ve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\noffice_df <- theoffice %>%\n  select(season, episode, episode_name, imdb_rating, total_votes, air_date) %>%\n  distinct(season, episode, .keep_all = TRUE) %>%\n  left_join(halloween_episodes, by = \"episode_name\") %>% \n  left_join(valentine_episodes, by = \"episode_name\") %>% \n  left_join(christmas_episodes, by = \"episode_name\") %>% \n  replace_na(list(halloween = 0, valentine = 0, christmas = 0)) %>%\n  mutate(michael = if_else(season > 7, 0, 1)) %>%\n  mutate(across(halloween:michael, as.factor)) %>%\n  left_join(office_lines, by = c(\"season\", \"episode\", \"episode_name\"))\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\noffice_split <- initial_split(office_df)\noffice_train <- training(office_split)\noffice_test <- testing(office_split)\n\n\n\nExercise 5 - Specify a linear regression model.\n\noffice_mod <- linear_reg() %>%\n  set_engine(\"lm\")\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, and removes all zero variance predictors.\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  update_role(episode_name, new_role = \"id\") %>%\n  step_rm(air_date) %>%\n  step_dummy(all_nominal(), -episode_name) %>%\n  step_zv(all_predictors())\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\noffice_wflow <- workflow() %>%\n  add_model(office_mod) %>%\n  add_recipe(office_rec)\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\noffice_fit <- office_wflow %>%\n  fit(data = office_train)\n\ntidy(office_fit)\n\n# A tibble: 12 x 5\n   term           estimate std.error statistic  p.value\n   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)    6.34     0.298       21.2    1.24e-43\n 2 season         0.0542   0.0224       2.42   1.68e- 2\n 3 episode        0.0125   0.00439      2.85   5.05e- 3\n 4 total_votes    0.000372 0.0000390    9.55   1.25e-16\n 5 lines_jim      0.653    0.679        0.962  3.38e- 1\n 6 lines_pam      0.0329   0.696        0.0473 9.62e- 1\n 7 lines_michael  0.111    0.544        0.204  8.39e- 1\n 8 lines_dwight   0.806    0.522        1.54   1.25e- 1\n 9 halloween_X1  -0.00340  0.181       -0.0188 9.85e- 1\n10 valentine_X1  -0.0573   0.180       -0.318  7.51e- 1\n11 christmas_X1   0.285    0.129        2.22   2.82e- 2\n12 michael_X1     0.585    0.141        4.15   6.01e- 5\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\nset.seed(345)\nfolds <- vfold_cv(office_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 x 2\n  splits           id   \n  <list>           <chr>\n1 <split [111/28]> Fold1\n2 <split [111/28]> Fold2\n3 <split [111/28]> Fold3\n4 <split [111/28]> Fold4\n5 <split [112/27]> Fold5\n\nset.seed(456)\noffice_fit_rs <- office_wflow %>%\n  fit_resamples(folds)\n\ncollect_metrics(office_fit_rs)\n\n# A tibble: 2 x 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.367     5  0.0512 Preprocessor1_Model1\n2 rsq     standard   0.543     5  0.0386 Preprocessor1_Model1\n\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\noffice_test_pred <- predict(office_fit, new_data = office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, episode_name))\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.401\n\n\n\n\nOld model\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n# A tibble: 12 x 5\n   term                estimate std.error statistic  p.value\n   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)         7.20     0.188        38.4   9.92e-72\n 2 season             -0.0501   0.0140       -3.57  5.04e- 4\n 3 episode             0.0449   0.00877       5.11  1.13e- 6\n 4 total_votes         0.000360 0.0000404     8.89  4.99e-15\n 5 air_date_month_Feb -0.145    0.139        -1.04  2.99e- 1\n 6 air_date_month_Mar -0.376    0.134        -2.81  5.69e- 3\n 7 air_date_month_Apr -0.309    0.131        -2.36  1.96e- 2\n 8 air_date_month_May -0.128    0.162        -0.791 4.30e- 1\n 9 air_date_month_Sep  0.512    0.178         2.88  4.63e- 3\n10 air_date_month_Oct  0.270    0.139         1.95  5.38e- 2\n11 air_date_month_Nov  0.116    0.126         0.924 3.57e- 1\n12 air_date_month_Dec  0.407    0.165         2.47  1.49e- 2\n\noffice_test_pred_old <- predict(office_fit_old, new_data = office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, episode_name))\n\nrmse(office_test_pred_old, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.403"
  },
  {
    "objectID": "ae/ae-09-feat-eng-cv/theoffice.html",
    "href": "ae/ae-09-feat-eng-cv/theoffice.html",
    "title": "The Office",
    "section": "",
    "text": "Use theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16~\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",~\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis~\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky~\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha~\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ~\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6~\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,~\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-~\n\n\nFix air_date for later use.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don’t match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %>%\n  distinct(season, episode)\n\n# A tibble: 186 x 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# ... with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\n\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine’s Day, and Christmas.\n\n\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you’ve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\n\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\n\n\n\nExercise 5 - Specify a linear regression model.\n\n\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, uses season as a factor, and removes all zero variance predictors.\n\n\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\n\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\n#set.seed(345)\n#folds <- vfold_cv(___, v = ___)\n#folds\n#\n#set.seed(456)\n#office_fit_rs <- ___ %>%\n#  ___(___)\n#\n#___(office_fit_rs)\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\n\n\n\n\nOld model\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n___\n\nError: <text>:22:1: unexpected input\n21: \n22: _\n    ^"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "Your account will be pre-created before the class begins and will use your Cornell College username. The default password will be shared in class and you will need to change it."
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(palmerpenguins)\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.1.6     v dplyr   1.0.7\nv tidyr   1.1.4     v stringr 1.4.0\nv readr   2.1.1     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\nRegistered S3 method overwritten by 'tune':\n  method                   from   \n  required_pkgs.model_spec parsnip\n\n\n-- Attaching packages -------------------------------------- tidymodels 0.1.4 --\n\n\nv broom        0.7.10         v rsample      0.1.1     \nv dials        0.0.10         v tune         0.1.6     \nv infer        1.0.1.9000     v workflows    0.2.4     \nv modeldata    0.1.1          v workflowsets 0.1.0     \nv parsnip      0.1.7          v yardstick    0.0.9     \nv recipes      0.2.0          \n\n\n-- Conflicts ----------------------------------------- tidymodels_conflicts() --\nx scales::discard() masks purrr::discard()\nx dplyr::filter()   masks stats::filter()\nx recipes::fixed()  masks stringr::fixed()\nx dplyr::lag()      masks stats::lag()\nx yardstick::spec() masks readr::spec()\nx recipes::step()   masks stats::step()\n* Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(knitr)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\n# A tibble: 2 x 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\nFormat model output as table:\n\ntidy(penguins_fit) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5780.831\n305.815\n-18.903\n0\n\n\nflipper_length_mm\n49.686\n1.518\n32.722\n0\n\n\n\n\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n# A tibble: 342 x 9\n   .rownames body_mass_g flipper_length_~ .fitted  .resid    .hat .sigma .cooksd\n   <chr>           <int>            <int>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>\n 1 1                3750              181   3212.  538.   0.00881   394. 8.34e-3\n 2 2                3800              186   3461.  339.   0.00622   394. 2.33e-3\n 3 3                3250              195   3908. -658.   0.00344   393. 4.83e-3\n 4 5                3450              193   3808. -358.   0.00385   394. 1.60e-3\n 5 6                3650              190   3659.   -9.43 0.00469   395. 1.35e-6\n 6 7                3625              181   3212.  413.   0.00881   394. 4.91e-3\n 7 8                4675              195   3908.  767.   0.00344   393. 6.56e-3\n 8 9                3475              193   3808. -333.   0.00385   394. 1.39e-3\n 9 10               4250              190   3659.  591.   0.00469   394. 5.31e-3\n10 11               3300              186   3461. -161.   0.00622   395. 5.23e-4\n# ... with 332 more rows, and 1 more variable: .std.resid <dbl>\n\n\n\n\nStatistical inference"
  },
  {
    "objectID": "computing-troubleshooting_depr.html",
    "href": "computing-troubleshooting_depr.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They’ll be able to help diagnose the issue."
  },
  {
    "objectID": "course-faq_in_dev.html",
    "href": "course-faq_in_dev.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder)."
  },
  {
    "objectID": "course-faq_in_dev.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq_in_dev.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq_in_dev.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq_in_dev.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.1.2: https://cran.r-project.org/\nDownload and install a daily build of RStudio: https://dailies.rstudio.com/\nInstall Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "course-instructor.html",
    "href": "course-instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Dr. Tyler George (her/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics at Central Michigan University. During his PhD I he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Friday 3:05 am - 4:05 am\nWest 311\n\n\nOther Times by Appointment\nWest\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor!"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\n🔗 on Cornell College Cluster\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nGradebook\n🔗 on Moodle"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "DSC 223: Introduction to Data Science",
    "section": "",
    "text": "At the end of this course I would like you to be to use software’s including RStudio and GitHub to respect, explore, understand, and utilize data in a way that is replicable. This course supports the Educational Priorities and Outcomes of Cornell College with emphasis on knowledge, inquiry, reasoning, and communication, ethical behavior, citizenship, and vocation. Your emphasis on knowledge is in the skills you will learn and apply in various interdisciplinary fields. You will inquire when investigating data – seeing patters or trends and exploring them to. Your reasoning skills are built and tested when making decisions based on the data and your own programmed visualizations and numerical summaries. Your group work in class and group project presentations will help you practice your communication of statistical analysis. When you make decisions about what data to work with, how to treat the data, and how to talk about your results in an ethical way you practice good ethical behavior. Some of our analysis’ will be with data from institutions such as governments or organizations that have an influence on the public – these types of analysis’ can inform public policies and are our way, as data scientists, to practice citizenship. Lastly, you will learn about the field of data science and the types of knowledge and training that would be required to support your vocation as a data scientist."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nYou are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first few days of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of your professors office hours here."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\n\nQuantitative Reasoning Studio (QRS)\nThere are times you may need help outside of class or office hours. Or, maybe you need something explained in a different way. In those instances, I encourage you to visit the Quantitative Reasoning Studio in Cole Library room 322. The Quantitative Reasoning Studio (QRS) offers free tutoring to all students at Cornell College. There will be at least 1 peer tutor that has taken this course and will be able to help you, if you arrive at a time they are working. Feel free to email Jessica Johanningmeier at QRS@cornellcollege.edu to ask when the tutor for this class will be available. They often will have a schedule posted on the wall in the studio.\n\n\nQRS Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n3 p.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\n\n\n\nDungy Writing Studio\nFor help with your writing, visit the Dungy Writing Studio. You can make online appointments individual or groups to get help with items such as your group project. If you have any questions about the studio, email Dungy Writing Studio Director and Director of Fellowships and Scholarships, Laura Farmer, at lfarmer@cornellcollege.edu.\n\n\nWriting Studio Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n1 p.m. - 5 p.m."
  },
  {
    "objectID": "course-support.html#student-success-center",
    "href": "course-support.html#student-success-center",
    "title": "Course support",
    "section": "Student Success Center",
    "text": "Student Success Center\nThe Student Success Center is a resource for all students. Their staff serves as student success coaches for all students and welcome students to visit us to talk about academic concerns, study plans, finding their place at Cornell, or any questions you have and aren’t sure where to start! You can walk in to chat or contact a staff member directly to set up an appointment! See the website for more information."
  },
  {
    "objectID": "course-support.html#professor-email",
    "href": "course-support.html#professor-email",
    "title": "Course support",
    "section": "Professor Email",
    "text": "Professor Email\nIf you are not available during office hours times or have a questions later in the evening or other times outside of class, email your professor at tgeorge@cornellcollege.edu. If your question involves code - it is very likely you will need to meet with him to get help. Please reach out with any concerns you have during the course!"
  },
  {
    "objectID": "course-support.html#ebersole-health-and-wellbeing-center",
    "href": "course-support.html#ebersole-health-and-wellbeing-center",
    "title": "Course support",
    "section": "Ebersole Health and Wellbeing Center",
    "text": "Ebersole Health and Wellbeing Center\nThe mission of Cornell College Student Health Services complements the mission of the college by promoting the optimal well-being of students. We do this by:\n\nproviding and coordinating quality health care services\nadvocating for students in their pursuit of health and wellness\npreparing students to be their own health advocates and informed consumers of appropriate health care services\nproviding health education to promote the development of healthy lifestyles\n\nThe Student Health Center is located in the Ebersole Building, directly south of the Thomas Commons. Appointments are preferred. You can schedule an appointment online or by phone at 319-895-4292. Walk-ins will be accommodated as time permits. Appointments with the nurse are free."
  },
  {
    "objectID": "course-support.html#technology-support",
    "href": "course-support.html#technology-support",
    "title": "Course support",
    "section": "Technology Support",
    "text": "Technology Support\nIf you have issues with your computer during the block, IT may be able to help. Please submit a ticket."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the FULL syllabus."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nData Science in a Box by Mine Çetinkaya-Rundel\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge"
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "exams/exam-2.html",
    "href": "exams/exam-2.html",
    "title": "Exam 2",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "exams/exam-3.html",
    "href": "exams/exam-3.html",
    "title": "Exam 2",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html",
    "href": "hw/hw-01/hw-01-pet-names.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "Photo by Jovana Askrabic on Unsplash\nThe goal of this assignment is to introduce you to R, RStudio, Git, and GitHub, which you’ll be using throughout the course both to learn the data science concepts discussed in the course and to analyze real data and come to informed conclusions."
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html#prerequisites",
    "href": "hw/hw-01/hw-01-pet-names.html#prerequisites",
    "title": "HW 01 - Pet names",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis assignment assumes that you have reviewed the lectures titled “Meet the toolkit: Programming” and “Meet the toolkit: version control and collaboration”. If you haven’t yet done so, please pause and complete the following before continuing."
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html#terminology",
    "href": "hw/hw-01/hw-01-pet-names.html#terminology",
    "title": "HW 01 - Pet names",
    "section": "Terminology",
    "text": "Terminology\nWe’ve already thrown around a few new terms, so let’s define them before we proceed.\n\nR: Name of the programming language we will be using throughout the course.\nRStudio: An integrated development environment for R. In other words, a convenient interface for writing and running R code.\nGit: A version control system.\nGitHub: A web platform for hosting version controlled files and facilitating collaboration among users.\nRepository: A Git repository contains all of your project’s files and stores each file’s revision history. It’s common to refer to a repository as a repo.\n\nIn this course, each assignment you work on will be contained in a Git repo.\nFor individual assignments, only you will have access to the repo. For team assignments, all team members will have access to a single repo where they work collaboratively.\nAll repos associated with this course are housed in the course GitHub organization. The organization is set up such that students can only see repos they have access to, but the course staff can see all of them."
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html#starting-slow",
    "href": "hw/hw-01/hw-01-pet-names.html#starting-slow",
    "title": "HW 01 - Pet names",
    "section": "Starting slow",
    "text": "Starting slow\nAs the course progresses, you are encouraged to explore beyond what the assignments dictate; a willingness to experiment will make you a much better programmer! Before we get to that stage, however, you need to build some basic fluency in R. First, we will explore the fundamental building blocks of all of these tools.\nBefore you can get started with the analysis, you need to make sure you:\n\nhave a GitHub account\nare a member of the course GitHub organization\nare a member of the course RStudio Cloud space\n\nIf you failed to confirm any of these, it means you have not yet completed the prerequisites for this assignment. Please go back to Prerequisites and complete them before continuing the assignment."
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "href": "hw/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "title": "HW 01 - Pet names",
    "section": "Step 1. Update the YAML",
    "text": "Step 1. Update the YAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document."
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html#step-2-commit",
    "href": "hw/hw-01/hw-01-pet-names.html#step-2-commit",
    "title": "HW 01 - Pet names",
    "section": "Step 2: Commit",
    "text": "Step 2: Commit\nThen Go to the Git pane in your RStudio.\nYou should see that your Rmd (R Markdown) file and its output, your md file (Markdown), are listed there as recently changed files.\nNext, click on Diff. This will pop open a new window that shows you the difference between the last committed state of the document and its current state that includes your changes. If you’re happy with these changes, click on the checkboxes of all files in the list, and type “Update author name” in the Commit message box and hit Commit.\n\n\n\n\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions."
  },
  {
    "objectID": "hw/hw-01/hw-01-pet-names.html#step-3.-push",
    "href": "hw/hw-01/hw-01-pet-names.html#step-3.-push",
    "title": "HW 01 - Pet names",
    "section": "Step 3. Push",
    "text": "Step 3. Push\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only). In order to push your changes to GitHub, click on Push.\n\n\n\n\n\nThis will prompt a dialogue box where you first need to enter your user name, and then your password. This might feel cumbersome. Bear with me… I will teach you how to save your password so you don’t have to enter it every time. But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it.\nThought exercise: Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?1"
  },
  {
    "objectID": "hw/hw-02/hw-02-airbnb-edi.html",
    "href": "hw/hw-02/hw-02-airbnb-edi.html",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "Photo by Madeleine Kohler on Unsplash\nOnce upon a time, people travelled all over the world, and some stayed in hotels and others chose to stay in other people’s houses that they booked through Airbnb. Recent developments in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed. Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighbourhood."
  },
  {
    "objectID": "hw/hw-02/hw-02-airbnb-edi.html#warm-up",
    "href": "hw/hw-02/hw-02-airbnb-edi.html#warm-up",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-02/hw-02-airbnb-edi.html#packages",
    "href": "hw/hw-02/hw-02-airbnb-edi.html#packages",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "hw/hw-02/hw-02-airbnb-edi.html#data",
    "href": "hw/hw-02/hw-02-airbnb-edi.html#data",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called edibnb. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package.\nYou can view the dataset as a spreadsheet using the View() function. Note that you should not put this function in your R Markdown document, but instead type it directly in the Console, as it pops open a new window (and the concept of popping open a window in a static document doesn’t really make sense…). When you run this in the console, you’ll see the following data viewer window pop up.\n\nView(edibnb)\n\nYou can find out more about the dataset by inspecting its documentation, which you can access by running ?edibnb in the Console or using the Help menu in RStudio to search for edibnb. You can also find this information here."
  },
  {
    "objectID": "hw/hw-03/hw-03-accidents.html",
    "href": "hw/hw-03/hw-03-accidents.html",
    "title": "HW 03 - Road traffic accidents",
    "section": "",
    "text": "Photo by Clark Van Der Beken on Unsplash\nIn this assignment we’ll look at traffic accidents in Edinburgh. The data are made available online by the UK Government. It covers all recorded accidents in Edinburgh in 2018 and some of the variables were modified for the purposes of this assignment."
  },
  {
    "objectID": "hw/hw-03/hw-03-accidents.html#warm-up",
    "href": "hw/hw-03/hw-03-accidents.html#warm-up",
    "title": "HW 03 - Road traffic accidents",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-03/hw-03-accidents.html#packages",
    "href": "hw/hw-03/hw-03-accidents.html#packages",
    "title": "HW 03 - Road traffic accidents",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "hw/hw-03/hw-03-accidents.html#data",
    "href": "hw/hw-03/hw-03-accidents.html#data",
    "title": "HW 03 - Road traffic accidents",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called accidents. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?accidents in the Console or using the Help menu in RStudio to search for accidents. You can also find this information here."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html",
    "href": "hw/hw-04/hw-04-college-majors.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "Photo by Marleena Garris on Unsplash\nThe first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#warm-up",
    "href": "hw/hw-04/hw-04-college-majors.html#warm-up",
    "title": "HW 04 - What should I major in?",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#packages",
    "href": "hw/hw-04/hw-04-college-majors.html#packages",
    "title": "HW 04 - What should I major in?",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the scales package for better formatting of labels on visualisations, and the data lives in the fivethirtyeight package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#data",
    "href": "hw/hw-04/hw-04-college-majors.html#data",
    "title": "HW 04 - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found in the fivethirtyeight package, and it’s called college_recent_grads. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?college_recent_grads in the Console or using the Help menu in RStudio to search for college_recent_grads. You can also find this information here.\nYou can also take a quick peek at your data frame and view its dimensions with the glimpse function.\n\nglimpse(college_recent_grads)\n\nThe college_recent_grads data frame is a trove of information. Let’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "href": "hw/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all we need to do is sort the data. We use the arrange function to do this, and sort it by the unemployment_rate variable. By default arrange sorts in ascending order, which is what we want here – we’re interested in the major with the lowest unemployment rate.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate)\n\nThis gives us what we wanted, but not in an ideal form. First, the name of the major barely fits on the page. Second, some of the variables are not that useful (e.g. major_code, major_category) and some we might want front and center are not easily viewed (e.g. unemployment_rate).\nWe can use the select function to choose which variables to display, and in which order:\n\nNote how easily we expanded our code with adding another step to our pipeline,\nwith the pipe operator: `%>%`.\n\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate) %>%\n  select(rank, major, unemployment_rate)\n\nOk, this is looking better, but do we really need to display all those decimal places in the unemployment variable? Not really!\nWe can use the percent() function to clean up the display a bit.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate) %>%\n  select(rank, major, unemployment_rate) %>%\n  mutate(unemployment_rate = percent(unemployment_rate))"
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "href": "hw/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nThe `desc` function specifies that we want `unemployment_rate` in descending order.\n\n\ncollege_recent_grads %>%\n  arrange(desc(unemployment_rate)) %>%\n  select(rank, major, unemployment_rate)\n\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding top_n(3) at the end of the pipeline."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "hw/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW 04 - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\n\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)\n\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nWe use the ggplot() function to do this. The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the aesthetic elements of the plot.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram()\n\nAlong with the plot, we get a message:\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nThis is telling us that we might want to reconsider the binwidth we chose for our histogram – or more accurately, the binwidth we didn’t specify. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\n\nWe can also calculate summary statistics for this distribution using the summarise function:\n\ncollege_recent_grads %>%\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.\n\n\ncollege_recent_grads %>%\n  group_by(major_category) %>%\n  summarise(___ = ___(median)) %>%\n  arrange(___)\n\n\nWhich major category is the least popular in this sample? To answer this question we use a new function called count, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.\n\n\ncollege_recent_grads %>%\n  count(major_category)\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "href": "hw/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "title": "HW 04 - What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads <- college_recent_grads %>%\n  mutate(major_type = ifelse(major_category %in% stem_categories, \"stem\", \"not stem\"))\n\nLet’s unpack this: with mutate we create a new variable called major_type, which is defined as \"stem\" if the major_category is in the vector called stem_categories we created earlier, and as \"not stem\" otherwise.\n%in% is a logical operator. Other logical operators that are commonly used are\n\n\n\nOperator\nOperation\n\n\n\n\nx < y\nless than\n\n\nx > y\ngreater than\n\n\nx <= y\nless than or equal to\n\n\nx >= y\ngreater than or equal to\n\n\nx != y\nnot equal to\n\n\nx == y\nequal to\n\n\nx %in% y\ncontains\n\n\nx | y\nor\n\n\nx & y\nand\n\n\n!x\nnot\n\n\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads %>%\n  filter(\n    major_type == \"stem\",\n    median < 36000\n  )\n\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "hw/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW 04 - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "hw/hw-04/hw-04-college-majors.html#further-exploration",
    "href": "hw/hw-04/hw-04-college-majors.html#further-exploration",
    "title": "HW 04 - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s).\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "hw/hw-05/hw-05-legos.html",
    "href": "hw/hw-05/hw-05-legos.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "Photo by Daniel Cheung on Unsplash\nThis week we’ll do some data gymnastics to refresh and review what we learned over the past few weeks using (simulated) data from Lego sales in 2018 for a sample of customers who bought Legos in the US."
  },
  {
    "objectID": "hw/hw-05/hw-05-legos.html#warm-up",
    "href": "hw/hw-05/hw-05-legos.html#warm-up",
    "title": "HW 05 - Legos",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-05/hw-05-legos.html#packages",
    "href": "hw/hw-05/hw-05-legos.html#packages",
    "title": "HW 05 - Legos",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "hw/hw-05/hw-05-legos.html#data",
    "href": "hw/hw-05/hw-05-legos.html#data",
    "title": "HW 05 - Legos",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called lego_sales. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?lego_sales in the Console or using the Help menu in RStudio to search for lego_sales. You can also find this information here."
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html",
    "href": "hw/hw-06/hw-06-money-in-politics.html",
    "title": "HW 06 - Money in US politics",
    "section": "",
    "text": "Photo by Sharon McCutcheon on Unsplash\nEvery election cycle brings its own brand of excitement – and lots of money. Political donations are of particular interest to political scientists and other researchers studying politics and voting patterns. They are also of interest to citizens who want to stay informed of how much money their candidates raise and where that money comes from.\nIn the United States, “only American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees.”1\nIn this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns. First, we will get data foreign connected PAC contributions in the 2022 election cycle. Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.\nIn order to complete this assignment you will need a Chrome browser with the Selector Gadget extension installed."
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html#warm-up",
    "href": "hw/hw-06/hw-06-money-in-politics.html#warm-up",
    "title": "HW 06 - Money in US politics",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html#packages",
    "href": "hw/hw-06/hw-06-money-in-politics.html#packages",
    "title": "HW 06 - Money in US politics",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we’re allowed to scrape the data, the rvest package for data scraping, and the scales package for better formatting of labels on visualisations. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(robotstxt)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html#data",
    "href": "hw/hw-06/hw-06-money-in-politics.html#data",
    "title": "HW 06 - Money in US politics",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you’ll be scraping the data!"
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "href": "hw/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "title": "HW 06 - Money in US politics",
    "section": "Data collection via web scraping",
    "text": "Data collection via web scraping\n\n\n\n\n\nThe data come from OpenSecrets.org, a “website tracking the influence of money on U.S. politics, and how that money affects policy and citizens’ lives”. This website is hosted by The Center for Responsive Politics, which is a nonpartisan, independent nonprofit that “tracks money in U.S. politics and its effect on elections and public policy.”2\nBefore getting started, let’s check that a bot has permissions to access pages on this domain.\n\nlibrary(robotstxt)\npaths_allowed(\"https://www.opensecrets.org\")\n\n[1] TRUE\n\n\nOur goal is to scrape data for contributions in all election years Open Secrets has data for. Since that means repeating a task many times, let’s first write a function that works on the first page. Confirm it works on a few others. Then iterate it over pages for all years.\n\nComplete the following set of steps in the scrape-pac.R file in the scripts folder of your repository. This file already contains some starter code to help you out.\n\n\nWrite a function called scrape_pac() that scrapes information from the Open Secrets webpage for foreign-connected PAC contributions in a given year. This function should\n\nhave one input: the URL of the webpage and should return a data frame.\nrename variables scraped, using snake_case naming.\nclean up the Country of Origin/Parent Company variable with str_squish().\nadd a new column to the data frame for year. We will want this information when we ultimately have data from all years, so this is a good time to keep track of it. Our function doesn’t take a year argument, but the year is embedded in the URL, so we can extract it out of there, and add it as a new column. Use the str_sub() function to extract the last 4 characters from the URL. You will probably want to look at the help for this function to figure out how to specify “last 4 characters”.\n\nDefine the URLs for 2022, 2020, and 2000 contributions. Then, test your function using these URLs as inputs. Does the function seem to do what you expected it to do?\nConstruct a vector called urls that contains the URLs for each webpage that contains information on foreign-connected PAC contributions for a given year.\nMap the scrape_pac() function over urls in a way that will result in a data frame called pac_all.\nWrite the data frame to a csv file called pac-all.csv in the data folder.\n\n✅⬆️ If you haven’t yet done so, now is definitely a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. “Data scraping complete”). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nComplete the following set of steps in the hw-06.Rmd file in your repository.\n\n\nIn your R Markdown file, load pac-all.csv and report its number of observations and variables using inline code."
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "href": "hw/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "title": "HW 06 - Money in US politics",
    "section": "Data cleaning",
    "text": "Data cleaning\nIn this section we clean the pac_all data frame to prepare it for analysis and visualization. We have two goals in data cleaning:\n\nSeparate the country_parent into two such that country and parent company appear in different columns for country-level analysis.\nConvert contribution amounts in total, dems, and repubs from character strings to numeric values.\n\nThe following exercises walk you through how to make these fixes to the data.\n\nUse the separate() function to separate country_parent into country and parent columns. Note that country and parent company names are separated by \\ (which will need to be specified in your function) and also note that there are some entries where the \\ sign appears twice and in these cases we want to only split the value at the first occurrence of \\. This can be accomplished by setting the extra argument in to \"merge\" so that the cell is split into only 2 segments, e.g. we want \"Denmark/Novo Nordisk A/S\" to be split into \"Denmark\" and \"Novo Nordisk A/S\". (See help for separate() for more on this.) End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you).\nRemove the character strings including $ and , signs in the total, dems,and repubs columns and convert these columns to numeric. End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you). A couple hints to help you out:\n\nThe $ character is a special character so it will need to be escaped.\nSome contribution amounts are in the millions (e.g. Anheuser-Busch contributed a total of $1,510,897 in 2008). In this case we need to remove all occurrences of ,, which we can do by using str_remove_all() instead of str_remove().\n\n\n🧶 ✅ ⬆️ Now is a good time to knit your document, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "href": "hw/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "title": "HW 06 - Money in US politics",
    "section": "Data visualization and interpretation",
    "text": "Data visualization and interpretation\n\nCreate a line plot of total contributions from all foreign-connected PACs in the Canada and Mexico over the years. Once you have made the plot, write a brief interpretation of what the graph reveals. Few hints to help you out:\n\nFilter for only Canada and Mexico.\nCalculate sum of total contributions from PACs for each year for each country by using a sequence of group_by() then summarise().\nMake a plot of total contributions (y-axis) by year (x-axis) where two lines identified by different colours represent each of Canada and Mexico.\n\n\n\n**Note:** The figure you create might look slightly different than this one if the data on the website has been updated recently.\n\n\nRecreate the following visualisation. Once you have made the plot, write a brief interpretation of what the graph reveals. Note that these are only UK contributions. You will need to make use of functions from the scales package for axis labels as well as from ggplot2.\n\n\n\n\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "Photo by Viktor Kern on Unsplash\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\nSource: UCI Machine Learning Repository - Bike Sharing Dataset"
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html#packages",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html#packages",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html#data",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html#data",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called dcbikeshare. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?dcbikeshare in the Console or using the Help menu in RStudio to search for dcbikeshare. You can also find this information here.\nThe data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days. The original data sources are http://capitalbikeshare.com/system-data and http://www.freemeteo.com."
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nRecode the season variable to be a factor with meaningful level names as outlined in the codebook, with spring as the baseline level.\nRecode the binary variables holiday and workingday to be factors with levels no (0) and yes (1), with no as the baseline level.\nRecode the yr variable to be a factor with levels 2011 and 2012, with 2011 as the baseline level.\nRecode the weathersit variable as 1 - clear, 2 - mist, 3 - light precipitation, and 4 - heavy precipitation, with clear as the baseline.\nCalculate raw temperature, feeling temperature, humidity, and windspeed as their values given in the dataset multiplied by the maximum raw values stated in the codebook for each variable. Instead of writing over the existing variables, create new ones with concise but informative names.\nCheck that the sum of casual and registered adds up to cnt for each record. Hint: One way of doing this is to create a new column that takes on the value TRUE if they add up and FALSE if not, and then checking if all values in that column are TRUEs. But this is only one way, you might come up with another.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nRecreate the following visualization, and interpret it in context of the data. Hint: You will need to use one of the variables you created above. The temperature plotted is the feeling temperature.\n\n\n\n\n\n\n\nCreate a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "href": "hw/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Modelling",
    "text": "Modelling\n\nFit a linear model predicting total daily bike rentals from daily temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\).\nFit another linear model predicting total daily bike rentals from daily feeling temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\). Is temperature or feeling temperature a better predictor of bike rentals? Explain your reasoning.\nFit a model predicting total daily bike rentals from season, year, whether the day is holiday or not, whether the day is a workingday or not, the weather category, temperature, feeling temperature, humidity, and windspeed, as well as the interaction between feeling temperature and holiday. Record adjusted \\(R^2\\) of the model.\nWrite the linear models for holidays and non-holidays. Is the slope of temperature the same or different for these two models? How about the slope for feeling temperature? Why or why not?\nInterpret the slopes of season and feeling temperature. If the slopes are different for holidays and non-holidays, make sure to interpret both. If the variable has multiple levels, make sure you interpret all of the slope coefficients associated with it.\nInterpret the intercept. If the intercept is different for holidays and non-holidays, make sure to interpret both.\nAccording to this model, assuming everything else is the same, in which season does the model predict total daily bike rentals to be highest and which to be the lowest?\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html",
    "href": "hw/hw-08/hw-08-exploring-gss.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "Photo by Mauro Mora on Unsplash\nThe GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes. Hundreds of trends have been tracked since 1972. In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.\nThe GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.\nIn this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.1"
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html#warm-up",
    "href": "hw/hw-08/hw-08-exploring-gss.html#warm-up",
    "title": "HW 08 - Exploring the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html#packages",
    "href": "hw/hw-08/hw-08-exploring-gss.html#packages",
    "title": "HW 08 - Exploring the GSS",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html#data",
    "href": "hw/hw-08/hw-08-exploring-gss.html#data",
    "title": "HW 08 - Exploring the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "href": "hw/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 1: Harassment at work",
    "text": "Part 1: Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nWhat are the possible responses to this question and how many respondents chose each of these answers?\nWhat percent of the respondents for whom this question is applicable\n(i.e. excluding NAs and Does not applys) have been harassed by their superiors or co-workers at their job.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "href": "hw/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 2: Time spent on email",
    "text": "Part 2: Time spent on email\nThe 2016 GSS also asked respondents how many hours and minutes they spend on email weekly. The responses to these questions are recorded in the emailhr and emailmin variables. For example, if the response is 2.5 hrs, this would be recorded as emailhr = 2 and emailmin = 30.\n\nCreate a new variable called email that combines these two variables to reports the number of minutes the respondents spend on email weekly.\nVisualize the distribution of this new variable. Find the mean and the median number of minutes respondents spend on email weekly. Is the mean or the median a better measure of the typical among of time Americans spend on email weekly? Why?\nCreate another new variable, snap_insta that is coded as “Yes” if the respondent reported using any of Snapchat (snapchat) or Instagram (instagrm), and “No” if not. If the recorded value was NA for both of these questions, the value in your new variable should also be NA.\nCalculate the percentage of Yes’s for snap_insta among those who answered the question, i.e. excluding NAs.\nWhat are the possible responses to the question Last week were you working full time, part time, going to school, keeping house, or what? and how many respondents chose each of these answers? Note that this information is stored in the wrkstat variable.\nFit a model predicting email (number of minutes per week spent on email) from educ (number of years of education), wrkstat, and snap_insta. Interpret the slopes for each of these variables.\nCreate a predicted values vs. residuals plot for this model. Are there any issues with the model? If yes, describe them.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "href": "hw/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 3: Political views and science research",
    "text": "Part 3: Political views and science research\nThe 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (polviews) and whether they think science research is necessary and should be supported by the federal government (advfront).\n\nThe question on science research is worded as follows:\n\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nAnd possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don’t know, No answer, Not applicable.\n\nThe question on political views is worded as follows:\n\n\nWe hear a lot of talk these days about liberals and conservatives. I’m going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal–point 1–to extremely conservative–point 7. Where would you place yourself on this scale?\n\n\n**Note:** The levels of this variables are spelled inconsistently: \"Extremely liberal\" vs. \"Extrmly conservative\". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.\n\nAnd possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative. Responses that were originally Don’t know, No answer and Not applicable are already mapped to NAs upon data import.\n\nIn a new variable, recode advfront such that Strongly Agree and Agree are mapped to \"Yes\", and Disagree and Strongly disagree are mapped to \"No\". The remaining levels can be left as is. Don’t overwrite the existing advfront, instead pick a different, informative name for your new variable.\nIn a new variable, recode polviews such that Extremely liberal, Liberal, and Slightly liberal, are mapped to \"Liberal\", and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to \"Conservative\". The remaining levels can be left as is. Make sure that the levels are in a reasonable order. Don’t overwrite the existing polviews, instead pick a different, informative name for your new variable.\nCreate a visualization that displays the relationship between these two new variables and interpret it.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "hw/hw-09/hw-09-modeling-gss.html",
    "href": "hw/hw-09/hw-09-modeling-gss.html",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "Photo Mauro Mora on Unsplash\nIn this assignment we continue our exploration of the 2016 GSS dataset from the previous homework."
  },
  {
    "objectID": "hw/hw-09/hw-09-modeling-gss.html#warm-up",
    "href": "hw/hw-09/hw-09-modeling-gss.html#warm-up",
    "title": "HW 09 - Modeling the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-09/hw-09-modeling-gss.html#packages",
    "href": "hw/hw-09/hw-09-modeling-gss.html#packages",
    "title": "HW 09 - Modeling the GSS",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "hw/hw-09/hw-09-modeling-gss.html#data",
    "href": "hw/hw-09/hw-09-modeling-gss.html#data",
    "title": "HW 09 - Modeling the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "hw/hw-09/hw-09-modeling-gss.html#scientific-research",
    "href": "hw/hw-09/hw-09-modeling-gss.html#scientific-research",
    "title": "HW 09 - Modeling the GSS",
    "section": "Scientific research",
    "text": "Scientific research\nIn this section we’re going to build a model to predict whether someone agrees or doesn’t agree with the following statement:\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nThe responses to the question on the GSS about this statement are in the advfront variable.\n\nIt's important that you don't recode the NAs, just the remaining levels.\n\n\nRe-level the advfront variable such that it has two levels: Strongly agree and “Agree\" combined into a new level called agree and the remaining levels (except NAs) combined into”Not agree\". Then, re-order the levels in the following order: \"Agree\" and \"Not agree\". Finally, count() how many times each new level appears in the advfront variable.\n\n\nYou can do this in various ways. One option is to use the `str_detect()` function to detect the existence of words like liberal or conservative. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the `str_detect()` function, you can use \"[Ll]iberal\" and \"[Cc]onservative\". But feel free to solve the problem however you like, this is just one option!\n\n\nCombine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word conservative in them are lumped into a level called \"Conservative\". Then, re-order the levels in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame. Sample code is provided below.\n\n\ngss16_advfront <- gss16 %>%\n  select(___, ___, ___, ___) %>%\n  drop_na()\n\n\nSplit the data into training (75%) and testing (25%) data sets. Make sure to set a seed before you do the initial_split(). Call the training data gss16_train and the testing data gss16_test. Sample code is provided below. Use these specific names to make it easier to follow the rest of the instructions.\n\n\nset.seed(___)\ngss16_split <- initial_split(gss16_advfront)\ngss16_train <- training(gss16_split)\ngss16_test  <- testing(gss16_split)\n\n\nCreate a recipe with the following steps for predicting advfront from polviews, wrkstat, and educ. Name this recipe gss16_rec_1. (We’ll create one more recipe later, that’s why we’re naming this recipe _1.) Sample code is provided below.\n\nstep_other() to pool values that occur less than 10% of the time (threshold = 0.10) in the wrkstat variable into \"Other\".\nstep_dummy() to create dummy variables for all_nominal() variables that are predictors, i.e. all_predictors()\n\n\n\ngss16_rec_1 <- recipe(___ ~ ___, data = ___) %>%\n  step_other(wrkstat, threshold = ___, other = \"Other\") %>%\n  step_dummy(all_nominal(), -all_outcomes())\n\n\nSpecify a logistic regression model using \"glm\" as the engine. Name this specification gss16_spec. Sample code is provided below.\n\n\ngss16_spec <- ___() %>%\n  set_engine(\"___\")\n\n\nBuild a workflow that uses the recipe you defined (gss16_rec) and the model you specified (gss16_spec). Name this workflow gss16_wflow_1. Sample code is provided below.\n\n\ngss16_wflow_1 <- workflow() %>%\n  add_model(___) %>%\n  add_recipe(___)\n\n\nPerform 5-fold cross validation. specifically,\n\nsplit the training data into 5 folds (don’t forget to set a seed first!),\napply the workflow you defined earlier to the folds with fit_resamples(), and\ncollect_metrics() and comment on the consistency of metrics across folds (you can get the area under the ROC curve and the accuracy for each fold by setting summarize = FALSE in collect_metrics())\nreport the average area under the ROC curve and the accuracy for all cross validation folds collect_metrics()\n\n\n\nset.seed(___)\ngss16_folds <- vfold_cv(___, v = ___)\n\ngss16_fit_rs_1 <- gss16_wflow_1 %>%\n  fit_resamples(___)\n\ncollect_metrics(___, summarize = FALSE)\ncollect_metrics(___)\n\n\nNow, try a different, simpler model: predict advfront from only polviews and educ. Specifically,\n\nupdate the recipe to reflect this simpler model specification (and name it gss16_rec_2),\nredefine the workflow with the new recipe (and name this new workflow gss16_wflow_2),\nperform cross validation, and\nreport the average area under the ROC curve and the accuracy for all cross validation folds collect_metrics().\n\nComment on which model performs better (one including wrkstat, model 1, or the one excluding wrkstat, model 2) on the training data based on area under the ROC curve.\nFit both models to the testing data, plot the ROC curves for the predictions for both models, and calculate the areas under the ROC curve. Does your answer to the previous exercise hold for the testing data as well? Explain your reasoning. Note: If you haven’t yet done so, you’ll need to first train your workflows on the training data with the following, and then use these fit objects to calculate predictions for the test data.\n\n\ngss16_fit_1 <- gss16_wflow_1 %>%\n  fit(gss16_train)\n\ngss16_fit_2 <- gss16_wflow_2 %>%\n  fit(gss16_train)\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-09/hw-09-modeling-gss.html#harassment-at-work",
    "href": "hw/hw-09/hw-09-modeling-gss.html#harassment-at-work",
    "title": "HW 09 - Modeling the GSS",
    "section": "Harassment at work",
    "text": "Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nCreate a subset of the data that only contains Yes and No answers for the harassment question. How many responses chose each of these answers?\nDescribe how bootstrapping can be used to estimate the proportion of Americans who have been harassed by their superiors or co-workers at their job.\nCalculate a 95% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Interpret this interval in context of the data.\nWould you expect a 90% confidence interval to be wider or narrower than the interval you calculated above? Explain your reasoning.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "hw/hw-10/hw-10-wrap-up.html",
    "href": "hw/hw-10/hw-10-wrap-up.html",
    "title": "HW 10 - Wrap up!",
    "section": "",
    "text": "Photo by Kari Shea on Unsplash\nIt’s almost time to wrap up the course! In this three part assignment you get to practice what we learned this week, try something new, and get creative!"
  },
  {
    "objectID": "hw/hw-10/hw-10-wrap-up.html#warm-up",
    "href": "hw/hw-10/hw-10-wrap-up.html#warm-up",
    "title": "HW 10 - Wrap up!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "hw/hw-10/hw-10-wrap-up.html#packages",
    "href": "hw/hw-10/hw-10-wrap-up.html#packages",
    "title": "HW 10 - Wrap up!",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for the first part of this assignment. For the second part you get to choose which package to use.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "hw/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "href": "hw/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "title": "HW 10 - Wrap up!",
    "section": "Part 1 - Mirror, mirror on the wall, who’s the ugliest of them all?",
    "text": "Part 1 - Mirror, mirror on the wall, who’s the ugliest of them all?\nHere is a simple plot using the mpg dataset, which contains information on fuel economy of cars. We’re plotting highway miles per gallon vs. city miles per gallon, coloured by whether the car is front-wheel drive, rear wheel drive, or four-wheel drive.\n\nggplot(data = mpg, aes(x = cty, y = hwy, color = drv)) +\n  geom_point()\n\n\nI realize that \"ugly\" is subjective, so we're mostly looking to see if you can figure out how to change the look of a plot using help files of functions you haven't learned before.\n\n\nMake this plot as ugly as possible by changing colours, background color, fonts, or anything else you can think of. You will probably want to play around with theme options, but you can do more. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "hw/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "href": "hw/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "title": "HW 10 - Wrap up!",
    "section": "Part 2 - You gotta pick a package or two",
    "text": "Part 2 - You gotta pick a package or two\nBut really, one is enough. Pick a package from the list below, and use it to do something. If you want to use a package not on this list, that’s also ok, but it needs to be a package we haven’t used in class. If you start with a package and are struggling to get it to work, ask for help on Piazza or just move to another one.\n\n**Remember:** You *install* the package in the Console, not in the R Markdown document since you don't want to keep reinstalling it every time you knit the document.\n\nYour task is to install the package you pick. Depending on where the package comes from, how you install the package differs:\n\nIf the package is on CRAN (Comprehensive R Archive Network), you can install it with install.packages.\nIf the package is only on Github (most likely because it is still under development), you need to use the install_github function.\n\nThen, load the package. Regardless of how you installed the package you can load it with the library function.\nFinally, do something with the package. It doesn’t have to be complicated. In fact, keep it simple. The goal is for you to read and understand the package documentation to carry out a simple task.\n\n**Note:** For the output generated by some of these packages to show up properly, you might need to change the output of your R Markdown document from `github_document` to `html_document` in the YAML of your R Markdown document.\n\n\nWhich package are you using? State the name of the package, whether it was on CRAN or GitHub, and include the code for loading it. Also include a one sentence description of what the package does.Then, do something with the package and provide a brief narrative including code and output. Also comment on difficulties you had, if any, figuring out how to use the package.\n\n\nPackages on CRAN\nThese packages can be installed with:\n\ninstall.packages(\"PACKAGENAME\")\n\n\n\n\nPackage\nDescription\n\n\n\n\ncowsay\nAllows printing of character strings as messages/warnings/etc. with ASCII animals, including cats, cows, frogs, chickens, ghosts, and more\n\n\nbabynames\nUS Baby Names 1880-2015\n\n\ndragracer\nThese are data sets for the hit TV show, RuPaul’s Drag Race. Data right now include episode-level data, contestant-level data, and episode-contestant-level data\n\n\ndatapasta\nRStudio addins and R functions that make copy-pasting vectors and tables to text painless\n\n\nDiagrammeR\nGraph/Network Visualization\n\n\njaneaustenr\nFull texts for Jane Austen’s 6 completed novels, ready for text analysis. These novels are “Sense and Sensibility”, “Pride and Prejudice”, “Mansfield Park”, “Emma”, “Northanger Abbey”, and “Persuasion”\n\n\nggimage\nSupports image files and graphic objects to be visualized in ‘ggplot2’ graphic system\n\n\ngganimate\nCreate easy animations with ggplot2\n\n\ngt\nEasily Create Presentation-Ready Display Tables\n\n\nleaflet\nCreate Interactive Web Maps with the JavaScript ‘Leaflet’ Library\n\n\npraise\nBuild friendly R packages that praise their users if they have done something good, or they just need it to feel better\n\n\nplotly\nCreate interactive web graphics from ggplot2 graphs and/or a custom interface to the JavaScript library plotly.js inspired by the grammar of graphics\n\n\nsuncalc\nR interface to suncalc.js library, part of the SunCalc.net project, for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), moon position and lunar phase for the given location and time\n\n\nschrute\nThe complete scripts from the American version of the Office television show in tibble format\n\n\nstatebins\nThe cartogram heatmaps generated by the included methods are an alternative to choropleth maps for the United States and are based on work by the Washington Post graphics department in their report on “The states most threatened by trade”\n\n\nttbbeer\nAn R data package of beer statistics from U.S. Department of the Treasury, Alcohol and Tobacco Tax and Trade Bureau (TTB)\n\n\nukbabynames\nFull listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994\n\n\n\n\n\nPackages on GitHub only\nThese packages can be installed with:\n\nlibrary(devtools)\ninstall_github(\"USERNAME/PACKAGENAME\")\n\nUSERNAME refers to the user name of the developer of the package. For example, for the first package listed below, USERNAME is hadley and PACKAGENAME is emo.\n\n\n\nPackage\nDescription\n\n\n\n\nbingo\nGenerate Bingo cards\n\n\nBRRR\nBRRR extends the beepr package to include a number of rap adlibs\n\n\nCatterPlots\nPlots with Cats\n\n\ncooking\nChopping, peeling, frying, and cooking various ingredients, and combining them to a delicious ragout. Also includes buying them from a local supermarket\n\n\ndadjoke\nThe goal of dadjoke is to make you laugh in spite of yourself\n\n\nemo\nThe goal of emo(ji) is to make it very easy to insert emoji into RMarkdown documents\n\n\nemoGG\nUse Emoji in ggplot2\n\n\nemokid\nFor those times when you’re having trouble expressing how you feel about your broken code\n\n\nflametree\nThe goal of flametree is to make pretty pictures\n\n\nggbarf\nMake isotype bars using the vomit emoji\n\n\nggCyberPunk\nCreate Cyberpunk area and line plots\n\n\nggiraph\nCreate interactive ggplot2 graphics using htmlwidgets\n\n\nggkeyboard\nPlot a Keyboard Using ggplot2\n\n\njasmines\nMake generative art\n\n\nkandinsky\nTurn any dataset into a Kandinsky painting\n\n\nlego\nThis R data package contains information about every Lego set manufactured from 1970 to 2015, a total of 6172 sets\n\n\nlinkinpark\nData package that contains a few different datasets about the band\n\n\nprenoms\nFirst names given to babies in metropolitan France between 1900 and 2015\n\n\nraybonsai\nGenerate 3D procedural trees in R, rendered with rayrender! Procedural generation code based on the flametree package by Danielle Navarro.\n\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSC 223: Introduction to Data Science",
    "section": "",
    "text": "Day\nDate\nTopic\nPrepare\nSlides\nAE\nLab\nHW\nExam\nProject\n\n\n\n\n1\nMon, Sep 26\nLab 0 - Meet + greet\n\n🖥️\n\n💻\n\n\n\n\n\n2\nTue, Sep 27\n\n\n\n\n\n\n\n\n\n\n3\nWed, Sep 28\n\n\n\n\n\n\n\n\n\n\n4\nThu, Sep 29\n\n\n\n\n\n\n\n\n\n\n5\nFri, Sep 30\n\n\n\n\n\n\n\n\n\n\n6\nMon, Oct 3\n\n\n\n\n\n\n\n\n\n\n7\nTue, Oct 4\n\n\n\n\n\n\n\n\n\n\n8\nWed, Oct 5\n\n\n\n\n\n\n\n\n\n\n9\nThu, Oct 6\n\n\n\n\n\n\n\n\n\n\n10\nFri, Oct 7\n\n\n\n\n\n\n\n\n\n\n11\nMon, Oct 10\n\n\n\n\n\n\n\n\n\n\n12\nTues, Oct 11\n\n\n\n\n\n\n\n\n\n\n13\nWed, Oct 12\n\n\n\n\n\n\n\n\n\n\n14\nThu, Oct 13\n\n\n\n\n\n\n\n\n\n\n15\nFri, Oct 14\n\n\n\n\n\n\n\n\n\n\n16\nMon, Oct 17\n\n\n\n\n\n\n\n\n\n\n17\nTue, Oct 18\n\n\n\n\n\n\n\n\n\n\n18\nWed, Oct 19"
  },
  {
    "objectID": "labs/lab-01/lab-01-hello-r.html",
    "href": "labs/lab-01/lab-01-hello-r.html",
    "title": "Lab 01 - Hello R!",
    "section": "",
    "text": "R is the name of the programming language itself and RStudio is a convenient interface.\nThe main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\nAn additional goal is to introduce you to Git and GitHub, which is the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nAnd to make versioning simpler, this is a solo lab. Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel. In future labs you’ll learn about collaborating on GitHub and produce a single lab report for your team."
  },
  {
    "objectID": "labs/lab-01/lab-01-hello-r.html#warm-up",
    "href": "labs/lab-01/lab-01-hello-r.html#warm-up",
    "title": "Lab 01 - Hello R!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for \"YAML Ain't Markup Language\". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\nYAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.\n\n\n\n\n\n\n\nCommitting changes\nGo to the Git pane in your RStudio (top right) and click on Commit. This will bring up a new menu.\n\n\n\n\n\nIf you have made changes to your Rmd file (which you just changed your name), you should see it list on of the left. Diff shows you the difference between the last committed state of the document and its current state that includes your changes. Look over the files in the box that say they have been change. If agree with these changes, you will need to check the box to the left of each changed file, and in this case, write “Update author name” in the Commit message box. Then click Commit. It is important that you always describe what changes were made since your last commit in that box. This is how people in your team know what you changed without having to review thousands of lines of code.\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the block progresses we will let you make these decisions. Committing does not save your progress to the web.\n\n\nPushing changes\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean whoever you are working with.\nIn order to push your changes to GitHub, click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password, then your PAT. This might feel cumbersome. Bear with me… We will teach you how to save your password so you don’t have to enter it every time. But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it."
  },
  {
    "objectID": "labs/lab-01/lab-01-hello-r.html#packages",
    "href": "labs/lab-01/lab-01-hello-r.html#packages",
    "title": "Lab 01 - Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with two more packages: datasauRus which contains the dataset we’ll be using and tidyverse which is a collection of packages for doing data analysis in a “tidy” way. These packages are already installed for you. You can load the packages by running the following in the Console.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\nNote that the packages are also loaded with the same commands in your R Markdown document."
  },
  {
    "objectID": "labs/lab-01/lab-01-hello-r.html#data",
    "href": "labs/lab-01/lab-01-hello-r.html#data",
    "title": "Lab 01 - Hello R!",
    "section": "Data",
    "text": "Data\n\nIf it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone! Have you heard of a [baker's dozen](https://en.wikipedia.org/wiki/Dozen#Baker's_dozen)?\n\nThe data frame we will be working with today is called datasaurus_dozen and it’s in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable.\nTo find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console."
  },
  {
    "objectID": "labs/lab-02/lab-02-plastic-waste.html",
    "href": "labs/lab-02/lab-02-plastic-waste.html",
    "title": "Lab 02 - Global plastic waste",
    "section": "",
    "text": "Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health. Our World in Data has a lot of great data at various levels including globally, per country, and over time. For this lab we focus on data from 2010.\nAdditionally, National Geographic ran a data visualization communication contest on plastic waste as seen here."
  },
  {
    "objectID": "labs/lab-02/lab-02-plastic-waste.html#packages",
    "href": "labs/lab-02/lab-02-plastic-waste.html#packages",
    "title": "Lab 02 - Global plastic waste",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for this analysis. Run the following code in the Console to load this package.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/lab-02/lab-02-plastic-waste.html#data",
    "href": "labs/lab-02/lab-02-plastic-waste.html#data",
    "title": "Lab 02 - Global plastic waste",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following.\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html",
    "href": "labs/lab-03/lab-03-nobel-laureates.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article on why Nobel laureates show immigration is so important for American science. You can read the article here. In the article they show that while most living Nobel laureates in the sciences are based in the US, many of them were born in other countries. This is one reason why scientific leaders say that immigration is vital for progress. In this lab we will work with the data from this article to recreate some of their visualizations as well as explore new questions."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "title": "Lab 03 - Nobel laureates",
    "section": "Merges and merge conflicts",
    "text": "Merges and merge conflicts\nThis is the second week you’re working in teams, so we’re going to make things a little more interesting and let all of you make changes and push those changes to your team repository. Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts. So our first task today is to walk you through a merge conflict!\n\nPushing to a repo replaces the code on GitHub with the code you have on your computer.\nIf a collaborator has made a change to your repo on GitHub that you haven’t incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator’s work!\nSo you need to explicitly “merge” your collaborator’s work before you can push.\nIf your and your collaborator’s changes are in different files or in different parts of the same file, git merges the work for you automatically when you *pull*.\nIf you both changed the same part of a file, git will produce a **merge conflict** because it doesn’t know how which change you want to keep and which change you want to overwrite.\n\nGit will put conflict markers in your code that look like:\n<<<<<<< HEAD \n\nSee also: [dplyr documentation](https://dplyr.tidyverse.org/)   \n\n======= \n\nSee also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  \n\n>>>>>>> some1alpha2numeric3string4\nThe ===s separate your changes (top) from their changes (bottom).\nNote that on top you see the word HEAD, which indicates that these are your changes.\nAnd at the bottom you see some1alpha2numeric3string4 (well, it probably looks more like 28e7b2ceb39972085a0860892062810fb812a08f).\nThis is the hash (a unique identifier) of the commit your collaborator made with the conflicting change.\nYour job is to reconcile the changes: edit the file so that it incorporates the best of both versions and delete the <<<, ===, and >>> lines. Then you can stage and commit the result."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#setup",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#setup",
    "title": "Lab 03 - Nobel laureates",
    "section": "Setup",
    "text": "Setup\n\nClone the repo and open the .Rmd file.\nAssign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "title": "Lab 03 - Nobel laureates",
    "section": "Let’s cause a merge conflict!",
    "text": "Let’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: everyone should have the repo cloned and know which role number(s) they are.\nRole 1:\n\nChange the team name to your actual team name.\nKnit, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange the team name to some other word.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nKnit.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nChange the a label of the first code chunk\nKnit, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nChange the label of the first code chunk to something other than previous role did.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Commit, and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "title": "Lab 03 - Nobel laureates",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (commit and push) before continuing your work. Never do new work while resolving a merge conflict.\nKnit, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#warm-up",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#warm-up",
    "title": "Lab 03 - Nobel laureates",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#packages",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#packages",
    "title": "Lab 03 - Nobel laureates",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#data",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSv (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nThe variable descriptions are as follows:\n\nid: ID number\nfirstname: First name of laureate\nsurname: Surname\nyear: Year prize won\ncategory: Category of prize\naffiliation: Affiliation of laureate\ncity: City of laureate in prize year\ncountry: Country of laureate in prize year\nborn_date: Birth date of laureate\ndied_date: Death date of laureate\ngender: Gender of laureate\nborn_city: City where laureate was born\nborn_country: Country where laureate was born\nborn_country_code: Code of country where laureate was born\ndied_city: City where laureate died\ndied_country: Country where laureate died\ndied_country_code: Code of country where laureate died\noverall_motivation: Overall motivation for recognition\nshare: Number of other winners award is shared with\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix `_original`.\n\nborn_country_original: Original country where laureate was born\nborn_city_original: Original city where laureate was born\ndied_country_original: Original country where laureate died\ndied_city_original: Original city where laureate died\ncity_original: Original city where laureate lived at the time of winning the award\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\n\n\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code.\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 03 - Nobel laureates",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nNote that we can achieve the same result using the `fct_other()` function we've seen before (i.e. with `country_us = fct_other(country, \"USA\")`). We decided to use the `if_else()` here to show you one example of an if statement in R.\n\n\nnobel_living <- nobel_living %>%\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science <- nobel_living %>%\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the next exercise work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your R Markdown document, even though the next exercise doesn’t explicitly ask you to do so.\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.d"
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 03 - Nobel laureates",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\n**Hint:** You should be able to ~~cheat~~ borrow from code you used earlier to create the `country_us` variable.\n\n\nCreate a new variable called born_country_us that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Based on your visualization, do the data appear to support Buzzfeed’s claim? Explain your reasoning in 1-2 sentences.\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be a bar for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "href": "labs/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "title": "Lab 03 - Nobel laureates",
    "section": "Here’s where those immigrant Nobelists were born",
    "text": "Here’s where those immigrant Nobelists were born\n\nNote that your bar plot won't exactly match the one from the Buzzfeed article. This is likely because the data has been updated since the article was published.\n\n\nIn a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work.\nNow go back through your write up to make sure you’ve answered all questions and all of your R chunks are properly labelled. Once you decide as a team that you’re done with this lab, all members of the team should pull the changes and knit the R Markdown document to confirm that they can reproduce the report."
  },
  {
    "objectID": "labs/lab-04/lab-04-viz-sp-data.html",
    "href": "labs/lab-04/lab-04-viz-sp-data.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "",
    "text": "Have you ever taken a road trip in the US and thought to yourself “I wonder what La Quinta means”. Well, the late comedian Mitch Hedberg thinks it’s Spanish for next to Denny’s.\nIf you’re not familiar with these two establishments, Denny’s is a casual diner chain that is open 24 hours and La Quinta Inn and Suites is a hotel chain.\nThese two establishments tend to be clustered together, or at least this observation is a joke made famous by Mitch Hedberg. In this lab we explore the validity of this joke and along the way learn some more data wrangling and tips for visualizing spatial data.\nThe inspiration for this lab comes from a blog post by John Reiser on his new jersey geographer blog. You can read that analysis here. Reiser’s blog post focuses on scraping data from Denny’s and La Quinta Inn and Suites websites using Python. In this lab we focus on visualization and analysis of these data. However note that the data scraping was also done in R, and we we will discuss web scraping using R later in the course. But for now we focus on the data that has already been scraped and tidied for you."
  },
  {
    "objectID": "labs/lab-04/lab-04-viz-sp-data.html#warm-up",
    "href": "labs/lab-04/lab-04-viz-sp-data.html#warm-up",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-04/lab-04-viz-sp-data.html#packages",
    "href": "labs/lab-04/lab-04-viz-sp-data.html#packages",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "labs/lab-04/lab-04-viz-sp-data.html#data",
    "href": "labs/lab-04/lab-04-viz-sp-data.html#data",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Data",
    "text": "Data\nThe datasets we’ll use are called dennys and laquinta from the dsbox package. Note that these data were scraped from here and here, respectively.\nSince the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here.\nTo help with our analysis we will also use a dataset on US states, which is located in your repository’s data folder.\n\nstates <- read_csv(\"data/states.csv\")\n\nEach observation in this dataset represents a state, including DC. Along with the name of the state we have the two-letter abbreviation and we have the geographic area of the state (in square miles)."
  },
  {
    "objectID": "labs/lab-05/lab-05-wrangle-sp-data.html",
    "href": "labs/lab-05/lab-05-wrangle-sp-data.html",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the Denny’s and La Quinta Inn and Suites data we visualized in the previous lab."
  },
  {
    "objectID": "labs/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "href": "labs/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-05/lab-05-wrangle-sp-data.html#packages",
    "href": "labs/lab-05/lab-05-wrangle-sp-data.html#packages",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "labs/lab-05/lab-05-wrangle-sp-data.html#data",
    "href": "labs/lab-05/lab-05-wrangle-sp-data.html#data",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Data",
    "text": "Data\nRemember that the datasets we’ll use are called dennys and laquinta from the dsbox package. Since the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here."
  },
  {
    "objectID": "labs/lab-06/lab-06-sad-plots.html",
    "href": "labs/lab-06/lab-06-sad-plots.html",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "",
    "text": "Given below are two data visualizations that violate many data visualization best practices. Improve these visualizations using R and the tips for effective visualizations that we introduced in class. You should produce one visualization per dataset. Your visualization should be accompanied by a brief paragraph describing the choices you made in your improvement, specifically discussing what you didn’t like in the original plots and why, and how you addressed them in the visualization you created.\nOn the due date you will give a brief presentation describing one of your improved visualizations and the reasoning for the choices you made."
  },
  {
    "objectID": "labs/lab-06/lab-06-sad-plots.html#warm-up",
    "href": "labs/lab-06/lab-06-sad-plots.html#warm-up",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-06/lab-06-sad-plots.html#packages",
    "href": "labs/lab-06/lab-06-sad-plots.html#packages",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "labs/lab-06/lab-06-sad-plots.html#data",
    "href": "labs/lab-06/lab-06-sad-plots.html#data",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Data",
    "text": "Data\nThe datasets we’ll use are called instructors and fisheries from the dsbox package. Since the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?instructors and ?fisheries in the Console or using the Help menu in RStudio to search for instructors or fisheries. You can also find this information here and here."
  },
  {
    "objectID": "labs/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "href": "labs/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Instructional staff employment trends",
    "text": "Instructional staff employment trends\nThe American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.\n\n\n\n\n\nLet’s start by loading the data used to create this plot.\n\nstaff <- read_csv(\"data/instructional-staff.csv\")\n\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n\n\n# A tibble: 5 x 12\n  facult~1 `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Full-Ti~   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8\n2 Full-Ti~   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6\n3 Full-Ti~   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1\n4 Part-Ti~   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1\n5 Graduat~   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4\n# ... with 1 more variable: `2011` <dbl>, and abbreviated variable name\n#   1: faculty_type\n\n\nIn order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year. In other words, we will convert the data from wide format to long format.\nBut before we do so, a thought exercise: How many rows will the long-format data have? It will have a row for each combination of year and faculty type. If there are 5 faculty types and 11 years of data, how many rows will we have?\nWe do the wide to long conversion using a new function: pivot_longer(). The animation below show how this function works, as well as its counterpart pivot_wider().\n\n\n\n\n\nThe function has the following arguments:\n\npivot_longer(data, cols, names_to = \"name\")\n\n\nThe first argument is data as usual.\nThe second argument, cols, is where you specify which columns to pivot into longer format – in this case all columns except for the faculty_type\nThe third argument, names_to, is a string specifying the name of the column to create from the data stored in the column names of data – in this case year\n\n\nstaff_long <- staff %>%\n  pivot_longer(cols = -faculty_type, names_to = \"year\") %>%\n  mutate(year = as.numeric(year))\n\nLet’s take a look at what the new longer data frame looks like.\n\nstaff_long\n\n# A tibble: 55 x 3\n   faculty_type               year value\n   <chr>                     <dbl> <dbl>\n 1 Full-Time Tenured Faculty  1975  29  \n 2 Full-Time Tenured Faculty  1989  27.6\n 3 Full-Time Tenured Faculty  1993  25  \n 4 Full-Time Tenured Faculty  1995  24.8\n 5 Full-Time Tenured Faculty  1999  21.8\n 6 Full-Time Tenured Faculty  2001  20.3\n 7 Full-Time Tenured Faculty  2003  19.3\n 8 Full-Time Tenured Faculty  2005  17.8\n 9 Full-Time Tenured Faculty  2007  17.2\n10 Full-Time Tenured Faculty  2009  16.8\n# ... with 45 more rows\n\n\nAnd now let’s plot is as a line plot. A possible approach for creating a line plot where we color the lines by faculty type is the following:\n\nstaff_long %>%\n  ggplot(aes(x = year, y = value, color = faculty_type)) +\n  geom_line()\n\n\n\n\nBut note that this results in a message as well as an unexpected plot. The message is saying that there is only one observation for each faculty type year combination. We can fix this using the group aesthetic following.\n\nstaff_long %>%\n  ggplot(aes(x = year, y = value, group = faculty_type, color = faculty_type)) +\n  geom_line()\n\n\n\n\n\nInclude the line plot you made above in your report and make sure the figure width is large enough to make it legible. Also fix the title, axis labels, and legend label.\nSuppose the objective of this plot was to show that the proportion of part-time faculty have gone up over time compared to other instructional staff types. What changes would you propose making to this plot to tell this story and why.\nImplement the changes you proposed in the previous exercise.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-06/lab-06-sad-plots.html#fisheries",
    "href": "labs/lab-06/lab-06-sad-plots.html#fisheries",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Fisheries",
    "text": "Fisheries\nFisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries. This Wikipedia page lists fishery production of countries for 2016. For each country tonnage from capture and aquaculture are listed. Note that countries whose total harvest was less than 100,000 tons are not included in the visualization.\nA researcher shared with you the following visualization they created based on these data. 😳\n\n\n\n\n\n\nCan you help them make improve it? First, brainstorm how you would improve it. Then create the improved visualization and write up the changes/decisions you made as bullet points. It’s ok if some of your improvements are aspirational, i.e. you don’t know how to implement it, but you think it’s a good idea.\n\nLoad the data.\n\nfisheries <- read_csv(\"data/fisheries.csv\")\n\n\nCreate a new data visualisation for these data that implements the improvements you proposed in the previous exercise (or many of them as you can).\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "labs/lab-07/lab-07-simpsons-paradox.html",
    "href": "labs/lab-07/lab-07-simpsons-paradox.html",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "",
    "text": "A study of conducted in Whickham, England recorded participants’ age, smoking status at baseline, and then 20 years later recorded their health outcome. In this lab we analyse the relationships between these variables, first two at a time, and then controlling for the third."
  },
  {
    "objectID": "labs/lab-07/lab-07-simpsons-paradox.html#warm-up",
    "href": "labs/lab-07/lab-07-simpsons-paradox.html#warm-up",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-07/lab-07-simpsons-paradox.html#packages",
    "href": "labs/lab-07/lab-07-simpsons-paradox.html#packages",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the mosaicData package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(mosaicData)"
  },
  {
    "objectID": "labs/lab-07/lab-07-simpsons-paradox.html#data",
    "href": "labs/lab-07/lab-07-simpsons-paradox.html#data",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Data",
    "text": "Data\nThe dataset we’ll use is called Whickham from the mosaicData package. You can find out more about the dataset by inspecting their documentation, which you can access by running ?Whickham in the Console or using the Help menu in RStudio to search for Whickham."
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html",
    "href": "labs/lab-08/lab-08-uoe-art.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "The University of Edinburgh Art Collection “supports the world-leading research and teaching that happens within the University. Comprised of an astonishing range of objects and ideas spanning two millennia and a multitude of artistic forms, the collection reflects not only the long and rich trajectory of the University, but also major national and international shifts in art history.”1.\nIn this lab we’ll scrape data on all art pieces in the Edinburgh College of Art collection."
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "href": "labs/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "R scripts vs. R Markdown documents",
    "text": "R scripts vs. R Markdown documents\nToday we will be using both R scripts and R Markdown documents:\n\n.R: R scripts are plain text files containing only code and brief comments,\n\nWe’ll use R scripts in the web scraping stage and ultimately save the scraped data as a csv.\n\n.Rmd: R Markdown documents are plain text files containing.\n\nWe’ll use an R Markdown document in the web analysis stage, where we start off by reading in the csv file we wrote out in the scraping stage.\n\n\nHere is the organization of your repo, and the corresponding section in the lab that each file will be used for:"
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#warm-up",
    "href": "labs/lab-08/lab-08-uoe-art.html#warm-up",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#packages",
    "href": "labs/lab-08/lab-08-uoe-art.html#packages",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we’re allowed to scrape the data, the rvest package for data scraping. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(robotstxt)\nlibrary(rvest)"
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#data",
    "href": "labs/lab-08/lab-08-uoe-art.html#data",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you’ll be scraping the data! But before doing so, let’s check that a bot has permissions to access pages on this domain.\n\npaths_allowed(\"https://collections.ed.ac.uk/art)\")\n\n\n collections.ed.ac.uk                      \n\n\n[1] TRUE"
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "href": "labs/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Scraping a single page",
    "text": "Scraping a single page\n\n**Tip:** To run the code you can highlight or put your cursor next to the lines of code you want to run and hit Command+Enter.\n\n\nWork in scripts/01-scrape-page-one.R.\n\nWe will start off by scraping data on the first 10 pieces in the collection from here.\nFirst, we define a new object called first_url, which is the link above. Then, we read the page at this url with the read_html() function from the rvest package. The code for this is already provided in 01-scrape-page-one.R.\n\n# set url\nfirst_url <- \"https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0\"\n\n# read html page\npage <- read_html(first_url)\n\nFor the ten pieces on this page we will extract title, artist, and link information, and put these three variables in a data frame.\n\nTitles\nLet’s start with titles. We make use of the SelectorGadget to identify the tags for the relevant nodes:\n\n\n\n\n\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\")\n\n{xml_nodeset (10)}\n [1] <a href=\"./record/99399?highlight=*:*\">Untitled - Girl with Crows        ...\n [2] <a href=\"./record/20533?highlight=*:*\">The Three Tyches                  ...\n [3] <a href=\"./record/22683?highlight=*:*\">Masked Divers                     ...\n [4] <a href=\"./record/20755?highlight=*:*\">A Good Dream and a Bad Dream      ...\n [5] <a href=\"./record/50392?highlight=*:*\">Unknown                           ...\n [6] <a href=\"./record/99889?highlight=*:*\">Untitled                          ...\n [7] <a href=\"./record/99480?highlight=*:*\">Untitled - Portrait of an Old Man ...\n [8] <a href=\"./record/22706?highlight=*:*\">(verso)                           ...\n [9] <a href=\"./record/21256?highlight=*:*\">Portrait                          ...\n[10] <a href=\"./record/99894?highlight=*:*\">Untitled                          ...\n\n\nThen we extract the text with html_text():\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text()\n\n [1] \"Untitled - Girl with Crows                                                                            (1961-1962)\"      \n [2] \"The Three Tyches                                    \"                                                                   \n [3] \"Masked Divers                                    \"                                                                      \n [4] \"A Good Dream and a Bad Dream                                                                            (1970)\"         \n [5] \"Unknown                                                                            (1950)\"                              \n [6] \"Untitled                                                                            (2007)\"                             \n [7] \"Untitled - Portrait of an Old Man                                                                            (Feb 1962)\"\n [8] \"(verso)                                                                            (1953)\"                              \n [9] \"Portrait                                                                            (1956)\"                             \n[10] \"Untitled                                                                            (2007)\"                             \n\n\nAnd get rid of all the spurious white space in the text with str_squish(), which reduces repeated whitespace inside a string.\n\nTake a look at the help for `str_squish()` to find out more about how it works and how it's different from `str_trim()`.\n\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text() %>%\n  str_squish()\n\n [1] \"Untitled - Girl with Crows (1961-1962)\"      \n [2] \"The Three Tyches\"                            \n [3] \"Masked Divers\"                               \n [4] \"A Good Dream and a Bad Dream (1970)\"         \n [5] \"Unknown (1950)\"                              \n [6] \"Untitled (2007)\"                             \n [7] \"Untitled - Portrait of an Old Man (Feb 1962)\"\n [8] \"(verso) (1953)\"                              \n [9] \"Portrait (1956)\"                             \n[10] \"Untitled (2007)\"                             \n\n\nAnd finally save the resulting data as a vector of length 10:\n\ntitles <- page %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text() %>%\n  str_squish()\n\n\n\nLinks\nThe same nodes that contain the text for the titles also contains information on the links to individual art piece pages for each title. We can extract this information using a new function from the rvest package, html_attr(), which extracts attributes.\nA mini HTML lesson! The following is how we define hyperlinked text in HTML:\n<a href=\"https://www.google.com\">Seach on Google</a>\nAnd this is how the text would look like on a webpage: Seach on Google.\nHere the text is Seach on Google and the href attribute contains the url of the website you’d go to if you click on the hyperlinked text: https://www.google.com.\nThe moral of the story is: the link is stored in the href attribute.\n\npage %>%\n  html_nodes(\".iteminfo\") %>%   # same nodes\n  html_node(\"h3 a\") %>%         # as before\n  html_attr(\"href\")             # but get href attribute instead of text\n\n [1] \"./record/99399?highlight=*:*\" \"./record/20533?highlight=*:*\"\n [3] \"./record/22683?highlight=*:*\" \"./record/20755?highlight=*:*\"\n [5] \"./record/50392?highlight=*:*\" \"./record/99889?highlight=*:*\"\n [7] \"./record/99480?highlight=*:*\" \"./record/22706?highlight=*:*\"\n [9] \"./record/21256?highlight=*:*\" \"./record/99894?highlight=*:*\"\n\n\nThese don’t really look like URLs as we know then though. They’re relative links.\n\nSee the help for `str_replace()` to find out how it works. Remember that the first argument is passed in from the pipeline, so you just need to define the `pattern` and `replacement` arguments.\n\n\nClick on one of art piece titles in your browser and take note of the url of the webpage it takes you to. Think about how that url compares to what we scraped above? How is it different? Using str_replace(), fix the URLs. You’ll note something special happening in the pattern to replace. We want to replace the ., but we have it as \\\\.. This is because the period . is a special character and so we need to escape it first with backslashes, \\\\s.\n\n\n\nArtists\n\nFill in the blanks to scrape artist names.\n\n\n\nPut it altogether\n\nFill in the blanks to organize everything in a tibble.\n\n\n\nScrape the next page\n\nClick on the next page, and grab its url. Fill in the blank in to define a new object: second_url. Copy-paste code from top of the R script to scrape the new set of art pieces, and save the resulting data frame as second_ten.\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#functions",
    "href": "labs/lab-08/lab-08-uoe-art.html#functions",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Functions",
    "text": "Functions\n\nWork in scripts/02-scrape-page-function.R.\n\nYou’ve been using R functions, now it’s time to write your own!\nLet’s start simple. Here is a function that takes in an argument x, and adds 2 to it.\n\nadd_two <- function(x){\n  x + 2\n}\n\nLet’s test it:\n\nadd_two(3)\n\n[1] 5\n\nadd_two(10)\n\n[1] 12\n\n\nThe skeleton for defining functions in R is as follows:\n\nfunction_name <- function(input){\n  # do something with the input(s)\n  # return something\n}\n\nThen, a function for scraping a page should look something like:\n\n**Reminder:** Function names should be short but evocative verbs.\n\n\nfunction_name <- function(url){\n  # read page at url\n  # extract title, link, artist info for n pieces on page\n  # return a n x 3 tibble\n}\n\n\nFill in the blanks using code you already developed in the previous exercises. Name the function scrape_page.\n\nTest out your new function by running the following in the console. Does the output look right? Discuss with teammates whether you’re getting the same results as before.\n\nscrape_page(first_url)\nscrape_page(second_url)\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#iteration",
    "href": "labs/lab-08/lab-08-uoe-art.html#iteration",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Iteration",
    "text": "Iteration\n\nWork in scripts/03-scrape-page-many.R.\n\nWe went from manually scraping individual pages to writing a function to do the same. Next, we will work on making our workflow a little more efficient by using R to iterate over all pages that contain information on the art collection.\n\n**Reminder:** The collection has 2970 pieces in total.\n\nThat means we give develop a list of URLs (of pages that each have 10 art pieces), and write some code that applies the scrape_page() function to each page, and combines the resulting data frames from each page into a single data frame with 2970 rows and 3 columns.\n\nList of URLs\nClick through the first few of the pages in the art collection and observe their URLs to confirm the following pattern:\n[sometext]offset=0     # Pieces 1-10\n[sometext]offset=10    # Pieces 11-20\n[sometext]offset=20    # Pieces 21-30\n[sometext]offset=30    # Pieces 31-40\n...\n[sometext]offset=2960  # Pieces 2961-2970\nWe can construct these URLs in R by pasting together two pieces: (1) a common (root) text for the beginning of the URL, and (2) numbers starting at 0, increasing by 10, all the way up to 2970. Two new functions are helpful for accomplishing this: glue() for pasting two pieces of text and seq() for generating a sequence of numbers.\n\nFill in the blanks to construct the list of URLs.\n\n\n\nMapping\nFinally, we’re ready to iterate over the list of URLs we constructed. We will do this by mapping the function we developed over the list of URLs. There are a series of mapping functions in R (which we’ll learn about in more detail tomorrow), and they each take the following form:\nmap([x], [function to apply to each element of x])\nIn our case x is the list of URLs we constructed and the function to apply to each element of x is the function we developed earlier, scrape_page. And as a result we want a data frame, so we use map_dfr function:\n\nmap_dfr(urls, scrape_page)\n\n\nFill in the blanks to scrape all pages, and to create a new data frame called uoe_art.\n\n\n\nWrite out data\n\nFinally write out the data frame you constructed into the data folder so that you can use it in the analysis section.\n\n\nAim to make it to this point during the workshop.\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-08/lab-08-uoe-art.html#analysis",
    "href": "labs/lab-08/lab-08-uoe-art.html#analysis",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Analysis",
    "text": "Analysis\n\nWork in lab-08.Rmd for the rest of the lab.\n\nNow that we have a tidy dataset that we can analyze, let’s do that!\nWe’ll start with some data cleaning, to clean up the dates that appear at the end of some title text in parentheses. Some of these are years, others are more specific dates, some art pieces have no date information whatsoever, and others have some non-date information in parentheses. This should be interesting to clean up!\nFirst thing we’ll try is to separate the title column into two: one for the actual title and the other for the date if it exists. In human speak, we need to\n\n“separate the title column at the first occurrence of ( and put the contents on one side of the ( into a column called title and the contents on the other side into a column called date”\n\nLuckily, there’s a function that does just this: separate()!\nAnd once we have completed separating the single title column into title and date, we need to do further clean-up in the date column to get rid of extraneous )s with str_remove(), capture year information, and save the data as a numeric variable.\n\n**Hint:** Remember escaping special characters from yesterday's lecture? You'll need to use that trick again.\n\n\nFill in the blanks in to implement the data wrangling we described above. Note that this will result in some warnings when you run the code, and that’s OK! Read the warnings, and explain what they mean, and why we are ok with leaving them in given that our objective is to just capture year where it’s convenient to do so.\nPrint out a summary of the data frame using the skim() function. How many pieces have artist info missing? How many have year info missing?\nMake a histogram of years. Use a reasonable binwidth. Do you see anything out of the ordinary?\n\n\n**Hint:** You'll want to use `mutate()` and `if_else()` or `case_when()` to implement the correction.\n\n\nFind which piece has the out of the ordinary year and go to its page on the art collection website to find the correct year for it. Can you tell why our code didn’t capture the correct year information? Correct the error in the data frame and visualize the data again.\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nWho is the most commonly featured artist in the collection? Do you know them? Any guess as to why the university has so many pieces from them?\n\n\n**Hint:** `str_subset()` can be helful here. You should consider how you might capture titles where the word appears as \"child\" and \"Child\".\n\n\nFinal question! How many art pieces have the word “child” in their title? Try to figure it out, and ask for help if you’re stuck.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "labs/lab-09/lab-09-better-viz.html",
    "href": "labs/lab-09/lab-09-better-viz.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "In this lab our goal is to reconstruct and improve a data visualisation on COVID and mask wearing."
  },
  {
    "objectID": "labs/lab-09/lab-09-better-viz.html#warm-up",
    "href": "labs/lab-09/lab-09-better-viz.html#warm-up",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-09/lab-09-better-viz.html#packages",
    "href": "labs/lab-09/lab-09-better-viz.html#packages",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/lab-09/lab-09-better-viz.html#data",
    "href": "labs/lab-09/lab-09-better-viz.html#data",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Data",
    "text": "Data\nIn this lab you’ll construct the dataset!"
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html",
    "href": "labs/lab-10/lab-10-slr-course-evals.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, “Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity” (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings. (Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. http://www.sciencedirect.com/science/article/pii/S0272775704001165.)\nIn this lab you will analyze the data from this study in order to learn what goes into a positive professor evaluation.\nThe data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors’ physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors."
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html#warm-up",
    "href": "labs/lab-10/lab-10-slr-course-evals.html#warm-up",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html#packages",
    "href": "labs/lab-10/lab-10-slr-course-evals.html#packages",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html#data",
    "href": "labs/lab-10/lab-10-slr-course-evals.html#data",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called evals. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "href": "labs/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nVisualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.\nVisualize and describe the relationship between score and bty_avg.\n\n\n**Hint:** See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.\n\n\nRecreate the scatterplot from Exercise 2, but this time use\ngeom_jitter()? What does “jitter” mean? What was misleading about the initial scatterplot?\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "href": "labs/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a numerical predictor",
    "text": "Linear regression with a numerical predictor\n\nLinear model is in the form $\\hat{y} = b_0 + b_1 x$.\n\n\nLet’s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called score_bty_fit to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.\nRecreate the scatterplot from Exercise 2, and add the regression line to this plot in orange colour, with shading for the uncertainty of the line turned off.\nInterpret the slope of the linear model in context of the data.\nInterpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.\nDetermine the \\(R^2\\) of the model and interpret it in context of the data.\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "href": "labs/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a categorical predictor",
    "text": "Linear regression with a categorical predictor\n\nFit a new linear model called score_gender_fit to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.\nWhat is the equation of the line corresponding to male professors? What is it for female professors?\nFit a new linear model called score_rank_fit to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.\nCreate a new variable called rank_relevel where \"tenure track\" is the baseline level.\nFit a new linear model called score_rank_relevel_fit to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 12. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\nCreate another new variable called tenure_eligible that labels \"teaching\" faculty as \"no\" and labels \"tenure track\" and \"tenured\" faculty as \"yes\".\nFit a new linear model called score_tenure_eligible_fit to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in the previous exercise. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "labs/lab-11/lab-11-mlr-course-evals.html",
    "href": "labs/lab-11/lab-11-mlr-course-evals.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the professor evaluations data we modelled in the previous lab. In the last lab we modelled evaluation scores using a single predictor at a time. This time we will use multiple predictors to model evaluation scores.\nFor context, review the previous lab’s introduction before continuing on to the exercises."
  },
  {
    "objectID": "labs/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "href": "labs/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-11/lab-11-mlr-course-evals.html#packages",
    "href": "labs/lab-11/lab-11-mlr-course-evals.html#packages",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "labs/lab-11/lab-11-mlr-course-evals.html#data",
    "href": "labs/lab-11/lab-11-mlr-course-evals.html#data",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called evals. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "labs/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "href": "labs/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nFit a linear model (one you have fit before): score_bty_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "labs/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "href": "labs/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nFit a linear model (one you have fit before): score_bty_gen_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\nInterpret the slopes and intercept of score_bty_gen_fit in context of the data.\nWhat percent of the variability in score is explained by the model score_bty_gen_fit.\nWhat is the equation of the line corresponding to just male professors?\nFor two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?\nHow does the relationship between beauty and evaluation score vary between male and female professors?\nHow do the adjusted \\(R^2\\) values of score_bty_gen_fit and score_bty_fit compare? What does this tell us about how useful gender is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.\nCompare the slopes of bty_avg under the two models (score_bty_fit and score_bty_gen_fit). Has the addition of gender to the model changed the parameter estimate (slope) for bty_avg?\nCreate a new model called score_bty_rank_fit with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html",
    "href": "labs/lab-12/lab-12-inference-smoking.html",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "",
    "text": "In 2004, the state of North Carolina released a large data set containing information on births recorded in this state. This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children. We will work with a random sample of observations from this data set."
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html#warm-up",
    "href": "labs/lab-12/lab-12-inference-smoking.html#warm-up",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html#packages",
    "href": "labs/lab-12/lab-12-inference-smoking.html#packages",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for inference, and the data lives in the openintro package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html#data",
    "href": "labs/lab-12/lab-12-inference-smoking.html#data",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called ncbirths. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?ncbirths in the Console or using the Help menu in RStudio to search for ncbirths. You can also find this information here."
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html#baby-weights",
    "href": "labs/lab-12/lab-12-inference-smoking.html#baby-weights",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weights",
    "text": "Baby weights\nA 1995 study suggests that average weight of Caucasian babies born in the US is 3,369 grams (7.43 pounds).1 In this dataset we only have information on mother’s race, so we will make the simplifying assumption that babies of Caucasian mothers are also Caucasian, i.e. whitemom = \"white\".\nWe want to evaluate whether the average weight of Caucasian babies has changed since 1995.\nOur null hypothesis should state “there is nothing going on”, i.e. no change since 1995: \\(H_0: \\mu = 7.43~pounds\\).\nOur alternative hypothesis should reflect the research question, i.e. some change since 1995. Since the research question doesn’t state a direction for the change, we use a two sided alternative hypothesis: \\(H_A: \\mu \\ne 7.43~pounds\\).\n\nCreate a filtered data frame called ncbirths_white that contain data only from white mothers. Then, calculate the mean of the weights of their babies.\nAre the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.\n\nLet’s discuss how this test would work. Our goal is to simulate a null distribution of sample means that is centred at the null value of 7.43 pounds. In order to do so, we\n\ntake a bootstrap sample of from the original sample,\ncalculate this bootstrap sample’s mean,\nrepeat these two steps a large number of times to create a bootstrap distribution of means centred at the observed sample mean,\nshift this distribution to be centred at the null value by subtracting / adding X to all bootstrap mean (X = difference between mean of bootstrap distribution and null value), and\ncalculate the p-value as the proportion of bootstrap samples that yielded a sample mean at least as extreme as the observed sample mean.\n\n\nRun the appropriate hypothesis test, visualize the null distribution, calculate the p-value, and interpret the results in context of the data and the hypothesis test."
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-smoking",
    "href": "labs/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-smoking",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weight vs. smoking",
    "text": "Baby weight vs. smoking\nConsider the possible relationship between a mother’s smoking habit and the weight of her baby. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.\n\nMake side-by-side boxplots displaying the relationship between habit and weight. What does the plot highlight about the relationship between these two variables?\nBefore moving forward, save a version of the dataset omitting observations where there are NAs for habit. You can call this version ncbirths_habitgiven.\n\nThe box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to first group the data by the habit variable, and then calculate the mean weight in these groups using.\n\nncbirths_habitgiven %>%\n  group_by(habit) %>%\n  summarise(mean_weight = mean(weight))\n\nThere is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test .\n\nWrite the hypotheses for testing if the average weights of babies born to smoking and non-smoking mothers are different.\nAre the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.\nRun the appropriate hypothesis test, calculate the p-value, and interpret the results in context of the data and the hypothesis test.\nConstruct a 95% confidence interval for the difference between the average weights of babies born to smoking and non-smoking mothers."
  },
  {
    "objectID": "labs/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-mothers-age",
    "href": "labs/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-mothers-age",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weight vs. mother’s age",
    "text": "Baby weight vs. mother’s age\nIn this portion of the analysis we focus on two variables. The first one is maturemom.\n\nFirst, a non-inference task: Determine the age cutoff for younger and mature mothers. Use a method of your choice, and explain how your method works.\n\nThe other variable of interest is lowbirthweight.\n\nConduct a hypothesis test evaluating whether the proportion of low birth weight babies is higher for mature mothers. State the hypotheses, verify the conditions, run the test and calculate the p-value, and state your conclusion in context of the research question. Use \\(\\alpha = 0.05\\). If you find a significant difference, construct a confidence interval, at the equivalent level to the hypothesis test, for the difference between the proportions of low birth weight babies between mature and younger mothers, and interpret this interval in context of the data."
  },
  {
    "objectID": "labs/lab-13/lab-13-work-on-projects.html",
    "href": "labs/lab-13/lab-13-work-on-projects.html",
    "title": "Lab 13 - Work on projects",
    "section": "",
    "text": "Remind yourself of the project assignment\nGo to the course organization on GitHub and clone your project repo titled project-TEAM_NAME\nAdd your project title and team name to the README.Rmd file in the repo and commit and push your changes. Observe that these are updated in the README of the repo.\nOpen the presentation.Rmd file, knit the document, and review the presentation format. This is where your presentation will go. Update the YAML with your project title, team name, etc. and commit and push your changes.\nGo to your project repo on GitHub, click on Settings on the top right corner, and scroll down to the section titled GiHub Pages. Under Source, select main branch and the root folder. This will give you a URL where the website for your project will be automatically built from the content in your README. This might take a few minutes.\n\nOnce the website is built, pull changes to your project in RStudio.\nTake a look at your rendered project website. Click on the link in the presentation section and you should be able to view the rendered slides. This is the link we will use to project your slides during the presentations.\nOn your repo you should see a text on top No description, website, or topics provided.. Next to it there’s an Edit button. Add a short description as well as the URL of your project website here.\nNote: This website is public, but your repository will remain private,unless… you as a team decide you would like to feature your repos in your personal GitHub profiles. If so, I will help you convert your repo to a public repo at the end of the semester. I will not add any marks to your repos so that your public work won’t contain your score for the project.\n\nAdd your dataset to the data folder and add your codebook to the README in that folder.\n\nIf in your proposal you were advised to update your codebook, make sure to make those updates.\nIf you had R scripts you used to scrape your data, add them to this folder as well.\n\nAdd the content from your proposal to the proposal.Rmd file in the proposal folder. Knit the document to make sure everything works and commit and push your proposal to your project repo.\n\nImportant: Your data now lives in a folder called data that is not inside your proposal folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function.\nYou don’t need to make further updates to your proposal at this point, even if your plans for the project change slightly.\n\nLoad your data in your presentation.Rmd, knit, and make sure everything works. Commit and push your updated proposal to your project repo.\n\nImportant: Same note as above! Your data now lives in a folder called data that is not inside your presentation folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function.\n\nNow that all the logistical details are done, start working on your project.\n\nOpen issues for things you want to accomplish. Assign them to specific team member(s) if you like. And as you complete the tasks, close the issues. You can also use the issues for discussion on the specific tasks.\n\nStrongly recommended: Get a hold of the instructor or a TA and run your ideas by them."
  },
  {
    "objectID": "labs/lab-14/lab-14-collaborating-on-github.html",
    "href": "labs/lab-14/lab-14-collaborating-on-github.html",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "",
    "text": "This week you’ll continue working on your projects. The first half of the workshop is structured, and you can use the second half to make progress on your projects."
  },
  {
    "objectID": "labs/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "href": "labs/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Opening an issue",
    "text": "Opening an issue\n\nGo to your project repo and open a new issue titled “Practice issue”.\nAdd the following text to the issue:\n\n\nThis is not a real issue. This is just some placeholder text.\n\nAnd the following is a bulleted to-do list:\n- [ ] Do this\n- [ ] Then that\n- [ ] And finally this\n\nHit preview to make sure the issue looks like the following:\n\n\n\n\n\n\n\nSubmit the issue.\nThen, assign the issue to one or few members of the team."
  },
  {
    "objectID": "labs/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "href": "labs/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Working on the issue",
    "text": "Working on the issue\nAs you work on the issue you can check the boxes.\n\n\n\n\n\nNote that this will also show progress on the issue on the issue dashboard.\n\n\n\n\n\n\nCheck some of the boxes on your practice issue and confirm that you can see the progress result on the issue dashboard."
  },
  {
    "objectID": "labs/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "href": "labs/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Closing the issue",
    "text": "Closing the issue\nOnce you’re done with an issue, you should close it. You can do this in one of two ways: on GitHub by clicking on Close issue or via a commit that directly addresses the issue. We’ll practice the second one. If you preface your commits with “Fixes”, “Fixed”, “Fix”, “Closes”, “Closed”, or “Close”, the issue will be closed when you push the changes to your repo.\n\nTake a note of the issue number, which will show up next to the issue title.\n\n\n\n\n\n\n\nGo to your project on RStudio and make a change. This can be something silly like adding a new line to the issue README. Then commit this change. In your commit message, use one of the special words listed above and reference the issue. For example, if the change I made was to add a new line to the README I would say something like the following:\n\n\nAdd a new line to the README, closes #2\n\n\n\n\n\n\nPush your changes and observe that the issue is now closed on GitHub. Click on the referenced commit to confirm that it was your last commit that closed the issue."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "DSC 223 - Fall 2022 - Block 2",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team’s project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you’re interested in potentially using for the final project. If you’re unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick “Start a new conversation”.\nMake the title “Your Team Name: Project Title”. For example, “Teaching Team: Our Awesome Presentation”.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click “Insert 1 item.” This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou’re done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group’s video, then click “Reply” to post a question for the group. You may not post a question that’s already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e. it shouldn’t be “Why did you use a bar plot instead of a pie chart”?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group’s specific presentation, i.e demonstrating that you’ve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-instructions_in_dev/project.html#data",
    "href": "project-instructions_in_dev/project.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nBelow are a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them. But you might find something interesting there:\n\nTidyTuesday\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland’s official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we’ll add here…"
  },
  {
    "objectID": "project-instructions_in_dev/project.html#deliverables",
    "href": "project-instructions_in_dev/project.html#deliverables",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal - due [ENTER DUE DATE]\nPresentation - due [ENTER DUE DATE]\nExecutive summary - due [ENTER DUE DATE]\n\n\nProposal\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset.\n\nSection 1 - Introduction: The introduction should introduce your general\nresearch question and your data (where it came from, how it was collected,\nwhat are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nThe outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)\nThe method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n3 pts\n\n\nProposal\n5 pts\n\n\nWorkflow, organization, code quality\n1 pt\n\n\nTeamwork\n1 pt\n\n\n\n\n\nPresentation\n5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop.\nPrepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\nPresentations will take place during the last workshop of the semester. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly.\nThe grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n50 pts\n\n\n\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use appropriate statistical procedures and interpretations of results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n10 pts\n\n\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n10 pts\n\n\n\n\n\nExecutive summary\nAlong with your presentation slides, we want you to provide a brief summary of your project in the README of your repository.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.\nThe executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nRepo organization\nThe following folders and files in your project repository:\n\npresentation.Rmd + presentation.html: Your presentation slides\nREADME.Rmd + README.md: Your write-up\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "project-instructions_in_dev/project.html#tips",
    "href": "project-instructions_in_dev/project.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou’re working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that’s fine Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nSet aside time to work together and apart (physically).\nWhen you’re done, review the documents on GitHub to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-instructions_in_dev/project.html#marking",
    "href": "project-instructions_in_dev/project.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal\n10 pts\n\n\nPresentation\n50 pts\n\n\nExecutive summary\n15 pts\n\n\nReproducibility and organization\n10 pts\n\n\nTeam peer evaluation\n10 pts\n\n\nClassmates’ evaluation\n5 pts\n\n\n\n\nCriteria\nYour project will be assessed on the following criteria:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations.\nThe late work policy for the write-up is 5% of the maximum obtainable mark per calendar day up to seven calendar days after the deadline. If you intend to submit work late for the project, you must notify the course organizer before the original deadline as well as as soon as the completed work is submitted on GitHub."
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/presentation/presentation.html",
    "href": "project-instructions_in_dev/repo-structure/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "project-instructions_in_dev/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/presentation/presentation.html#plot-and-text",
    "href": "project-instructions_in_dev/repo-structure/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[]"
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/proposal/proposal.html",
    "href": "project-instructions_in_dev/repo-structure/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/proposal/proposal.html#introduction",
    "href": "project-instructions_in_dev/repo-structure/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/proposal/proposal.html#data",
    "href": "project-instructions_in_dev/repo-structure/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "project-instructions_in_dev/repo-structure/proposal/proposal.html#data-analysis-plan",
    "href": "project-instructions_in_dev/repo-structure/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "slides/setup.html",
    "href": "slides/setup.html",
    "title": "DSC 223 - Fall 2022 - Block 2",
    "section": "",
    "text": "datasciencebox.org"
  },
  {
    "objectID": "slides/u1-d01-welcome/u1-d01-welcome.html",
    "href": "slides/u1-d01-welcome/u1-d01-welcome.html",
    "title": "Welcome!",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u1-d01-welcome/u1-d01-welcome.html#data-science",
    "href": "slides/u1-d01-welcome/u1-d01-welcome.html#data-science",
    "title": "Welcome!",
    "section": "Data science",
    "text": "Data science\n.pull-left-wide[ - Data science is an exciting discipline that allows you to turn raw data into understanding, insight, and knowledge. ]"
  },
  {
    "objectID": "slides/u1-d01-welcome/u1-d01-welcome.html#course-faq",
    "href": "slides/u1-d01-welcome/u1-d01-welcome.html#course-faq",
    "title": "Welcome!",
    "section": "Course FAQ",
    "text": "Course FAQ\n.pull-left-wide[ Q - What data science background does this course assume?\nA - None.]"
  },
  {
    "objectID": "slides/u1-d01-welcome/u1-d01-welcome.html#course-faq-1",
    "href": "slides/u1-d01-welcome/u1-d01-welcome.html#course-faq-1",
    "title": "Welcome!",
    "section": "Course FAQ",
    "text": "Course FAQ\n.pull-left-wide[ Q - Is this an intro CS course?\nA - No, but many themes are shared.]\n\nclass: middle"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html",
    "title": "Meet the toolkit:programming",
    "section": "",
    "text": "layout: true"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#course-toolkit",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#course-toolkit",
    "title": "Meet the toolkit:programming",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n.pull-left[ ### .gray[Course operation] .gray[ - introds.org - Learn - Zoom - Teams - Piazza]] .pull-right[ ### .pink[Doing data science] - .pink[Programming:] - .pink[R] - .pink[RStudio] - .pinktidyverse - .pinkR Markdown - .gray[Version control and collaboration:] - .gray[Git] - .gray[GitHub]]"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#learning-goals",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#learning-goals",
    "title": "Meet the toolkit:programming",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n–\n\ngain insight from data\n\n\n\n\n\n\n\n- gain insight from data, reproducibly\n\n\n\n\n- gain insight from data, reproducibly, using modern programming tools and techniques\n\n\n\n\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\n\n\n\n\n\n\n\n- gain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#reproducibility-checklist",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#reproducibility-checklist",
    "title": "Meet the toolkit:programming",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n.question[ What does it mean for a data analysis to be “reproducible”?]\n–\nNear-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#toolkit-for-reproducibility",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit:programming",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) R Markdown\nVersion control \\(\\rightarrow\\) Git / GitHub\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-and-rstudio-1",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-and-rstudio-1",
    "title": "Meet the toolkit:programming",
    "section": "R and RStudio",
    "text": "R and RStudio\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-packages",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-packages",
    "title": "Meet the toolkit:programming",
    "section": "R packages",
    "text": "R packages\n\nPackages are the fundamental units of reproducible R code. They include reusable R functions, the documentation that describes how to use them, and sample data1\nAs of September 2020, there are over 16,000 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n.footnote[ 1 Wickham and Bryan, R Packages.]"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#tour-r-and-rstudio",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#tour-r-and-rstudio",
    "title": "Meet the toolkit:programming",
    "section": "Tour: R and RStudio",
    "text": "Tour: R and RStudio"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#a-short-list-for-now-of-r-essentials",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#a-short-list-for-now-of-r-essentials",
    "title": "Meet the toolkit:programming",
    "section": "A short list (for now) of R essentials",
    "text": "A short list (for now) of R essentials\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\n\ndo_this(to_this)\ndo_that(to_this, to_that, with_those)\n\n–\n\nPackages are installed with the install.packages function and loaded with the library function, once per session:\n\n\ninstall.packages(\"package_name\")\nlibrary(package_name)"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-essentials-continued",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-essentials-continued",
    "title": "Meet the toolkit:programming",
    "section": "R essentials (continued)",
    "text": "R essentials (continued)\n\nColumns (variables) in data frames are accessed with $:\n\n.small[]\n–\n\nObject documentation can be accessed with ?\n\n\n?mean"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#tidyverse",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#tidyverse",
    "title": "Meet the toolkit:programming",
    "section": "tidyverse",
    "text": "tidyverse\n.pull-left[]\n.pull-right[ .center[.large[ tidyverse.org]]]"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#rmarkdown",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#rmarkdown",
    "title": "Meet the toolkit:programming",
    "section": "rmarkdown",
    "text": "rmarkdown\n.pull-left[ .center[.large[ rmarkdown.rstudio.com]]]\n.pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-markdown-1",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-markdown-1",
    "title": "Meet the toolkit:programming",
    "section": "R Markdown",
    "text": "R Markdown\n\nFully reproducible reports – each time you knit the analysis is ran from the beginning\nSimple markdown syntax for text\nCode goes in chunks, defined by three backticks, narrative goes outside of chunks"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#tour-r-markdown",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#tour-r-markdown",
    "title": "Meet the toolkit:programming",
    "section": "Tour: R Markdown",
    "text": "Tour: R Markdown"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#environments",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#environments",
    "title": "Meet the toolkit:programming",
    "section": "Environments",
    "text": "Environments\n.tip[ The environment of your R Markdown document is separate from the Console!]\nRemember this, and expect it to bite you a few times as you’re learning to work with R Markdown!"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#environments-1",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#environments-1",
    "title": "Meet the toolkit:programming",
    "section": "Environments",
    "text": "Environments\n.pull-left[ First, run the following in the console]\n–\n.pull-right[ Then, add the following in an R chunk in your R Markdown document]"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-markdown-help",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#r-markdown-help",
    "title": "Meet the toolkit:programming",
    "section": "R Markdown help",
    "text": "R Markdown help\n.pull-left[ .center[ .midi[R Markdown Cheat Sheet\nHelp -> Cheatsheets]]] .pull-right[ .center[ .midi[Markdown Quick Reference\nHelp -> Markdown Quick Reference]]]"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#how-will-we-use-r-markdown",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#how-will-we-use-r-markdown",
    "title": "Meet the toolkit:programming",
    "section": "How will we use R Markdown?",
    "text": "How will we use R Markdown?\n\nEvery assignment / report / project / etc. is an R Markdown document\nYou’ll always have a template R Markdown document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#whats-with-all-the-hexes",
    "href": "slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#whats-with-all-the-hexes",
    "title": "Meet the toolkit:programming",
    "section": "What’s with all the hexes?",
    "text": "What’s with all the hexes?\n\n\n\n\n\n\n\n\n\n.footnote[ Mitchell O’Hara-Wild, useR! 2018 feature wall]\n\n.your-turn[ .light-blue[.hand[Your turn:]] AE 02 - Bechdel + R Markdown - The Bechdel test asks whether a work of fiction features at least two women who talk to each other about something other than a man, and there must be two women named characters. - Go to RStudio Server and start the assignment AE 02 - Bechdel + R Markdown. - Open and knit the R Markdown document bechdel.Rmd, review the document, and fill in the blanks.]"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "",
    "text": "layout: true"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#course-toolkit",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#course-toolkit",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n.pull-left[ ### .gray[Course operation] .gray[ - introds.org - Learn - Zoom - Teams - Piazza]] .pull-right[ ### .gray[Doing data science] - .gray[Programming:] - .gray[R] - .gray[RStudio] - .gray[tidyverse] - .gray[R Markdown] - .pink[Version control and collaboration:] - .pink[Git] - .pink[GitHub]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#git-and-github-1",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#git-and-github-1",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#versioning",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#versioning",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "Versioning",
    "text": "Versioning"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#versioning-1",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#versioning-1",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "Versioning",
    "text": "Versioning\n\nwith human readable messages"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#why-do-we-need-version-control",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#why-do-we-need-version-control",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github-1",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github-1",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github-2",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github-2",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github-3",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#how-will-we-use-git-and-github-3",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#tour-git-and-github",
    "href": "slides/u1-d03-toolkit-git/u1-d03-toolkit-git.html#tour-git-and-github",
    "title": "Meet the toolkit:version control and collaboration",
    "section": "Tour: Git and GitHub",
    "text": "Tour: Git and GitHub\n\nCreate a GitHub account\nVerify your GitHub email\nAdjust your GitHub settings for a more pleasant GitHub experience\n\nSettings > Emails > Uncheck “Keep my email address private”\nSettings > Emails > Update name and photo\n\n\n\nNext week…\nWork with R, RStudio, Git, and GitHub together!+\n.footnote[ +Just like a real data scientist!]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html",
    "title": "Data and visualisation",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#dataset-terminology",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#dataset-terminology",
    "title": "Data and visualisation",
    "section": "Dataset terminology",
    "text": "Dataset terminology\n\nEach row is an observation\nEach column is a variable\n\n.small[]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#luke-skywalker",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#luke-skywalker",
    "title": "Data and visualisation",
    "section": "Luke Skywalker",
    "text": "Luke Skywalker\n\n\n\nluke-skywalker"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#whats-in-the-star-wars-data",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#whats-in-the-star-wars-data",
    "title": "Data and visualisation",
    "section": "What’s in the Star Wars data?",
    "text": "What’s in the Star Wars data?\nTake a glimpse at the data:\n\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       <chr> \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth V~\n$ height     <int> 172, 167, 96, 202, 150, 178, 165, 97, 183, 1~\n$ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, ~\n$ hair_color <chr> \"blond\", NA, NA, \"none\", \"brown\", \"brown, gr~\n$ skin_color <chr> \"fair\", \"gold\", \"white, blue\", \"white\", \"lig~\n$ eye_color  <chr> \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", ~\n$ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, N~\n$ sex        <chr> \"male\", \"none\", \"none\", \"male\", \"female\", \"m~\n$ gender     <chr> \"masculine\", \"masculine\", \"masculine\", \"masc~\n$ homeworld  <chr> \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\",~\n$ species    <chr> \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\",~\n$ films      <list> <\"The Empire Strikes Back\", \"Revenge of the~\n$ vehicles   <list> <\"Snowspeeder\", \"Imperial Speeder Bike\">, <~\n$ starships  <list> <\"X-wing\", \"Imperial shuttle\">, <>, <>, \"TI~\n\n\n\n.question[ How many rows and columns does this dataset have? What does each row represent? What does each column represent?]\n\n?starwars\n\n\n\n\n\n\n\n\n\n\n\n.question[ How many rows and columns does this dataset have?]\n.pull-left[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#what-is-eda",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#what-is-eda",
    "title": "Data and visualisation",
    "section": "What is EDA?",
    "text": "What is EDA?\n\nExploratory data analysis (EDA) is an approach to analysing data sets to summarize its main characteristics\nOften, this is visual – this is what we’ll focus on first\nBut we might also calculate summary statistics and perform data wrangling/manipulation/transformation at (or before) this stage of the analysis – this is what we’ll focus on next"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#mass-vs.-height",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#mass-vs.-height",
    "title": "Data and visualisation",
    "section": "Mass vs. height",
    "text": "Mass vs. height\n.question[ How would you describe the relationship between mass and height of Starwars characters? What other variables would help us understand data points that don’t follow the overall trend? Who is the not so tall but really chubby character?]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#jabba",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#jabba",
    "title": "Data and visualisation",
    "section": "Jabba!",
    "text": "Jabba!\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#data-visualization-1",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#data-visualization-1",
    "title": "Data and visualisation",
    "section": "Data visualization",
    "text": "Data visualization\n\n“The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey\n\n\nData visualization is the creation and study of the visual representation of data\nMany tools for visualizing data – R is one of them\nMany approaches/systems within R for making data visualizations – ggplot2 is one of them, and that’s what we’re going to use"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#ggplot2-in-tidyverse",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#ggplot2-in-tidyverse",
    "title": "Data and visualisation",
    "section": "ggplot2 \\(\\in\\) tidyverse",
    "text": "ggplot2 \\(\\in\\) tidyverse\n.pull-left[] .pull-right[ - ggplot2 is tidyverse’s data visualization package - gg in “ggplot2” stands for Grammar of Graphics - Inspired by the book Grammar of Graphics by Leland Wilkinson]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#grammar-of-graphics",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#grammar-of-graphics",
    "title": "Data and visualisation",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n.pull-left-narrow[ A grammar of graphics is a tool that enables us to concisely describe the components of a graphic] .pull-right-wide[]\n.footnote[ Source: BloggoType]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#mass-vs.-height-1",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#mass-vs.-height-1",
    "title": "Data and visualisation",
    "section": "Mass vs. height",
    "text": "Mass vs. height\n\nggplot(data = starwars, mapping = aes(x = height, y = mass)) +\n  geom_point() +\n  labs(title = \"Mass vs. height of Starwars characters\",\n       x = \"Height (cm)\", y = \"Weight (kg)\")\n\nWarning: Removed 28 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n\n\n\n.question[ - What are the functions doing the plotting? - What is the dataset being plotted? - Which variables map to which features (aesthetics) of the plot? - What does the warning mean?+]\n\nggplot(data = starwars, mapping = aes(x = height, y = mass)) +\n  geom_point() +\n  labs(title = \"Mass vs. height of Starwars characters\",\n       x = \"Height (cm)\", y = \"Weight (kg)\")\n\nWarning: Removed 28 rows containing missing values (geom_point).\n\n\n.footnote[ +Suppressing warning to subsequent slides to save space]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#hello-ggplot2",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#hello-ggplot2",
    "title": "Data and visualisation",
    "section": "Hello ggplot2!",
    "text": "Hello ggplot2!\n.pull-left-wide[ - ggplot() is the main function in ggplot2 - Plots are constructed in layers - Structure of the code for plots can be summarized as]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#anscombes-quartet",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#anscombes-quartet",
    "title": "Data and visualisation",
    "section": "Anscombe’s quartet",
    "text": "Anscombe’s quartet\n\n\n\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#summarising-anscombes-quartet",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#summarising-anscombes-quartet",
    "title": "Data and visualisation",
    "section": "Summarising Anscombe’s quartet",
    "text": "Summarising Anscombe’s quartet\n\nquartet %>%\n  group_by(set) %>%\n  summarise(\n    mean_x = mean(x), \n    mean_y = mean(y),\n    sd_x = sd(x),\n    sd_y = sd(y),\n    r = cor(x, y)\n  )\n\n# A tibble: 4 x 6\n  set   mean_x mean_y  sd_x  sd_y     r\n  <fct>  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 I          9   7.50  3.32  2.03 0.816\n2 II         9   7.50  3.32  2.03 0.816\n3 III        9   7.5   3.32  2.03 0.816\n4 IV         9   7.50  3.32  2.03 0.817"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#visualizing-anscombes-quartet",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#visualizing-anscombes-quartet",
    "title": "Data and visualisation",
    "section": "Visualizing Anscombe’s quartet",
    "text": "Visualizing Anscombe’s quartet"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#age-at-first-kiss",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#age-at-first-kiss",
    "title": "Data and visualisation",
    "section": "Age at first kiss",
    "text": "Age at first kiss\n.question[ Do you see anything out of the ordinary?]"
  },
  {
    "objectID": "slides/u2-d01-data-viz/u2-d01-data-viz.html#facebook-visits",
    "href": "slides/u2-d01-data-viz/u2-d01-data-viz.html#facebook-visits",
    "title": "Data and visualisation",
    "section": "Facebook visits",
    "text": "Facebook visits\n.question[ How are people reporting lower vs. higher values of FB visits?]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html",
    "title": "Visualising data with ggplot2",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#ggplot2-in-tidyverse",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#ggplot2-in-tidyverse",
    "title": "Visualising data with ggplot2",
    "section": "ggplot2 \\(\\in\\) tidyverse",
    "text": "ggplot2 \\(\\in\\) tidyverse\n.pull-left[] .pull-right[ - ggplot2 is tidyverse’s data visualization package - Structure of the code for plots can be summarized as]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#data-palmer-penguins",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#data-palmer-penguins",
    "title": "Visualising data with ggplot2",
    "section": "Data: Palmer Penguins",
    "text": "Data: Palmer Penguins\nMeasurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.\n.pull-left-narrow[] .pull-right-wide[]\n\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#argument-names",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#argument-names",
    "title": "Visualising data with ggplot2",
    "section": "Argument names",
    "text": "Argument names\n.tip[ You can omit the names of first two arguments when building plots with ggplot().]\n.pull-left[] .pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#aesthetics-options",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#aesthetics-options",
    "title": "Visualising data with ggplot2",
    "section": "Aesthetics options",
    "text": "Aesthetics options\nCommonly used characteristics of plotting characters that can be mapped to a specific variable in the data are\n\ncolour\nshape\nsize\nalpha (transparency)"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#colour",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#colour",
    "title": "Visualising data with ggplot2",
    "section": "Colour",
    "text": "Colour\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#shape",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#shape",
    "title": "Visualising data with ggplot2",
    "section": "Shape",
    "text": "Shape\nMapped to a different variable than colour\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#shape-1",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#shape-1",
    "title": "Visualising data with ggplot2",
    "section": "Shape",
    "text": "Shape\nMapped to same variable as colour\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#size",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#size",
    "title": "Visualising data with ggplot2",
    "section": "Size",
    "text": "Size\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#alpha",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#alpha",
    "title": "Visualising data with ggplot2",
    "section": "Alpha",
    "text": "Alpha\n.pull-left[] .pull-right[]\n\n.pull-left[ Mapping] .pull-right[ Setting]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#mapping-vs.-setting",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#mapping-vs.-setting",
    "title": "Visualising data with ggplot2",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nMapping: Determine the size, alpha, etc. of points based on the values of a variable in the data\n\ngoes into aes()\n\nSetting: Determine the size, alpha, etc. of points not based on the values of a variable in the data\n\ngoes into geom_*() (this was geom_point() in the previous example, but we’ll learn about other geoms soon!)\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#faceting-1",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#faceting-1",
    "title": "Visualising data with ggplot2",
    "section": "Faceting",
    "text": "Faceting\n\nSmaller plots that display different subsets of the data\nUseful for exploring conditional relationships and large data\n\n\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#various-ways-to-facet",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#various-ways-to-facet",
    "title": "Visualising data with ggplot2",
    "section": "Various ways to facet",
    "text": "Various ways to facet\n.question[ In the next few slides describe what each plot displays. Think about how the code relates to the output.]\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(species ~ sex) #<<\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(sex ~ species) #<<\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ species) #<<\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(. ~ species) #<<\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ species, ncol = 2) #<<"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#faceting-summary",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#faceting-summary",
    "title": "Visualising data with ggplot2",
    "section": "Faceting summary",
    "text": "Faceting summary\n\nfacet_grid():\n\n2d grid\nrows ~ cols\nuse . for no split\n\nfacet_wrap(): 1d ribbon wrapped according to number of rows and columns specified or available plotting area"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#facet-and-color",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#facet-and-color",
    "title": "Visualising data with ggplot2",
    "section": "Facet and color",
    "text": "Facet and color\n.pull-left-narrow[] .pull-right-wide[]"
  },
  {
    "objectID": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#face-and-color-no-legend",
    "href": "slides/u2-d02-ggplot2/u2-d02-ggplot2.html#face-and-color-no-legend",
    "title": "Visualising data with ggplot2",
    "section": "Face and color, no legend",
    "text": "Face and color, no legend\n.pull-left-narrow[] .pull-right-wide[]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html",
    "title": "Visualising numerical data",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#number-of-variables-involved",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#number-of-variables-involved",
    "title": "Visualising numerical data",
    "section": "Number of variables involved",
    "text": "Number of variables involved\n\nUnivariate data analysis - distribution of single variable\nBivariate data analysis - relationship between two variables\nMultivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#types-of-variables",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#types-of-variables",
    "title": "Visualising numerical data",
    "section": "Types of variables",
    "text": "Types of variables\n\nNumerical variables can be classified as continuous or discrete based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.\nIf the variable is categorical, we can determine if it is ordinal based on whether or not the levels have a natural ordering.\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#data-lending-club",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#data-lending-club",
    "title": "Visualising numerical data",
    "section": "Data: Lending Club",
    "text": "Data: Lending Club\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#take-a-peek-at-data",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#take-a-peek-at-data",
    "title": "Visualising numerical data",
    "section": "Take a peek at data",
    "text": "Take a peek at data\n\nlibrary(openintro)\nglimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        <chr> \"global config enginee~\n$ emp_length                       <dbl> 3, 10, 3, 1, 10, NA, 1~\n$ state                            <fct> NJ, HI, WI, PA, CA, KY~\n$ homeownership                    <fct> MORTGAGE, RENT, RENT, ~\n$ annual_income                    <dbl> 90000, 40000, 40000, 3~\n$ verified_income                  <fct> Verified, Not Verified~\n$ debt_to_income                   <dbl> 18.01, 5.04, 21.15, 10~\n$ annual_income_joint              <dbl> NA, NA, NA, NA, 57000,~\n$ verification_income_joint        <fct> , , , , Verified, , No~\n$ debt_to_income_joint             <dbl> NA, NA, NA, NA, 37.66,~\n$ delinq_2y                        <int> 0, 0, 0, 0, 0, 1, 0, 1~\n$ months_since_last_delinq         <int> 38, NA, 28, NA, NA, 3,~\n$ earliest_credit_line             <dbl> 2001, 1996, 2006, 2007~\n$ inquiries_last_12m               <int> 6, 1, 4, 0, 7, 6, 1, 1~\n$ total_credit_lines               <int> 28, 30, 31, 4, 22, 32,~\n$ open_credit_lines                <int> 10, 14, 10, 4, 16, 12,~\n..."
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#selected-variables",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#selected-variables",
    "title": "Visualising numerical data",
    "section": "Selected variables",
    "text": "Selected variables\n\nloans <- loans_full_schema %>%\n  select(loan_amount, interest_rate, term, grade, \n         state, annual_income, homeownership, debt_to_income)\nglimpse(loans)\n\nRows: 10,000\nColumns: 8\n$ loan_amount    <int> 28000, 5000, 2000, 21600, 23000, 5000, 2~\n$ interest_rate  <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, ~\n$ term           <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, ~\n$ grade          <ord> C, C, D, A, C, A, C, B, C, A, C, B, C, B~\n$ state          <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, IL, ~\n$ annual_income  <dbl> 90000, 40000, 40000, 30000, 35000, 34000~\n$ homeownership  <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN, M~\n$ debt_to_income <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, ~"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#selected-variables-1",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#selected-variables-1",
    "title": "Visualising numerical data",
    "section": "Selected variables",
    "text": "Selected variables\n\n.midi[ variable | description —————-|————- loan_amount | Amount of the loan received, in US dollars interest_rate | Interest rate on the loan, in an annual percentage term | The length of the loan, which is always set as a whole number of months grade | Loan grade, which takes a values A through G and represents the quality of the loan and its likelihood of being repaid state | US state where the borrower resides annual_income | Borrower’s annual income, including any second income, in US dollars homeownership | Indicates whether the person owns, owns but has a mortgage, or rents debt_to_income | Debt-to-income ratio]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#variable-types",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#variable-types",
    "title": "Visualising numerical data",
    "section": "Variable types",
    "text": "Variable types\n\n\n\n\nvariable\ntype\n\n\n\n\nloan_amount\nnumerical, continuous\n\n\ninterest_rate\nnumerical, continuous\n\n\nterm\nnumerical, discrete\n\n\ngrade\ncategorical, ordinal\n\n\nstate\ncategorical, not ordinal\n\n\nannual_income\nnumerical, continuous\n\n\nhomeownership\ncategorical, not ordinal\n\n\ndebt_to_income\nnumerical, continuous\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#describing-shapes-of-numerical-distributions",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#describing-shapes-of-numerical-distributions",
    "title": "Visualising numerical data",
    "section": "Describing shapes of numerical distributions",
    "text": "Describing shapes of numerical distributions\n\nshape:\n\nskewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)\nmodality: unimodal, bimodal, multimodal, uniform\n\ncenter: mean (mean), median (median), mode (not always useful)\nspread: range (range), standard deviation (sd), inter-quartile range (IQR)\nunusual observations\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#histogram-1",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#histogram-1",
    "title": "Visualising numerical data",
    "section": "Histogram",
    "text": "Histogram\n\nggplot(loans, aes(x = loan_amount)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with\n`binwidth`."
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#histograms-and-binwidth",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#histograms-and-binwidth",
    "title": "Visualising numerical data",
    "section": "Histograms and binwidth",
    "text": "Histograms and binwidth\n.panelset[ .panel[.panel-name[binwidth = 1000]] .panel[.panel-name[binwidth = 5000]] .panel[.panel-name[binwidth = 20000]]]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#customizing-histograms",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#customizing-histograms",
    "title": "Visualising numerical data",
    "section": "Customizing histograms",
    "text": "Customizing histograms\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#fill-with-a-categorical-variable",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#fill-with-a-categorical-variable",
    "title": "Visualising numerical data",
    "section": "Fill with a categorical variable",
    "text": "Fill with a categorical variable\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#facet-with-a-categorical-variable",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#facet-with-a-categorical-variable",
    "title": "Visualising numerical data",
    "section": "Facet with a categorical variable",
    "text": "Facet with a categorical variable\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#density-plot-1",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#density-plot-1",
    "title": "Visualising numerical data",
    "section": "Density plot",
    "text": "Density plot\n\nggplot(loans, aes(x = loan_amount)) +\n  geom_density()"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#density-plots-and-adjusting-bandwidth",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#density-plots-and-adjusting-bandwidth",
    "title": "Visualising numerical data",
    "section": "Density plots and adjusting bandwidth",
    "text": "Density plots and adjusting bandwidth\n.panelset[ .panel[.panel-name[adjust = 0.5]] .panel[.panel-name[adjust = 1]] .panel[.panel-name[adjust = 2]]]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#customizing-density-plots",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#customizing-density-plots",
    "title": "Visualising numerical data",
    "section": "Customizing density plots",
    "text": "Customizing density plots\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#adding-a-categorical-variable",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#adding-a-categorical-variable",
    "title": "Visualising numerical data",
    "section": "Adding a categorical variable",
    "text": "Adding a categorical variable\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#box-plot-1",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#box-plot-1",
    "title": "Visualising numerical data",
    "section": "Box plot",
    "text": "Box plot\n\nggplot(loans, aes(x = interest_rate)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#box-plot-and-outliers",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#box-plot-and-outliers",
    "title": "Visualising numerical data",
    "section": "Box plot and outliers",
    "text": "Box plot and outliers\n\nggplot(loans, aes(x = annual_income)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#customizing-box-plots",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#customizing-box-plots",
    "title": "Visualising numerical data",
    "section": "Customizing box plots",
    "text": "Customizing box plots\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#adding-a-categorical-variable-1",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#adding-a-categorical-variable-1",
    "title": "Visualising numerical data",
    "section": "Adding a categorical variable",
    "text": "Adding a categorical variable\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#scatterplot",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#scatterplot",
    "title": "Visualising numerical data",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nggplot(loans, aes(x = debt_to_income, y = interest_rate)) +\n  geom_point()"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#hex-plot",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#hex-plot",
    "title": "Visualising numerical data",
    "section": "Hex plot",
    "text": "Hex plot\n\nggplot(loans, aes(x = debt_to_income, y = interest_rate)) +\n  geom_hex()"
  },
  {
    "objectID": "slides/u2-d03-viz-num/u2-d03-viz-num.html#hex-plot-1",
    "href": "slides/u2-d03-viz-num/u2-d03-viz-num.html#hex-plot-1",
    "title": "Visualising numerical data",
    "section": "Hex plot",
    "text": "Hex plot\n\nggplot(loans %>% filter(debt_to_income < 100), \n       aes(x = debt_to_income, y = interest_rate)) +\n  geom_hex()"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html",
    "title": "Visualising categorical data",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#variables",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#variables",
    "title": "Visualising categorical data",
    "section": "Variables",
    "text": "Variables\n\nNumerical variables can be classified as continuous or discrete based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.\nIf the variable is categorical, we can determine if it is ordinal based on whether or not the levels have a natural ordering.\n\n\n\nData\n\nlibrary(openintro)\nloans <- loans_full_schema %>%\n  select(loan_amount, interest_rate, term, grade, \n         state, annual_income, homeownership, debt_to_income)\nglimpse(loans)\n\nRows: 10,000\nColumns: 8\n$ loan_amount    <int> 28000, 5000, 2000, 21600, 23000, 5000, 2~\n$ interest_rate  <dbl> 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, ~\n$ term           <dbl> 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, ~\n$ grade          <ord> C, C, D, A, C, A, C, B, C, A, C, B, C, B~\n$ state          <fct> NJ, HI, WI, PA, CA, KY, MI, AZ, NV, IL, ~\n$ annual_income  <dbl> 90000, 40000, 40000, 30000, 35000, 34000~\n$ homeownership  <fct> MORTGAGE, RENT, RENT, RENT, RENT, OWN, M~\n$ debt_to_income <dbl> 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, ~\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#bar-plot-1",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#bar-plot-1",
    "title": "Visualising categorical data",
    "section": "Bar plot",
    "text": "Bar plot\n\nggplot(loans, aes(x = homeownership)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#segmented-bar-plot",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#segmented-bar-plot",
    "title": "Visualising categorical data",
    "section": "Segmented bar plot",
    "text": "Segmented bar plot\n\nggplot(loans, aes(x = homeownership, \n                  fill = grade)) + #<<\n  geom_bar()"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#segmented-bar-plot-1",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#segmented-bar-plot-1",
    "title": "Visualising categorical data",
    "section": "Segmented bar plot",
    "text": "Segmented bar plot\n\nggplot(loans, aes(x = homeownership, fill = grade)) +\n  geom_bar(position = \"fill\") #<<\n\n\n\n\n\n\n\n\n\n.question[ Which bar plot is a more useful representation for visualizing the relationship between homeownership and grade?]\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#customizing-bar-plots",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#customizing-bar-plots",
    "title": "Visualising categorical data",
    "section": "Customizing bar plots",
    "text": "Customizing bar plots\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#already-talked-about",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#already-talked-about",
    "title": "Visualising categorical data",
    "section": "Already talked about…",
    "text": "Already talked about…\n\nColouring and faceting histograms and density plots\nSide-by-side box plots"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#violin-plots",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#violin-plots",
    "title": "Visualising categorical data",
    "section": "Violin plots",
    "text": "Violin plots\n\nggplot(loans, aes(x = homeownership, y = loan_amount)) +\n  geom_violin()"
  },
  {
    "objectID": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#ridge-plots",
    "href": "slides/u2-d04-viz-cat/u2-d04-viz-cat.html#ridge-plots",
    "title": "Visualising categorical data",
    "section": "Ridge plots",
    "text": "Ridge plots\n\nlibrary(ggridges)\nggplot(loans, aes(x = loan_amount, y = grade, fill = grade, color = grade)) + \n  geom_density_ridges(alpha = 0.5)"
  },
  {
    "objectID": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html",
    "href": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html",
    "title": "Tidy data",
    "section": "",
    "text": "layout: true"
  },
  {
    "objectID": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html#tidy-data",
    "href": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html#tidy-data",
    "title": "Tidy data",
    "section": "Tidy data",
    "text": "Tidy data\n\nHappy families are all alike; every unhappy family is unhappy in its own way.\nLeo Tolstoy\n\n–\n.pull-left[ Characteristics of tidy data:] – .pull-right[ Characteristics of untidy data:]"
  },
  {
    "objectID": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html#section",
    "href": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html#section",
    "title": "Tidy data",
    "section": "",
    "text": ".question[ What makes this data not tidy?]\n\n\n\n\n\n\n\n\n\n.footnote[ Source: Army Air Forces Statistical Digest, WW II]\n\n.question[ What makes this data not tidy?]\n\n\n\n\n\n\n\n\n\n\n.footnote[ Source: Gapminder, Estimated HIV prevalence among 15-49 year olds]\n\n.question[ What makes this data not tidy?]\n\n\n\n\n\n\n\n\n\n\n.footnote[ Source: US Census Fact Finder, General Economic Characteristics, ACS 2017]"
  },
  {
    "objectID": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html#displaying-vs.-summarising-data",
    "href": "slides/u2-d05-tidy-data/u2-d05-tidy-data.html#displaying-vs.-summarising-data",
    "title": "Tidy data",
    "section": "Displaying vs. summarising data",
    "text": "Displaying vs. summarising data\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html",
    "title": "Grammar of data wrangling",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#a-grammar-of-data-wrangling",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#a-grammar-of-data-wrangling",
    "title": "Grammar of data wrangling",
    "section": "A grammar of data wrangling…",
    "text": "A grammar of data wrangling…\n… based on the concepts of functions as verbs that manipulate data frames\n.pull-left[] .pull-right[ .midi[ - select: pick columns by name - arrange: reorder rows - slice: pick rows using index(es) - filter: pick rows matching criteria - distinct: filter for unique rows - mutate: add new variables - summarise: reduce variables to values - group_by: for grouped operations - … (many more)]]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#rules-of-dplyr-functions",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#rules-of-dplyr-functions",
    "title": "Grammar of data wrangling",
    "section": "Rules of dplyr functions",
    "text": "Rules of dplyr functions\n\nFirst argument is always a data frame\nSubsequent arguments say what to do with that data frame\nAlways return a data frame\nDon’t modify in place"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#data-hotel-bookings",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#data-hotel-bookings",
    "title": "Grammar of data wrangling",
    "section": "Data: Hotel bookings",
    "text": "Data: Hotel bookings\n\nData from two hotels: one resort and one city hotel\nObservations: Each row represents a hotel booking\nGoal for original data collection: Development of prediction models to classify a hotel booking’s likelihood to be cancelled (Antonia et al., 2019)\n\n\nhotels <- read_csv(\"data/hotels.csv\")\n\n.footnote[ Source: TidyTuesday]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#first-look-variables",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#first-look-variables",
    "title": "Grammar of data wrangling",
    "section": "First look: Variables",
    "text": "First look: Variables\n\nnames(hotels)\n\n [1] \"hotel\"                         \n [2] \"is_canceled\"                   \n [3] \"lead_time\"                     \n [4] \"arrival_date_year\"             \n [5] \"arrival_date_month\"            \n [6] \"arrival_date_week_number\"      \n [7] \"arrival_date_day_of_month\"     \n [8] \"stays_in_weekend_nights\"       \n [9] \"stays_in_week_nights\"          \n[10] \"adults\"                        \n[11] \"children\"                      \n[12] \"babies\"                        \n[13] \"meal\"                          \n[14] \"country\"                       \n[15] \"market_segment\"                \n[16] \"distribution_channel\"          \n[17] \"is_repeated_guest\"             \n[18] \"previous_cancellations\"        \n..."
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#second-look-overview",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#second-look-overview",
    "title": "Grammar of data wrangling",
    "section": "Second look: Overview",
    "text": "Second look: Overview\n\nglimpse(hotels)\n\nRows: 119,390\nColumns: 32\n$ hotel                          <chr> \"Resort Hotel\", \"Resort ~\n$ is_canceled                    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ lead_time                      <dbl> 342, 737, 7, 13, 14, 14,~\n$ arrival_date_year              <dbl> 2015, 2015, 2015, 2015, ~\n$ arrival_date_month             <chr> \"July\", \"July\", \"July\", ~\n$ arrival_date_week_number       <dbl> 27, 27, 27, 27, 27, 27, ~\n$ arrival_date_day_of_month      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ stays_in_weekend_nights        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ stays_in_week_nights           <dbl> 0, 0, 1, 1, 2, 2, 2, 2, ~\n$ adults                         <dbl> 2, 2, 1, 1, 2, 2, 2, 2, ~\n$ children                       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ babies                         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ meal                           <chr> \"BB\", \"BB\", \"BB\", \"BB\", ~\n$ country                        <chr> \"PRT\", \"PRT\", \"GBR\", \"GB~\n$ market_segment                 <chr> \"Direct\", \"Direct\", \"Dir~\n$ distribution_channel           <chr> \"Direct\", \"Direct\", \"Dir~\n..."
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column",
    "title": "Grammar of data wrangling",
    "section": "Select a single column",
    "text": "Select a single column\nView only lead_time (number of days between booking and arrival date):\n\nselect(hotels, lead_time)\n\n# A tibble: 119,390 x 1\n  lead_time\n      <dbl>\n1       342\n2       737\n3         7\n4        13\n5        14\n6        14\n# ... with 119,384 more rows"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-1",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-1",
    "title": "Grammar of data wrangling",
    "section": "Select a single column",
    "text": "Select a single column\n.pull-left[] .pull-right[ - Start with the function (a verb): select()]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-2",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-2",
    "title": "Grammar of data wrangling",
    "section": "Select a single column",
    "text": "Select a single column\n.pull-left[] .pull-right[ - Start with the function (a verb): select() - First argument: data frame we’re working with , hotels]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-3",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-3",
    "title": "Grammar of data wrangling",
    "section": "Select a single column",
    "text": "Select a single column\n.pull-left[] .pull-right[ - Start with the function (a verb): select() - First argument: data frame we’re working with , hotels - Second argument: variable we want to select, lead_time]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-4",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-a-single-column-4",
    "title": "Grammar of data wrangling",
    "section": "Select a single column",
    "text": "Select a single column\n.pull-left[] .pull-right[ - Start with the function (a verb): select() - First argument: data frame we’re working with , hotels - Second argument: variable we want to select, lead_time - Result: data frame with 119390 rows and 1 column]\n\n.tip[ dplyr functions always expect a data frame and always yield a data frame.]\n\nselect(hotels, lead_time)\n\n# A tibble: 119,390 x 1\n  lead_time\n      <dbl>\n1       342\n2       737\n3         7\n4        13\n5        14\n6        14\n# ... with 119,384 more rows"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-multiple-columns",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#select-multiple-columns",
    "title": "Grammar of data wrangling",
    "section": "Select multiple columns",
    "text": "Select multiple columns\nView only the hotel type and lead_time:\n–\n.pull-left[] – .pull-right[ .question[ What if we wanted to select these columns, and then arrange the data in descending order of lead time?]]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#data-wrangling-step-by-step",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#data-wrangling-step-by-step",
    "title": "Grammar of data wrangling",
    "section": "Data wrangling, step-by-step",
    "text": "Data wrangling, step-by-step\n.pull-left[ Select:]\n\n\n\n\n\n\n.pull-right[ Select, then arrange:\n\n\n::: {.cell layout-align=“center”}\n\n\n{.r .cell-code} hotels %>% select(hotel, lead_time) %>% arrange(desc(lead_time))\n\n\n::: {.cell-output .cell-output-stdout}\n\n\n]\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#what-is-a-pipe",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#what-is-a-pipe",
    "title": "Grammar of data wrangling",
    "section": "What is a pipe?",
    "text": "What is a pipe?\nIn programming, a pipe is a technique for passing information from one process to another.\n–\n.pull-left[ - Start with the data frame hotels, and pass it to the select() function,] .pull-right[ .small[]]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#what-is-a-pipe-1",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#what-is-a-pipe-1",
    "title": "Grammar of data wrangling",
    "section": "What is a pipe?",
    "text": "What is a pipe?\nIn programming, a pipe is a technique for passing information from one process to another.\n.pull-left[ - Start with the data frame hotels, and pass it to the select() function, - then we select the variables hotel and lead_time,] .pull-right[ .small[]]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#what-is-a-pipe-2",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#what-is-a-pipe-2",
    "title": "Grammar of data wrangling",
    "section": "What is a pipe?",
    "text": "What is a pipe?\nIn programming, a pipe is a technique for passing information from one process to another.\n.pull-left[ - Start with the data frame hotels, and pass it to the select() function, - then we select the variables hotel and lead_time, - and then we arrange the data frame by lead_time in descending order.] .pull-right[ .small[]]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#aside",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#aside",
    "title": "Grammar of data wrangling",
    "section": "Aside",
    "text": "Aside\nThe pipe operator is implemented in the package magrittr, though we don’t need to load this package explicitly since tidyverse does this for us.\n–\n.question[ Any guesses as to why the package is called magrittr?]\n–\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#how-does-a-pipe-work",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#how-does-a-pipe-work",
    "title": "Grammar of data wrangling",
    "section": "How does a pipe work?",
    "text": "How does a pipe work?\n\nYou can think about the following sequence of actions - find keys, unlock car, start car, drive to work, park.\n\n\n\n\n\n\n\n- Expressed as a set of nested functions in R pseudocode this would look like:\n\n\n\n\n- Writing it out using pipes give it a more natural (and easier to read) structure:\n\n\n::: {.cell layout-align=“center”}\n\n\n{.r .cell-code} find(\"keys\") %>% start_car() %>% drive(to = \"work\") %>% park() :::"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#a-note-on-piping-and-layering",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#a-note-on-piping-and-layering",
    "title": "Grammar of data wrangling",
    "section": "A note on piping and layering",
    "text": "A note on piping and layering\n\n%>% used mainly in dplyr pipelines, we pipe the output of the previous line of code as the first input of the next line of code\n\n\n\n\n\n\n\n- + used in ggplot2 plots is used for “layering”, we create the plot in layers, separated by +"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#dplyr",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#dplyr",
    "title": "Grammar of data wrangling",
    "section": "dplyr",
    "text": "dplyr\n.midi[ ❌]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#ggplot2",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#ggplot2",
    "title": "Grammar of data wrangling",
    "section": "ggplot2",
    "text": "ggplot2\n.midi[ ❌]"
  },
  {
    "objectID": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#code-styling",
    "href": "slides/u2-d06-grammar-wrangle/u2-d06-grammar-wrangle.html#code-styling",
    "title": "Grammar of data wrangling",
    "section": "Code styling",
    "text": "Code styling\nMany of the styling principles are consistent across %>% and +:\n\nalways a space before\nalways a line break after (for pipelines with more than 2 lines)\n\n❌\n\nggplot(hotels,aes(x=hotel,y=deposit_type))+geom_bar()\n\n✅\n\nggplot(hotels, aes(x = hotel, y = deposit_type)) + \n  geom_bar()"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html",
    "title": "Working with a single data frame",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#data-hotel-bookings",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#data-hotel-bookings",
    "title": "Working with a single data frame",
    "section": "Data: Hotel bookings",
    "text": "Data: Hotel bookings\n\nData from two hotels: one resort and one city hotel\nObservations: Each row represents a hotel booking\n\n\nhotels <- read_csv(\"data/hotels.csv\")\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#select-to-keep-variables",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#select-to-keep-variables",
    "title": "Working with a single data frame",
    "section": "select to keep variables",
    "text": "select to keep variables\n\nhotels %>%\n  select(hotel, lead_time) #<<\n\n# A tibble: 119,390 x 2\n  hotel        lead_time\n  <chr>            <dbl>\n1 Resort Hotel       342\n2 Resort Hotel       737\n3 Resort Hotel         7\n4 Resort Hotel        13\n5 Resort Hotel        14\n6 Resort Hotel        14\n# ... with 119,384 more rows"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#select-to-exclude-variables",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#select-to-exclude-variables",
    "title": "Working with a single data frame",
    "section": "select to exclude variables",
    "text": "select to exclude variables\n.small[]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#select-a-range-of-variables",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#select-a-range-of-variables",
    "title": "Working with a single data frame",
    "section": "select a range of variables",
    "text": "select a range of variables\n\nhotels %>%\n  select(hotel:arrival_date_month) #<<\n\n# A tibble: 119,390 x 5\n  hotel        is_canceled lead_time arrival_date_year arrival_~1\n  <chr>              <dbl>     <dbl>             <dbl> <chr>     \n1 Resort Hotel           0       342              2015 July      \n2 Resort Hotel           0       737              2015 July      \n3 Resort Hotel           0         7              2015 July      \n4 Resort Hotel           0        13              2015 July      \n5 Resort Hotel           0        14              2015 July      \n6 Resort Hotel           0        14              2015 July      \n# ... with 119,384 more rows, and abbreviated variable name\n#   1: arrival_date_month"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#select-variables-with-certain-characteristics",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#select-variables-with-certain-characteristics",
    "title": "Working with a single data frame",
    "section": "select variables with certain characteristics",
    "text": "select variables with certain characteristics\n\nhotels %>%\n  select(starts_with(\"arrival\")) #<<\n\n# A tibble: 119,390 x 4\n  arrival_date_year arrival_date_month arrival_date_wee~1 arriv~2\n              <dbl> <chr>                           <dbl>   <dbl>\n1              2015 July                               27       1\n2              2015 July                               27       1\n3              2015 July                               27       1\n4              2015 July                               27       1\n5              2015 July                               27       1\n6              2015 July                               27       1\n# ... with 119,384 more rows, and abbreviated variable names\n#   1: arrival_date_week_number, 2: arrival_date_day_of_month"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#select-variables-with-certain-characteristics-1",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#select-variables-with-certain-characteristics-1",
    "title": "Working with a single data frame",
    "section": "select variables with certain characteristics",
    "text": "select variables with certain characteristics\n\nhotels %>%\n  select(ends_with(\"type\")) #<<\n\n# A tibble: 119,390 x 4\n  reserved_room_type assigned_room_type deposit_type customer_t~1\n  <chr>              <chr>              <chr>        <chr>       \n1 C                  C                  No Deposit   Transient   \n2 C                  C                  No Deposit   Transient   \n3 A                  C                  No Deposit   Transient   \n4 A                  A                  No Deposit   Transient   \n5 A                  A                  No Deposit   Transient   \n6 A                  A                  No Deposit   Transient   \n# ... with 119,384 more rows, and abbreviated variable name\n#   1: customer_type"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#select-helpers",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#select-helpers",
    "title": "Working with a single data frame",
    "section": "Select helpers",
    "text": "Select helpers\n\nstarts_with(): Starts with a prefix\nends_with(): Ends with a suffix\ncontains(): Contains a literal string\nnum_range(): Matches a numerical range like x01, x02, x03\none_of(): Matches variable names in a character vector\neverything(): Matches all variables\nlast_col(): Select last variable, possibly with an offset\nmatches(): Matches a regular expression (a sequence of symbols/characters expressing a string/pattern to be searched for within text)\n\n.footnote[ See help for any of these functions for more info, e.g. ?everything.]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#arrange-in-ascending-descending-order",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#arrange-in-ascending-descending-order",
    "title": "Working with a single data frame",
    "section": "arrange in ascending / descending order",
    "text": "arrange in ascending / descending order\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#slice-for-certain-row-numbers",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#slice-for-certain-row-numbers",
    "title": "Working with a single data frame",
    "section": "slice for certain row numbers",
    "text": "slice for certain row numbers\n.midi[]\n\n.tip[ In R, you can use the # for adding comments to your code. Any text following # will be printed as is, and won’t be run as R code. This is useful for leaving comments in your code and for temporarily disabling certain lines of code while debugging.]\n.small[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#filter-to-select-a-subset-of-rows",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#filter-to-select-a-subset-of-rows",
    "title": "Working with a single data frame",
    "section": "filter to select a subset of rows",
    "text": "filter to select a subset of rows\n.midi[]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#filter-for-many-conditions-at-once",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#filter-for-many-conditions-at-once",
    "title": "Working with a single data frame",
    "section": "filter for many conditions at once",
    "text": "filter for many conditions at once\n\nhotels %>%\n  filter( \n    adults == 0,     #<<\n    children >= 1    #<<\n    ) %>% \n  select(adults, babies, children)\n\n# A tibble: 223 x 3\n  adults babies children\n   <dbl>  <dbl>    <dbl>\n1      0      0        3\n2      0      0        2\n3      0      0        2\n4      0      0        2\n5      0      0        2\n6      0      0        3\n# ... with 217 more rows"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#filter-for-more-complex-conditions",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#filter-for-more-complex-conditions",
    "title": "Working with a single data frame",
    "section": "filter for more complex conditions",
    "text": "filter for more complex conditions\n\n# bookings with no adults and some children or babies in the room\nhotels %>%\n  filter( \n    adults == 0,     \n    children >= 1 | babies >= 1     # | means or  #<<\n    ) %>%\n  select(adults, babies, children)\n\n# A tibble: 223 x 3\n  adults babies children\n   <dbl>  <dbl>    <dbl>\n1      0      0        3\n2      0      0        2\n3      0      0        2\n4      0      0        2\n5      0      0        2\n6      0      0        3\n# ... with 217 more rows"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#logical-operators-in-r",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#logical-operators-in-r",
    "title": "Working with a single data frame",
    "section": "Logical operators in R",
    "text": "Logical operators in R\n\noperator | definition || operator | definition ————|——————————||————–|—————- < | less than ||x | y | x OR y <= | less than or equal to ||is.na(x) | test if x is NA > | greater than ||!is.na(x) | test if x is not NA >= | greater than or equal to ||x %in% y | test if x is in y == | exactly equal to ||!(x %in% y) | test if x is not in y != | not equal to ||!x | not x x & y | x AND y || |\n\n.your-turn[ ### Your turn!]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#distinct-to-filter-for-unique-rows",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#distinct-to-filter-for-unique-rows",
    "title": "Working with a single data frame",
    "section": "distinct to filter for unique rows",
    "text": "distinct to filter for unique rows\n… and arrange to order alphabetically\n.small[ .pull-left[] .pull-right[]]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#count-to-create-frequency-tables",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#count-to-create-frequency-tables",
    "title": "Working with a single data frame",
    "section": "count to create frequency tables",
    "text": "count to create frequency tables\n.pull-left[] – .pull-right[]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#count-and-arrange",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#count-and-arrange",
    "title": "Working with a single data frame",
    "section": "count and arrange",
    "text": "count and arrange\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#count-for-multiple-variables",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#count-for-multiple-variables",
    "title": "Working with a single data frame",
    "section": "count for multiple variables",
    "text": "count for multiple variables\n\nhotels %>%\n  count(hotel, market_segment) #<<\n\n# A tibble: 14 x 3\n   hotel        market_segment     n\n   <chr>        <chr>          <int>\n 1 City Hotel   Aviation         237\n 2 City Hotel   Complementary    542\n 3 City Hotel   Corporate       2986\n 4 City Hotel   Direct          6093\n 5 City Hotel   Groups         13975\n 6 City Hotel   Offline TA/TO  16747\n 7 City Hotel   Online TA      38748\n 8 City Hotel   Undefined          2\n 9 Resort Hotel Complementary    201\n10 Resort Hotel Corporate       2309\n11 Resort Hotel Direct          6513\n12 Resort Hotel Groups          5836\n13 Resort Hotel Offline TA/TO   7472\n14 Resort Hotel Online TA      17729"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#order-matters-when-you-count",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#order-matters-when-you-count",
    "title": "Working with a single data frame",
    "section": "order matters when you count",
    "text": "order matters when you count\n.midi[ .pull-left[] .pull-right[]]\n\n.your-turn[ ### Your turn!]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#mutate-to-add-a-new-variable",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#mutate-to-add-a-new-variable",
    "title": "Working with a single data frame",
    "section": "mutate to add a new variable",
    "text": "mutate to add a new variable\n\nhotels %>%\n  mutate(little_ones = children + babies) %>% #<<\n  select(children, babies, little_ones) %>%\n  arrange(desc(little_ones))\n\n# A tibble: 119,390 x 3\n  children babies little_ones\n     <dbl>  <dbl>       <dbl>\n1       10      0          10\n2        0     10          10\n3        0      9           9\n4        2      1           3\n5        2      1           3\n6        2      1           3\n# ... with 119,384 more rows"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#little-ones-in-resort-and-city-hotels",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#little-ones-in-resort-and-city-hotels",
    "title": "Working with a single data frame",
    "section": "Little ones in resort and city hotels",
    "text": "Little ones in resort and city hotels\n.midi[ .pull-left[] .pull-right[]]\n\n.question[ What is happening in the following chunk?]\n.midi[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#summarise-for-summary-stats",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#summarise-for-summary-stats",
    "title": "Working with a single data frame",
    "section": "summarise for summary stats",
    "text": "summarise for summary stats\n\n# mean average daily rate for all bookings\nhotels %>%\n  summarise(mean_adr = mean(adr)) #<<\n\n# A tibble: 1 x 1\n  mean_adr\n     <dbl>\n1     102.\n\n\n–\n.pull-left-wide[ .tip[ summarise() changes the data frame entirely, it collapses rows down to a single summary statistic, and removes all columns that are irrelevant to the calculation.]]\n\n.tip[ summarise() also lets you get away with being sloppy and not naming your new column, but that’s not recommended!]\n.pull-left[ ❌] .pull-right[ ✅]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#group_by-for-grouped-operations",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#group_by-for-grouped-operations",
    "title": "Working with a single data frame",
    "section": "group_by for grouped operations",
    "text": "group_by for grouped operations\n\n# mean average daily rate for all booking at city and resort hotels\nhotels %>%\n  group_by(hotel) %>% #<<\n  summarise(mean_adr = mean(adr))\n\n# A tibble: 2 x 2\n  hotel        mean_adr\n  <chr>           <dbl>\n1 City Hotel      105. \n2 Resort Hotel     95.0"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#calculating-frequencies",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#calculating-frequencies",
    "title": "Working with a single data frame",
    "section": "Calculating frequencies",
    "text": "Calculating frequencies\nThe following two give the same result, so count is simply short for group_by then determine frequencies\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d07-single-df/u2-d07-single-df.html#multiple-summary-statistics",
    "href": "slides/u2-d07-single-df/u2-d07-single-df.html#multiple-summary-statistics",
    "title": "Working with a single data frame",
    "section": "Multiple summary statistics",
    "text": "Multiple summary statistics\nsummarise can be used for multiple summary statistics as well\n\nhotels %>%\n  summarise(\n    min_adr = min(adr),\n    mean_adr = mean(adr),\n    median_adr = median(adr),\n    max_adr = max(adr)\n    )\n\n# A tibble: 1 x 4\n  min_adr mean_adr median_adr max_adr\n    <dbl>    <dbl>      <dbl>   <dbl>\n1   -6.38     102.       94.6    5400\n\n\n\n.your-turn[ ### Your turn!]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html",
    "title": "Working with multiple data frames",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#data-women-in-science",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#data-women-in-science",
    "title": "Working with multiple data frames",
    "section": "Data: Women in science",
    "text": "Data: Women in science\nInformation on 10 women in science who changed the world\n.small[]\n.footnote[ Source: Discover Magazine]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inputs",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inputs",
    "title": "Working with multiple data frames",
    "section": "Inputs",
    "text": "Inputs\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#desired-output",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#desired-output",
    "title": "Working with multiple data frames",
    "section": "Desired output",
    "text": "Desired output\n\n\n# A tibble: 10 x 5\n   name               profession          birth~1 death~2 known~3\n   <chr>              <chr>                 <dbl>   <dbl> <chr>  \n 1 Ada Lovelace       Mathematician            NA      NA first ~\n 2 Marie Curie        Physicist and Chem~      NA      NA theory~\n 3 Janaki Ammal       Botanist               1897    1984 hybrid~\n 4 Chien-Shiung Wu    Physicist              1912    1997 confim~\n 5 Katherine Johnson  Mathematician          1918    2020 calcul~\n 6 Rosalind Franklin  Chemist                1920    1958 <NA>   \n 7 Vera Rubin         Astronomer             1928    2016 existe~\n 8 Gladys West        Mathematician          1930      NA mathem~\n 9 Flossie Wong-Staal Virologist and Mol~    1947      NA first ~\n10 Jennifer Doudna    Biochemist             1964      NA one of~\n# ... with abbreviated variable names 1: birth_year,\n#   2: death_year, 3: known_for"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inputs-reminder",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inputs-reminder",
    "title": "Working with multiple data frames",
    "section": "Inputs, reminder",
    "text": "Inputs, reminder\n.pull-left[] .pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#joining-data-frames-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#joining-data-frames-1",
    "title": "Working with multiple data frames",
    "section": "Joining data frames",
    "text": "Joining data frames\n\nsomething_join(x, y)\n\n\nleft_join(): all rows from x\nright_join(): all rows from y\nfull_join(): all rows from both x and y\nsemi_join(): all rows from x where there are matching values in y, keeping just columns from x\ninner_join(): all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches\nanti_join(): return all rows from x where there are not matching values in y, never duplicate rows of x\n…"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#setup",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#setup",
    "title": "Working with multiple data frames",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#left_join",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#left_join",
    "title": "Working with multiple data frames",
    "section": "left_join()",
    "text": "left_join()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#left_join-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#left_join-1",
    "title": "Working with multiple data frames",
    "section": "left_join()",
    "text": "left_join()\n\nprofessions %>%\n  left_join(dates) #<<\n\n# A tibble: 10 x 4\n   name               profession                  birth~1 death~2\n   <chr>              <chr>                         <dbl>   <dbl>\n 1 Ada Lovelace       Mathematician                    NA      NA\n 2 Marie Curie        Physicist and Chemist            NA      NA\n 3 Janaki Ammal       Botanist                       1897    1984\n 4 Chien-Shiung Wu    Physicist                      1912    1997\n 5 Katherine Johnson  Mathematician                  1918    2020\n 6 Rosalind Franklin  Chemist                        1920    1958\n 7 Vera Rubin         Astronomer                     1928    2016\n 8 Gladys West        Mathematician                  1930      NA\n 9 Flossie Wong-Staal Virologist and Molecular B~    1947      NA\n10 Jennifer Doudna    Biochemist                     1964      NA\n# ... with abbreviated variable names 1: birth_year,\n#   2: death_year"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#right_join",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#right_join",
    "title": "Working with multiple data frames",
    "section": "right_join()",
    "text": "right_join()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#right_join-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#right_join-1",
    "title": "Working with multiple data frames",
    "section": "right_join()",
    "text": "right_join()\n\nprofessions %>%\n  right_join(dates) #<<\n\n# A tibble: 8 x 4\n  name               profession                   birth~1 death~2\n  <chr>              <chr>                          <dbl>   <dbl>\n1 Janaki Ammal       Botanist                        1897    1984\n2 Chien-Shiung Wu    Physicist                       1912    1997\n3 Katherine Johnson  Mathematician                   1918    2020\n4 Rosalind Franklin  Chemist                         1920    1958\n5 Vera Rubin         Astronomer                      1928    2016\n6 Gladys West        Mathematician                   1930      NA\n7 Flossie Wong-Staal Virologist and Molecular Bi~    1947      NA\n8 Jennifer Doudna    Biochemist                      1964      NA\n# ... with abbreviated variable names 1: birth_year,\n#   2: death_year"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#full_join",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#full_join",
    "title": "Working with multiple data frames",
    "section": "full_join()",
    "text": "full_join()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#full_join-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#full_join-1",
    "title": "Working with multiple data frames",
    "section": "full_join()",
    "text": "full_join()\n\ndates %>%\n  full_join(works) #<<\n\n# A tibble: 10 x 4\n   name               birth_year death_year known_for            \n   <chr>                   <dbl>      <dbl> <chr>                \n 1 Janaki Ammal             1897       1984 hybrid species, biod~\n 2 Chien-Shiung Wu          1912       1997 confim and refine th~\n 3 Katherine Johnson        1918       2020 calculations of orbi~\n 4 Rosalind Franklin        1920       1958 <NA>                 \n 5 Vera Rubin               1928       2016 existence of dark ma~\n 6 Gladys West              1930         NA mathematical modelin~\n 7 Flossie Wong-Staal       1947         NA first scientist to c~\n 8 Jennifer Doudna          1964         NA one of the primary d~\n 9 Ada Lovelace               NA         NA first computer algor~\n10 Marie Curie                NA         NA theory of radioactiv~"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inner_join",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inner_join",
    "title": "Working with multiple data frames",
    "section": "inner_join()",
    "text": "inner_join()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inner_join-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#inner_join-1",
    "title": "Working with multiple data frames",
    "section": "inner_join()",
    "text": "inner_join()\n\ndates %>%\n  inner_join(works) #<<\n\n# A tibble: 7 x 4\n  name               birth_year death_year known_for             \n  <chr>                   <dbl>      <dbl> <chr>                 \n1 Janaki Ammal             1897       1984 hybrid species, biodi~\n2 Chien-Shiung Wu          1912       1997 confim and refine the~\n3 Katherine Johnson        1918       2020 calculations of orbit~\n4 Vera Rubin               1928       2016 existence of dark mat~\n5 Gladys West              1930         NA mathematical modeling~\n6 Flossie Wong-Staal       1947         NA first scientist to cl~\n7 Jennifer Doudna          1964         NA one of the primary de~"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#semi_join",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#semi_join",
    "title": "Working with multiple data frames",
    "section": "semi_join()",
    "text": "semi_join()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#semi_join-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#semi_join-1",
    "title": "Working with multiple data frames",
    "section": "semi_join()",
    "text": "semi_join()\n\ndates %>%\n  semi_join(works) #<<\n\n# A tibble: 7 x 3\n  name               birth_year death_year\n  <chr>                   <dbl>      <dbl>\n1 Janaki Ammal             1897       1984\n2 Chien-Shiung Wu          1912       1997\n3 Katherine Johnson        1918       2020\n4 Vera Rubin               1928       2016\n5 Gladys West              1930         NA\n6 Flossie Wong-Staal       1947         NA\n7 Jennifer Doudna          1964         NA"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#anti_join",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#anti_join",
    "title": "Working with multiple data frames",
    "section": "anti_join()",
    "text": "anti_join()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#anti_join-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#anti_join-1",
    "title": "Working with multiple data frames",
    "section": "anti_join()",
    "text": "anti_join()\n\ndates %>%\n  anti_join(works) #<<\n\n# A tibble: 1 x 3\n  name              birth_year death_year\n  <chr>                  <dbl>      <dbl>\n1 Rosalind Franklin       1920       1958"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#putting-it-altogether",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#putting-it-altogether",
    "title": "Working with multiple data frames",
    "section": "Putting it altogether",
    "text": "Putting it altogether\n\nprofessions %>%\n  left_join(dates) %>%\n  left_join(works)\n\n# A tibble: 10 x 5\n   name               profession          birth~1 death~2 known~3\n   <chr>              <chr>                 <dbl>   <dbl> <chr>  \n 1 Ada Lovelace       Mathematician            NA      NA first ~\n 2 Marie Curie        Physicist and Chem~      NA      NA theory~\n 3 Janaki Ammal       Botanist               1897    1984 hybrid~\n 4 Chien-Shiung Wu    Physicist              1912    1997 confim~\n 5 Katherine Johnson  Mathematician          1918    2020 calcul~\n 6 Rosalind Franklin  Chemist                1920    1958 <NA>   \n 7 Vera Rubin         Astronomer             1928    2016 existe~\n 8 Gladys West        Mathematician          1930      NA mathem~\n 9 Flossie Wong-Staal Virologist and Mol~    1947      NA first ~\n10 Jennifer Doudna    Biochemist             1964      NA one of~\n# ... with abbreviated variable names 1: birth_year,\n#   2: death_year, 3: known_for\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#student-records",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#student-records",
    "title": "Working with multiple data frames",
    "section": "Student records",
    "text": "Student records\n\nHave:\n\nEnrolment: official university enrolment records\nSurvey: Student provided info missing students who never filled it out and including students who filled it out but dropped the class\n\nWant: Survey info for all enrolled in class\n\n–\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#student-records-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#student-records-1",
    "title": "Working with multiple data frames",
    "section": "Student records",
    "text": "Student records\n.panelset[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#grocery-sales",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#grocery-sales",
    "title": "Working with multiple data frames",
    "section": "Grocery sales",
    "text": "Grocery sales\n\nHave:\n\nPurchases: One row per customer per item, listing purchases they made\nPrices: One row per item in the store, listing their prices\n\nWant: Total revenue\n\n–\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d08-multi-df/u2-d08-multi-df.html#grocery-sales-1",
    "href": "slides/u2-d08-multi-df/u2-d08-multi-df.html#grocery-sales-1",
    "title": "Working with multiple data frames",
    "section": "Grocery sales",
    "text": "Grocery sales\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html",
    "title": "Tidying data",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#data-sales",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#data-sales",
    "title": "Tidying data",
    "section": "Data: Sales",
    "text": "Data: Sales\n\n.pull-left[ ### .green[We have…]]\n\n\n\n\n\n\n.pull-right[ ### .pink[We want…]\n\n\n::: {.cell layout-align=“center”} ::: {.cell-output .cell-output-stdout}\n\n\n]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#a-grammar-of-data-tidying",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#a-grammar-of-data-tidying",
    "title": "Tidying data",
    "section": "A grammar of data tidying",
    "text": "A grammar of data tidying\n.pull-left[] .pull-right[ The goal of tidyr is to help you tidy your data via]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#not-this",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#not-this",
    "title": "Tidying data",
    "section": "Not this…",
    "text": "Not this…"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#but-this",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#but-this",
    "title": "Tidying data",
    "section": "but this!",
    "text": "but this!\n.center[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#wider-vs.-longer",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#wider-vs.-longer",
    "title": "Tidying data",
    "section": "Wider vs. longer",
    "text": "Wider vs. longer\n.pull-left[ ### .green[wider] more columns]\n\n\n\n\n\n\n.pull-right[ ### .pink[longer] more rows\n\n\n::: {.cell layout-align=“center”} ::: {.cell-output .cell-output-stdout}\n\n\n]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n.pull-left[ - data (as usual)] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer-1",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer-1",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n.pull-left[ - data (as usual) - cols: columns to pivot into longer format ] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer-2",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer-2",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n.pull-left[ - data (as usual) - cols: columns to pivot into longer format - names_to: name of the column where column names of pivoted variables go (character string)] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer-3",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot_longer-3",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n.pull-left[ - data (as usual) - cols: columns to pivot into longer format - names_to: name of the column where column names of pivoted variables go (character string) - values_to: name of the column where data in pivoted variables go (character string)] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#customers-rightarrow-purchases",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#customers-rightarrow-purchases",
    "title": "Tidying data",
    "section": "Customers \\(\\rightarrow\\) purchases",
    "text": "Customers \\(\\rightarrow\\) purchases\n\npurchases <- customers %>%\n  pivot_longer( #<<\n    cols = item_1:item_3,  # variables item_1 to item_3 #<<\n    names_to = \"item_no\",  # column names -> new column called item_no #<<\n    values_to = \"item\"     # values in columns -> new column called item #<<\n    ) #<<\n\npurchases\n\n# A tibble: 6 x 3\n  customer_id item_no item        \n        <dbl> <chr>   <chr>       \n1           1 item_1  bread       \n2           1 item_2  milk        \n3           1 item_3  banana      \n4           2 item_1  milk        \n5           2 item_2  toilet paper\n6           2 item_3  <NA>"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#why-pivot",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#why-pivot",
    "title": "Tidying data",
    "section": "Why pivot?",
    "text": "Why pivot?\nMost likely, because the next step of your analysis needs it\n–\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#purchases-rightarrow-customers",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#purchases-rightarrow-customers",
    "title": "Tidying data",
    "section": "Purchases \\(\\rightarrow\\) customers",
    "text": "Purchases \\(\\rightarrow\\) customers\n.pull-left-narrow[ - data (as usual) - names_from: which column in the long format contains the what should be column names in the wide format - values_from: which column in the long format contains the what should be values in the new columns in the wide format] .pull-right-wide[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#data",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#data",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data\n\ntrump\n\n# A tibble: 2,702 x 4\n   subgroup date       approval disapproval\n   <chr>    <date>        <dbl>       <dbl>\n 1 Voters   2020-10-04     44.7        52.2\n 2 Adults   2020-10-04     43.2        52.6\n 3 Adults   2020-10-03     43.2        52.6\n 4 Voters   2020-10-03     45.0        51.7\n 5 Adults   2020-10-02     43.3        52.4\n 6 Voters   2020-10-02     44.5        52.1\n 7 Voters   2020-10-01     44.1        52.8\n 8 Adults   2020-10-01     42.7        53.3\n 9 Adults   2020-09-30     42.2        53.7\n10 Voters   2020-09-30     44.2        52.7\n# ... with 2,692 more rows"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#goal",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#goal",
    "title": "Tidying data",
    "section": "Goal",
    "text": "Goal\n.pull-left-wide[] – .pull-right-narrow[ Aesthetic mappings:\n✅ x = date\n❌ y = rating_value\n❌ color = rating_type]"
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#pivot",
    "title": "Tidying data",
    "section": "Pivot",
    "text": "Pivot\n\ntrump_longer <- trump %>%\n  pivot_longer(\n    cols = c(approval, disapproval),\n    names_to = \"rating_type\",\n    values_to = \"rating_value\"\n  )\n\ntrump_longer\n\n# A tibble: 5,404 x 4\n   subgroup date       rating_type rating_value\n   <chr>    <date>     <chr>              <dbl>\n 1 Voters   2020-10-04 approval            44.7\n 2 Voters   2020-10-04 disapproval         52.2\n 3 Adults   2020-10-04 approval            43.2\n 4 Adults   2020-10-04 disapproval         52.6\n 5 Adults   2020-10-03 approval            43.2\n 6 Adults   2020-10-03 disapproval         52.6\n 7 Voters   2020-10-03 approval            45.0\n 8 Voters   2020-10-03 disapproval         51.7\n..."
  },
  {
    "objectID": "slides/u2-d09-tidying/u2-d09-tidying.html#plot",
    "href": "slides/u2-d09-tidying/u2-d09-tidying.html#plot",
    "title": "Tidying data",
    "section": "Plot",
    "text": "Plot\n\nggplot(trump_longer, \n       aes(x = date, y = rating_value, color = rating_type, group = rating_type)) +\n  geom_line() +\n  facet_wrap(~ subgroup)\n\n\n\n\n\n\n\n\n\n.panelset[]\n\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html",
    "title": "Data types",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#example-cat-lovers",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#example-cat-lovers",
    "title": "Data types",
    "section": "Example: Cat lovers",
    "text": "Example: Cat lovers\nA survey asked respondents their name and number of cats. The instructions said to enter the number of cats as a numerical value.\n\ncat_lovers <- read_csv(\"data/cat-lovers.csv\")\n\n\n\n# A tibble: 60 x 3\n  name           number_of_cats handedness\n  <chr>          <chr>          <chr>     \n1 Bernice Warren 0              left      \n2 Woodrow Stone  0              left      \n3 Willie Bass    1              left      \n4 Tyrone Estrada 3              left      \n5 Alex Daniels   3              left      \n6 Jane Bates     2              left      \n# ... with 54 more rows"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#oh-why-wont-you-work",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#oh-why-wont-you-work",
    "title": "Data types",
    "section": "Oh why won’t you work?!",
    "text": "Oh why won’t you work?!\n\ncat_lovers %>%\n  summarise(mean_cats = mean(number_of_cats))\n\nWarning in mean.default(number_of_cats): argument is not numeric\nor logical: returning NA\n\n\n# A tibble: 1 x 1\n  mean_cats\n      <dbl>\n1        NA\n\n\n\n\n?mean"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#oh-why-wont-you-still-work",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#oh-why-wont-you-still-work",
    "title": "Data types",
    "section": "Oh why won’t you still work??!!",
    "text": "Oh why won’t you still work??!!\n\ncat_lovers %>%\n  summarise(mean_cats = mean(number_of_cats, na.rm = TRUE))\n\nWarning in mean.default(number_of_cats, na.rm = TRUE): argument\nis not numeric or logical: returning NA\n\n\n# A tibble: 1 x 1\n  mean_cats\n      <dbl>\n1        NA"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#take-a-breath-and-look-at-your-data",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#take-a-breath-and-look-at-your-data",
    "title": "Data types",
    "section": "Take a breath and look at your data",
    "text": "Take a breath and look at your data\n.question[ What is the type of the number_of_cats variable?]\n\nglimpse(cat_lovers)\n\nRows: 60\nColumns: 3\n$ name           <chr> \"Bernice Warren\", \"Woodrow Stone\", \"Will~\n$ number_of_cats <chr> \"0\", \"0\", \"1\", \"3\", \"3\", \"2\", \"1\", \"1\", ~\n$ handedness     <chr> \"left\", \"left\", \"left\", \"left\", \"left\", ~"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#lets-take-another-look",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#lets-take-another-look",
    "title": "Data types",
    "section": "Let’s take another look",
    "text": "Let’s take another look\n.small[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#sometimes-you-might-need-to-babysit-your-respondents",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#sometimes-you-might-need-to-babysit-your-respondents",
    "title": "Data types",
    "section": "Sometimes you might need to babysit your respondents",
    "text": "Sometimes you might need to babysit your respondents\n.midi[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#always-you-need-to-respect-data-types",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#always-you-need-to-respect-data-types",
    "title": "Data types",
    "section": "Always you need to respect data types",
    "text": "Always you need to respect data types\n\ncat_lovers %>%\n  mutate(\n    number_of_cats = case_when(\n      name == \"Ginger Clark\" ~ \"2\",\n      name == \"Doug Bass\"    ~ \"3\",\n      TRUE                   ~ number_of_cats\n      ),\n    number_of_cats = as.numeric(number_of_cats)\n    ) %>%\n  summarise(mean_cats = mean(number_of_cats))\n\n# A tibble: 1 x 1\n  mean_cats\n      <dbl>\n1     0.833"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#now-that-we-know-what-were-doing",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#now-that-we-know-what-were-doing",
    "title": "Data types",
    "section": "Now that we know what we’re doing…",
    "text": "Now that we know what we’re doing…\n\ncat_lovers <- cat_lovers %>% #<<\n  mutate(\n    number_of_cats = case_when(\n      name == \"Ginger Clark\" ~ \"2\",\n      name == \"Doug Bass\"    ~ \"3\",\n      TRUE                   ~ number_of_cats\n      ),\n    number_of_cats = as.numeric(number_of_cats)\n    )"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#moral-of-the-story",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#moral-of-the-story",
    "title": "Data types",
    "section": "Moral of the story",
    "text": "Moral of the story\n\nIf your data does not behave how you expect it to, type coercion upon reading in the data might be the reason.\nGo in and investigate your data, apply the fix, save your data, live happily ever after.\n\n\nclass: middle\n.hand[.light-blue[now that we have a good motivation for]]\n.hand[.light-blue[learning about data types in R]]\n\n.large[ .hand[.light-blue[let’s learn about data types in R!]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#data-types-in-r",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#data-types-in-r",
    "title": "Data types",
    "section": "Data types in R",
    "text": "Data types in R\n\nlogical\ndouble\ninteger\ncharacter\nand some more, but we won’t be focusing on those"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#logical-character",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#logical-character",
    "title": "Data types",
    "section": "Logical & character",
    "text": "Logical & character\n.pull-left[ logical - boolean values TRUE and FALSE] .pull-right[ character - character strings]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#double-integer",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#double-integer",
    "title": "Data types",
    "section": "Double & integer",
    "text": "Double & integer\n.pull-left[ double - floating point numerical values (default numerical type)] .pull-right[ integer - integer numerical values (indicated with an L)]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#concatenation",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#concatenation",
    "title": "Data types",
    "section": "Concatenation",
    "text": "Concatenation\nVectors can be constructed using the c() function.\n\nc(1, 2, 3)\n\n[1] 1 2 3\n\nc(\"Hello\", \"World!\")\n\n[1] \"Hello\"  \"World!\"\n\nc(c(\"hi\", \"hello\"), c(\"bye\", \"jello\"))\n\n[1] \"hi\"    \"hello\" \"bye\"   \"jello\""
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#converting-between-types",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#converting-between-types",
    "title": "Data types",
    "section": "Converting between types",
    "text": "Converting between types\n.hand[with intention…]\n.pull-left[] – .pull-right[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#converting-between-types-1",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#converting-between-types-1",
    "title": "Data types",
    "section": "Converting between types",
    "text": "Converting between types\n.hand[with intention…]\n.pull-left[] – .pull-right[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#converting-between-types-2",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#converting-between-types-2",
    "title": "Data types",
    "section": "Converting between types",
    "text": "Converting between types\n.hand[without intention…]\nR will happily convert between various types without complaint when different types of data are concatenated in a vector, and that’s not always a great thing!\n.pull-left[] – .pull-right[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#explicit-vs.-implicit-coercion",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#explicit-vs.-implicit-coercion",
    "title": "Data types",
    "section": "Explicit vs. implicit coercion",
    "text": "Explicit vs. implicit coercion\nLet’s give formal names to what we’ve seen so far:\n\n\n\n\n\n\n- Explicit coercion is when you call a function like as.logical(), as.numeric(), as.integer(), as.double(), or as.character()\n\n\n\n\n- Implicit coercion happens when you use a vector in a specific context that expects a certain type of vector\n\n\n\n.midi[ .your-turn[ ### .hand[Your turn!]]]\n–\n.small[ Example: Suppose we want to know the type of c(1, \"a\"). First, I’d look at: ]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#special-values-1",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#special-values-1",
    "title": "Data types",
    "section": "Special values",
    "text": "Special values\n\nNA: Not available\nNaN: Not a number\nInf: Positive infinity\n-Inf: Negative infinity\n\n–\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#nas-are-special-s",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#nas-are-special-s",
    "title": "Data types",
    "section": "NAs are special ❄️s",
    "text": "NAs are special ❄️s\n\nx <- c(1, 2, 3, 4, NA)\n\n\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 2.5\n\nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00    1.75    2.50    2.50    3.25    4.00       1"
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#nas-are-logical",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#nas-are-logical",
    "title": "Data types",
    "section": "NAs are logical",
    "text": "NAs are logical\nR uses NA to represent missing values in its data structures.\n\ntypeof(NA)\n\n[1] \"logical\""
  },
  {
    "objectID": "slides/u2-d10-data-types/u2-d10-data-types.html#mental-model-for-nas",
    "href": "slides/u2-d10-data-types/u2-d10-data-types.html#mental-model-for-nas",
    "title": "Data types",
    "section": "Mental model for NAs",
    "text": "Mental model for NAs\n\nUnlike NaN, NAs are genuinely unknown values\nBut that doesn’t mean they can’t function in a logical way\nLet’s think about why NAs are logical…\n\n–\n.question[ Why do the following give different answers?] .pull-left[] .pull-right[]\n\\(\\rightarrow\\) See next slide for answers…\n\n\nNA is unknown, so it could be TRUE or FALSE\n\n.pull-left[ .midi[ - TRUE | NA]] .pull-right[ .midi[ - FALSE | NA]]\n\nDoesn’t make sense for mathematical operations\nMakes sense in the context of missing data"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html",
    "title": "Data classes",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#data-classes-1",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#data-classes-1",
    "title": "Data classes",
    "section": "Data classes",
    "text": "Data classes\nWe talked about types so far, next we’ll introduce the concept of classes\n\nVectors are like Lego building blocks\n\n\n\n\n- We stick them together to build more complicated constructs, e.g. representations of data\n\n\n\n\n- The class attribute relates to the S3 class of an object which determines its behaviour - You don’t need to worry about what S3 classes really mean, but you can read more about it here if you’re curious\n\n\n\n\nExamples: factors, dates, and data frames"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#factors",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#factors",
    "title": "Data classes",
    "section": "Factors",
    "text": "Factors\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values\n\nx <- factor(c(\"BS\", \"MS\", \"PhD\", \"MS\"))\nx\n\n[1] BS  MS  PhD MS \nLevels: BS MS PhD\n\n\n–\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#more-on-factors",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#more-on-factors",
    "title": "Data classes",
    "section": "More on factors",
    "text": "More on factors\nWe can think of factors like character (level labels) and an integer (level numbers) glued together\n\nglimpse(x)\n\n Factor w/ 3 levels \"BS\",\"MS\",\"PhD\": 1 2 3 2\n\nas.integer(x)\n\n[1] 1 2 3 2"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#dates",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#dates",
    "title": "Data classes",
    "section": "Dates",
    "text": "Dates\n\ny <- as.Date(\"2020-01-01\")\ny\n\n[1] \"2020-01-01\"\n\ntypeof(y)\n\n[1] \"double\"\n\nclass(y)\n\n[1] \"Date\""
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#more-on-dates",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#more-on-dates",
    "title": "Data classes",
    "section": "More on dates",
    "text": "More on dates\nWe can think of dates like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together\n\nas.integer(y)\n\n[1] 18262\n\nas.integer(y) / 365 # roughly 50 yrs\n\n[1] 50.03288"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#data-frames",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#data-frames",
    "title": "Data classes",
    "section": "Data frames",
    "text": "Data frames\nWe can think of data frames like like vectors of equal length glued together\n\ndf <- data.frame(x = 1:2, y = 3:4)\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#lists",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#lists",
    "title": "Data classes",
    "section": "Lists",
    "text": "Lists\nLists are a generic vector container vectors of any type can go in them\n\nl <- list(\n  x = 1:4,\n  y = c(\"hi\", \"hello\", \"jello\"),\n  z = c(TRUE, FALSE)\n)\nl\n\n$x\n[1] 1 2 3 4\n\n$y\n[1] \"hi\"    \"hello\" \"jello\"\n\n$z\n[1]  TRUE FALSE"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#lists-and-data-frames",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#lists-and-data-frames",
    "title": "Data classes",
    "section": "Lists and data frames",
    "text": "Lists and data frames\n\nA data frame is a special list containing vectors of equal length\nWhen we use the pull() function, we extract a vector from the data frame\n\n\ndf\n\n  x y\n1 1 3\n2 2 4\n\ndf %>%\n  pull(y)\n\n[1] 3 4\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#read-data-in-as-character-strings",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#read-data-in-as-character-strings",
    "title": "Data classes",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nglimpse(cat_lovers)\n\nRows: 60\nColumns: 3\n$ name           <chr> \"Bernice Warren\", \"Woodrow Stone\", \"Will~\n$ number_of_cats <chr> \"0\", \"0\", \"1\", \"3\", \"3\", \"2\", \"1\", \"1\", ~\n$ handedness     <chr> \"left\", \"left\", \"left\", \"left\", \"left\", ~"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#but-coerce-when-plotting",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#but-coerce-when-plotting",
    "title": "Data classes",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(cat_lovers, mapping = aes(x = handedness)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#use-forcats-to-manipulate-factors",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#use-forcats-to-manipulate-factors",
    "title": "Data classes",
    "section": "Use forcats to manipulate factors",
    "text": "Use forcats to manipulate factors\n\ncat_lovers %>%\n  mutate(handedness = fct_infreq(handedness)) %>% #<<\n  ggplot(mapping = aes(x = handedness)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#come-for-the-functionality",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#come-for-the-functionality",
    "title": "Data classes",
    "section": "Come for the functionality",
    "text": "Come for the functionality\n.pull-left[ … stay for the logo] .pull-right[]\n.pull-left-wide[ - Factors are useful when you have true categorical data and you want to override the ordering of character vectors to improve display - They are also useful in modeling scenarios - The forcats package provides a suite of useful tools that solve common problems with factors]\n\n.small[ .your-turn[ ### .hand[Your turn!] ]]\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#make-a-date",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#make-a-date",
    "title": "Data classes",
    "section": "Make a date",
    "text": "Make a date\n.pull-left[] .pull-right[ - lubridate is the tidyverse-friendly package that makes dealing with dates a little easier - It’s not one of the core tidyverse packages, hence it’s installed with install.packages(\"tidyverse) but it’s not loaded with it, and needs to be explicitly loaded with library(lubridate)]\n\nclass: middle\n.hand[.light-blue[ we’re just going to scratch the surface of working with dates in R here…]]\n\n.question[ Calculate and visualise the number of bookings on any given arrival date.]\n\nhotels %>%\n  select(starts_with(\"arrival_\"))\n\n# A tibble: 119,390 x 4\n  arrival_date_year arrival_date_month arrival_date_wee~1 arriv~2\n              <dbl> <chr>                           <dbl>   <dbl>\n1              2015 July                               27       1\n2              2015 July                               27       1\n3              2015 July                               27       1\n4              2015 July                               27       1\n5              2015 July                               27       1\n6              2015 July                               27       1\n# ... with 119,384 more rows, and abbreviated variable names\n#   1: arrival_date_week_number, 2: arrival_date_day_of_month"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-1.-construct-dates",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-1.-construct-dates",
    "title": "Data classes",
    "section": "Step 1. Construct dates",
    "text": "Step 1. Construct dates\n.midi[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-2.-count-bookings-per-date",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-2.-count-bookings-per-date",
    "title": "Data classes",
    "section": "Step 2. Count bookings per date",
    "text": "Step 2. Count bookings per date\n.midi[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-3.-visualise-bookings-per-date",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-3.-visualise-bookings-per-date",
    "title": "Data classes",
    "section": "Step 3. Visualise bookings per date",
    "text": "Step 3. Visualise bookings per date\n.midi[]\n\n.hand[zooming in a bit…]\n.question[ Why does the plot start with August when we know our data start in July? And why does 10 August come after 1 August?]\n.midi[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-1.-revised-construct-dates-as-dates",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-1.-revised-construct-dates-as-dates",
    "title": "Data classes",
    "section": "Step 1. REVISED Construct dates “as dates”",
    "text": "Step 1. REVISED Construct dates “as dates”\n.midi[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-2.-count-bookings-per-date-1",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-2.-count-bookings-per-date-1",
    "title": "Data classes",
    "section": "Step 2. Count bookings per date",
    "text": "Step 2. Count bookings per date\n.midi[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-3a.-visualise-bookings-per-date",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-3a.-visualise-bookings-per-date",
    "title": "Data classes",
    "section": "Step 3a. Visualise bookings per date",
    "text": "Step 3a. Visualise bookings per date\n.midi[]"
  },
  {
    "objectID": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-3b.-visualise-using-a-smooth-curve",
    "href": "slides/u2-d11-data-classes/u2-d11-data-classes.html#step-3b.-visualise-using-a-smooth-curve",
    "title": "Data classes",
    "section": "Step 3b. Visualise using a smooth curve",
    "text": "Step 3b. Visualise using a smooth curve\n.midi[]"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html",
    "title": "Importing data",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#reading-data",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#reading-data",
    "title": "Importing data",
    "section": "Reading data",
    "text": "Reading data\n\nnobel <- read_csv(file = \"data/nobel.csv\")\nnobel\n\n# A tibble: 935 x 26\n     id firstname     surname  year categ~1 affil~2 city  country\n  <dbl> <chr>         <chr>   <dbl> <chr>   <chr>   <chr> <chr>  \n1     1 Wilhelm Conr~ Röntgen  1901 Physics Munich~ Muni~ Germany\n2     2 Hendrik A.    Lorentz  1902 Physics Leiden~ Leid~ Nether~\n3     3 Pieter        Zeeman   1902 Physics Amster~ Amst~ Nether~\n4     4 Henri         Becque~  1903 Physics École ~ Paris France \n5     5 Pierre        Curie    1903 Physics École ~ Paris France \n6     6 Marie         Curie    1903 Physics <NA>    <NA>  <NA>   \n# ... with 929 more rows, 18 more variables: born_date <date>,\n#   died_date <date>, gender <chr>, born_city <chr>,\n#   born_country <chr>, born_country_code <chr>,\n#   died_city <chr>, died_country <chr>,\n#   died_country_code <chr>, overall_motivation <chr>,\n#   share <dbl>, motivation <chr>, born_country_original <chr>,\n#   born_city_original <chr>, died_country_original <chr>, ..."
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#writing-data",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#writing-data",
    "title": "Importing data",
    "section": "Writing data",
    "text": "Writing data\n.pull-left[ - Write a file]\n\n\n\n\n\n\n.pull-right[ - Read it back in to inspect\n\n\n::: {.cell layout-align=“center”}\n\n\n{.r .cell-code} read_csv(\"data/df.csv\")\n\n\n::: {.cell-output .cell-output-stdout}\n\n\n]\n\n\n\n.your-turn[ ### .hand[Your turn!]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#data-with-bad-names",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#data-with-bad-names",
    "title": "Importing data",
    "section": "Data with bad names",
    "text": "Data with bad names\n\nedibnb_badnames <- read_csv(\"data/edibnb-badnames.csv\")\nnames(edibnb_badnames)\n\n [1] \"ID\"                   \"Price\"               \n [3] \"neighbourhood\"        \"accommodates\"        \n [5] \"Number of bathrooms\"  \"Number of Bedrooms\"  \n [7] \"n beds\"               \"Review Scores Rating\"\n [9] \"Number of reviews\"    \"listing_url\"         \n\n\n–\n… but R doesn’t allow spaces in variable names\n\nggplot(edibnb_badnames, aes(x = Number of bathrooms, y = Price)) +\n  geom_point()\n\nError: <text>:1:40: unexpected symbol\n1: ggplot(edibnb_badnames, aes(x = Number of\n                                           ^"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#option-1---define-column-names",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#option-1---define-column-names",
    "title": "Importing data",
    "section": "Option 1 - Define column names",
    "text": "Option 1 - Define column names\n.small[]"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#option-2---format-text-to-snake_case",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#option-2---format-text-to-snake_case",
    "title": "Importing data",
    "section": "Option 2 - Format text to snake_case",
    "text": "Option 2 - Format text to snake_case\n\nedibnb_clean_names <- read_csv(\"data/edibnb-badnames.csv\") %>%\n  janitor::clean_names()\n\nnames(edibnb_clean_names)\n\n [1] \"id\"                   \"price\"               \n [3] \"neighbourhood\"        \"accommodates\"        \n [5] \"number_of_bathrooms\"  \"number_of_bedrooms\"  \n [7] \"n_beds\"               \"review_scores_rating\"\n [9] \"number_of_reviews\"    \"listing_url\"         \n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#option-1.-explicit-nas",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#option-1.-explicit-nas",
    "title": "Importing data",
    "section": "Option 1. Explicit NAs",
    "text": "Option 1. Explicit NAs\n\nread_csv(\"data/df-na.csv\", \n         na = c(\"\", \"NA\", \".\", \"9999\", \"Not applicable\"))\n\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#option-2.-specify-column-types",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#option-2.-specify-column-types",
    "title": "Importing data",
    "section": "Option 2. Specify column types",
    "text": "Option 2. Specify column types\n\nread_csv(\"data/df-na.csv\", col_types = list(col_double(), \n                                            col_character(), \n                                            col_character()))\n\n\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\n# A tibble: 9 x 3\n      x y              z     \n  <dbl> <chr>          <chr> \n1     1 a              hi    \n2    NA b              hello \n3     3 Not applicable 9999  \n4     4 d              ola   \n5     5 e              hola  \n6    NA f              whatup\n7     7 g              wassup\n8     8 h              sup   \n9     9 i              <NA>"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#column-types",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#column-types",
    "title": "Importing data",
    "section": "Column types",
    "text": "Column types\n.small[ type function | data type —————— | ————- col_character() | character col_date() | date col_datetime() | POSIXct (date-time) col_double() | double (numeric) col_factor() | factor col_guess() | let readr guess (default) col_integer() | integer col_logical() | logical col_number() | numbers mixed with non-number characters col_numeric() | double or integer col_skip() | do not read col_time() | time]\n\n.question[ Wondering where you remember these from?]\n\nread_csv(\"data/df-na.csv\")\n\nRows: 9 Columns: 3\n-- Column specification -----------------------------------------\nDelimiter: \",\"\nchr (3): x, y, z\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 9 x 3\n  x     y              z     \n  <chr> <chr>          <chr> \n1 1     a              hi    \n2 <NA>  b              hello \n3 3     Not applicable 9999  \n4 4     d              ola   \n...\n\n\n\nclass:middle"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#favourite-foods",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#favourite-foods",
    "title": "Importing data",
    "section": "Favourite foods",
    "text": "Favourite foods\n\n\n\n\n\n\n\n\n\n–\n\nfav_food <- read_excel(\"data/favourite-food.xlsx\") #<<\n\nfav_food\n\n# A tibble: 5 x 6\n  `Student ID` `Full Name`      favourite.f~1 mealP~2 AGE   SES  \n         <dbl> <chr>            <chr>         <chr>   <chr> <chr>\n1            1 Sunil Huffmann   Strawberry y~ Lunch ~ 4     High \n2            2 Barclay Lynn     French fries  Lunch ~ 5     Midd~\n3            3 Jayendra Lyne    N/A           Breakf~ 7     Low  \n4            4 Leon Rossini     Anchovies     Lunch ~ 99999 Midd~\n5            5 Chidiegwu Dunkel Pizza         Breakf~ five  High \n# ... with abbreviated variable names 1: favourite.food,\n#   2: mealPlan"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#variable-names-1",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#variable-names-1",
    "title": "Importing data",
    "section": "Variable names",
    "text": "Variable names\n\n\n\n\n\n\n\n\n\n–\n\nfav_food <- read_excel(\"data/favourite-food.xlsx\") %>%\n  janitor::clean_names() #<<\n\nfav_food \n\n# A tibble: 5 x 6\n  student_id full_name        favourite_food  meal_~1 age   ses  \n       <dbl> <chr>            <chr>           <chr>   <chr> <chr>\n1          1 Sunil Huffmann   Strawberry yog~ Lunch ~ 4     High \n2          2 Barclay Lynn     French fries    Lunch ~ 5     Midd~\n3          3 Jayendra Lyne    N/A             Breakf~ 7     Low  \n4          4 Leon Rossini     Anchovies       Lunch ~ 99999 Midd~\n5          5 Chidiegwu Dunkel Pizza           Breakf~ five  High \n# ... with abbreviated variable name 1: meal_plan"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#handling-nas",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#handling-nas",
    "title": "Importing data",
    "section": "Handling NAs",
    "text": "Handling NAs\n\n\n\n\n\n\n\n\n\n–\n\nfav_food <- read_excel(\"data/favourite-food.xlsx\",\n                       na = c(\"N/A\", \"99999\")) %>% #<<\n  janitor::clean_names()\n\nfav_food \n\n# A tibble: 5 x 6\n  student_id full_name        favourite_food  meal_~1 age   ses  \n       <dbl> <chr>            <chr>           <chr>   <chr> <chr>\n1          1 Sunil Huffmann   Strawberry yog~ Lunch ~ 4     High \n2          2 Barclay Lynn     French fries    Lunch ~ 5     Midd~\n3          3 Jayendra Lyne    <NA>            Breakf~ 7     Low  \n4          4 Leon Rossini     Anchovies       Lunch ~ <NA>  Midd~\n5          5 Chidiegwu Dunkel Pizza           Breakf~ five  High \n# ... with abbreviated variable name 1: meal_plan"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#make-age-numeric",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#make-age-numeric",
    "title": "Importing data",
    "section": "Make age numeric",
    "text": "Make age numeric\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#socio-economic-status",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#socio-economic-status",
    "title": "Importing data",
    "section": "Socio-economic status",
    "text": "Socio-economic status\n.question[ What order are the levels of ses listed in?]\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#make-ses-factor",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#make-ses-factor",
    "title": "Importing data",
    "section": "Make ses factor",
    "text": "Make ses factor\n.pull-left-wide[]"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#putting-it-altogether",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#putting-it-altogether",
    "title": "Importing data",
    "section": "Putting it altogether",
    "text": "Putting it altogether\n\nfav_food <- read_excel(\"data/favourite-food.xlsx\", na = c(\"N/A\", \"99999\")) %>%\n  janitor::clean_names() %>%\n  mutate(\n    age = if_else(age == \"five\", \"5\", age), \n    age = as.numeric(age),\n    ses = fct_relevel(ses, \"Low\", \"Middle\", \"High\")\n  )\n\nfav_food\n\n# A tibble: 5 x 6\n  student_id full_name        favourite_food  meal_~1   age ses  \n       <dbl> <chr>            <chr>           <chr>   <dbl> <fct>\n1          1 Sunil Huffmann   Strawberry yog~ Lunch ~     4 High \n2          2 Barclay Lynn     French fries    Lunch ~     5 Midd~\n3          3 Jayendra Lyne    <NA>            Breakf~     7 Low  \n4          4 Leon Rossini     Anchovies       Lunch ~    NA Midd~\n5          5 Chidiegwu Dunkel Pizza           Breakf~     5 High \n# ... with abbreviated variable name 1: meal_plan"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#out-and-back-in",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#out-and-back-in",
    "title": "Importing data",
    "section": "Out and back in",
    "text": "Out and back in\n\nwrite_csv(fav_food, file = \"data/fav-food-clean.csv\")\n\nfav_food_clean <- read_csv(\"data/fav-food-clean.csv\")\n\n\n.question[ What happened to ses again?]\n\nfav_food_clean %>%\n  count(ses)\n\n# A tibble: 3 x 2\n  ses        n\n  <chr>  <int>\n1 High       2\n2 Low        1\n3 Middle     2"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#read_rds-and-write_rds",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#read_rds-and-write_rds",
    "title": "Importing data",
    "section": "read_rds() and write_rds()",
    "text": "read_rds() and write_rds()\n\nCSVs can be unreliable for saving interim results if there is specific variable type information you want to hold on to.\nAn alternative is RDS files, you can read and write them with read_rds() and write_rds(), respectively.\n\n\nread_rds(path)\nwrite_rds(x, path)"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#out-and-back-in-take-2",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#out-and-back-in-take-2",
    "title": "Importing data",
    "section": "Out and back in, take 2",
    "text": "Out and back in, take 2\n\nwrite_rds(fav_food, file = \"data/fav-food-clean.rds\")\n\nfav_food_clean <- read_rds(\"data/fav-food-clean.rds\")\n\nfav_food_clean %>%\n  count(ses)\n\n# A tibble: 3 x 2\n  ses        n\n  <fct>  <int>\n1 Low        1\n2 Middle     2\n3 High       2\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d12-data-import/u2-d12-data-import.html#other-types-of-data-1",
    "href": "slides/u2-d12-data-import/u2-d12-data-import.html#other-types-of-data-1",
    "title": "Importing data",
    "section": "Other types of data",
    "text": "Other types of data\n\ngooglesheets4: Google Sheets\nhaven: SPSS, Stata, and SAS files\nDBI, along with a database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc): allows you to run SQL queries against a database and return a data frame\njsonline: JSON\nxml2: xml\nrvest: web scraping\nhttr: web APIs\nsparklyr: data loaded into spark\n\n\n.your-turn[ ### .hand[Your turn!] .midi[ - RStudio Cloud > AE 06 - Nobels and sales + Data import > sales-excel.Rmd. - Load the sales.xlsx file from the data-raw/ folder, using appropriate arguments for the read_excel() function such that it looks like the output on the left. - Stretch goal: Manipulate the sales data such that it looks like the output on the right.]]\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html",
    "title": "Recoding data",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#read-data",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#read-data",
    "title": "Recoding data",
    "section": "Read data",
    "text": "Read data\n\nlibrary(readxl)\nrel_inc <- read_excel(\"data/relig-income.xlsx\")\n\n.small[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#rename-columns",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#rename-columns",
    "title": "Recoding data",
    "section": "Rename columns",
    "text": "Rename columns\n.midi[]\n\n.question[ If we want a new variable called income with levels such as “Less than $30,000”, “$30,000-$49,999”, … etc. which function should we use?]\n\n\n# A tibble: 48 x 4\n   religion                   n income            proportion\n   <chr>                  <dbl> <chr>                  <dbl>\n 1 Buddhist                 233 Less than $30,000       0.36\n 2 Buddhist                 233 $30,000-$49,999         0.18\n 3 Buddhist                 233 $50,000-$99,999         0.32\n 4 Buddhist                 233 $100,000 or more        0.13\n 5 Catholic                6137 Less than $30,000       0.36\n 6 Catholic                6137 $30,000-$49,999         0.19\n 7 Catholic                6137 $50,000-$99,999         0.26\n 8 Catholic                6137 $100,000 or more        0.19\n 9 Evangelical Protestant  7462 Less than $30,000       0.35\n10 Evangelical Protestant  7462 $30,000-$49,999         0.22\n11 Evangelical Protestant  7462 $50,000-$99,999         0.28\n12 Evangelical Protestant  7462 $100,000 or more        0.14\n13 Hindu                    172 Less than $30,000       0.17\n14 Hindu                    172 $30,000-$49,999         0.13\n15 Hindu                    172 $50,000-$99,999         0.34\n# ... with 33 more rows"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#pivot-longer",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#pivot-longer",
    "title": "Recoding data",
    "section": "Pivot longer",
    "text": "Pivot longer\n.midi[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#calculate-frequencies",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#calculate-frequencies",
    "title": "Recoding data",
    "section": "Calculate frequencies",
    "text": "Calculate frequencies\n.midi[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#save-data",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#save-data",
    "title": "Recoding data",
    "section": "Save data",
    "text": "Save data\n\nrel_inc_long <- rel_inc %>% \n  rename(\n    religion = `Religious tradition`,\n    n = `Sample Size`\n  ) %>%\n  pivot_longer(\n    cols = -c(religion, n), \n    names_to = \"income\", \n    values_to = \"proportion\"\n  ) %>%\n  mutate(frequency = round(proportion * n))"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#barplot",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#barplot",
    "title": "Recoding data",
    "section": "Barplot",
    "text": "Barplot\n\nggplot(rel_inc_long, aes(y = religion, x = frequency)) +\n  geom_col()"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#recode-religion",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#recode-religion",
    "title": "Recoding data",
    "section": "Recode religion",
    "text": "Recode religion\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#reverse-religion-order",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#reverse-religion-order",
    "title": "Recoding data",
    "section": "Reverse religion order",
    "text": "Reverse religion order\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#add-income",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#add-income",
    "title": "Recoding data",
    "section": "Add income",
    "text": "Add income\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#fill-bars",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#fill-bars",
    "title": "Recoding data",
    "section": "Fill bars",
    "text": "Fill bars\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#change-colors",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#change-colors",
    "title": "Recoding data",
    "section": "Change colors",
    "text": "Change colors\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#change-theme",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#change-theme",
    "title": "Recoding data",
    "section": "Change theme",
    "text": "Change theme\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#move-legend-to-the-bottom",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#move-legend-to-the-bottom",
    "title": "Recoding data",
    "section": "Move legend to the bottom",
    "text": "Move legend to the bottom\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#legend-adjustments",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#legend-adjustments",
    "title": "Recoding data",
    "section": "Legend adjustments",
    "text": "Legend adjustments\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d13-data-recode/u2-d13-data-recode.html#fix-labels",
    "href": "slides/u2-d13-data-recode/u2-d13-data-recode.html#fix-labels",
    "title": "Recoding data",
    "section": "Fix labels",
    "text": "Fix labels\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html",
    "title": "Tips for effective data visualization",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#keep-it-simple",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#keep-it-simple",
    "title": "Tips for effective data visualization",
    "section": "Keep it simple",
    "text": "Keep it simple\n.pull-left-narrow[] .pull-right-wide[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-color-to-draw-attention",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-color-to-draw-attention",
    "title": "Tips for effective data visualization",
    "section": "Use color to draw attention",
    "text": "Use color to draw attention\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#tell-a-story",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#tell-a-story",
    "title": "Tips for effective data visualization",
    "section": "Tell a story",
    "text": "Tell a story\n\n\n\n\n\n\n\n\n\n.footnote[ Credit: Angela Zoss and Eric Monson, Duke DVS]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#principles-for-effective-visualizations-1",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#principles-for-effective-visualizations-1",
    "title": "Tips for effective data visualization",
    "section": "Principles for effective visualizations",
    "text": "Principles for effective visualizations\n\nOrder matters\nPut long categories on the y-axis\nKeep scales consistent\nSelect meaningful colors\nUse meaningful and nonredundant labels"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#data",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#data",
    "title": "Tips for effective data visualization",
    "section": "Data",
    "text": "Data\nIn September 2019, YouGov survey asked 1,639 GB adults the following question:\n.pull-left[ > In hindsight, do you think Britain was right/wrong to vote to leave EU? > >- Right to leave\n>- Wrong to leave\n>- Don’t know] .pull-right[]\n.footnote[ Source: YouGov Survey Results, retrieved Oct 7, 2019]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#alphabetical-order-is-rarely-ideal",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#alphabetical-order-is-rarely-ideal",
    "title": "Tips for effective data visualization",
    "section": "Alphabetical order is rarely ideal",
    "text": "Alphabetical order is rarely ideal\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#order-by-frequency",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#order-by-frequency",
    "title": "Tips for effective data visualization",
    "section": "Order by frequency",
    "text": "Order by frequency\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#clean-up-labels",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#clean-up-labels",
    "title": "Tips for effective data visualization",
    "section": "Clean up labels",
    "text": "Clean up labels\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#alphabetical-order-is-rarely-ideal-1",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#alphabetical-order-is-rarely-ideal-1",
    "title": "Tips for effective data visualization",
    "section": "Alphabetical order is rarely ideal",
    "text": "Alphabetical order is rarely ideal\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-inherent-level-order",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-inherent-level-order",
    "title": "Tips for effective data visualization",
    "section": "Use inherent level order",
    "text": "Use inherent level order\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#clean-up-labels-1",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#clean-up-labels-1",
    "title": "Tips for effective data visualization",
    "section": "Clean up labels",
    "text": "Clean up labels\n.panelset[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#long-categories-can-be-hard-to-read",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#long-categories-can-be-hard-to-read",
    "title": "Tips for effective data visualization",
    "section": "Long categories can be hard to read",
    "text": "Long categories can be hard to read"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#move-them-to-the-y-axis",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#move-them-to-the-y-axis",
    "title": "Tips for effective data visualization",
    "section": "Move them to the y-axis",
    "text": "Move them to the y-axis\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#and-reverse-the-order-of-levels",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#and-reverse-the-order-of-levels",
    "title": "Tips for effective data visualization",
    "section": "And reverse the order of levels",
    "text": "And reverse the order of levels\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#clean-up-labels-2",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#clean-up-labels-2",
    "title": "Tips for effective data visualization",
    "section": "Clean up labels",
    "text": "Clean up labels\n.panelset[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#segmented-bar-plots-can-be-hard-to-read",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#segmented-bar-plots-can-be-hard-to-read",
    "title": "Tips for effective data visualization",
    "section": "Segmented bar plots can be hard to read",
    "text": "Segmented bar plots can be hard to read\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-facets",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-facets",
    "title": "Tips for effective data visualization",
    "section": "Use facets",
    "text": "Use facets\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#avoid-redundancy",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#avoid-redundancy",
    "title": "Tips for effective data visualization",
    "section": "Avoid redundancy?",
    "text": "Avoid redundancy?"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#redundancy-can-help-tell-a-story",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#redundancy-can-help-tell-a-story",
    "title": "Tips for effective data visualization",
    "section": "Redundancy can help tell a story",
    "text": "Redundancy can help tell a story\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#be-selective-with-redundancy",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#be-selective-with-redundancy",
    "title": "Tips for effective data visualization",
    "section": "Be selective with redundancy",
    "text": "Be selective with redundancy\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-informative-labels",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-informative-labels",
    "title": "Tips for effective data visualization",
    "section": "Use informative labels",
    "text": "Use informative labels\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#a-bit-more-info",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#a-bit-more-info",
    "title": "Tips for effective data visualization",
    "section": "A bit more info",
    "text": "A bit more info\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#lets-do-better",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#lets-do-better",
    "title": "Tips for effective data visualization",
    "section": "Let’s do better",
    "text": "Let’s do better\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#fix-up-facet-labels",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#fix-up-facet-labels",
    "title": "Tips for effective data visualization",
    "section": "Fix up facet labels",
    "text": "Fix up facet labels\n.panelset[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#rainbow-colors-not-always-the-right-choice",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#rainbow-colors-not-always-the-right-choice",
    "title": "Tips for effective data visualization",
    "section": "Rainbow colors not always the right choice",
    "text": "Rainbow colors not always the right choice"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#manually-choose-colors-when-needed",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#manually-choose-colors-when-needed",
    "title": "Tips for effective data visualization",
    "section": "Manually choose colors when needed",
    "text": "Manually choose colors when needed\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#choosing-better-colors",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#choosing-better-colors",
    "title": "Tips for effective data visualization",
    "section": "Choosing better colors",
    "text": "Choosing better colors\n.center[.large[ colorbrewer2.org]]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-better-colors",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#use-better-colors",
    "title": "Tips for effective data visualization",
    "section": "Use better colors",
    "text": "Use better colors\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#select-theme",
    "href": "slides/u2-d14-effective-dataviz/u2-d14-effective-dataviz.html#select-theme",
    "title": "Tips for effective data visualization",
    "section": "Select theme",
    "text": "Select theme\n.panelset[]\n\n.your-turn[ ### .hand[Your turn!] .midi[ - RStudio Cloud > AE 07 - Brexit + Telling stories with dataviz > brexit.Rmd. - Change the visualisation in three different ways to tell slightly different stories with it each time.]]"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html",
    "title": "Scientific studies and confounding",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#scientific-studies-1",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#scientific-studies-1",
    "title": "Scientific studies and confounding",
    "section": "Scientific studies",
    "text": "Scientific studies\n.pull-left[ Observational\n- Collect data in a way that does not interfere with how the data arise (“observe”) - Establish associations] .pull-right[ Experimental\n- Randomly assign subjects to treatments - Establish causal connections]\n\n.question[ What type of study is the following, observational or experiment? What does that mean in terms of causal conclusions?]\n\n.question[ What type of study is the following, observational or experiment? What does that mean in terms of causal conclusions?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#explanatory-and-response-variables",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#explanatory-and-response-variables",
    "title": "Scientific studies and confounding",
    "section": "Explanatory and response variables",
    "text": "Explanatory and response variables\n\nExplanatory variable: Whether the participant ate breakfast or not\nReponse variable: BMI of the participant"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#three-possible-explanations",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#three-possible-explanations",
    "title": "Scientific studies and confounding",
    "section": "Three possible explanations",
    "text": "Three possible explanations\n–\n\nEating breakfast causes girls to be slimmer\n\n\n\n\n\n\n\n2. Being slim causes girls to eat breakfast\n\n\n\n\n3. A third variable is responsible for both – a confounding variable: an extraneous variable that affects both the explanatory and the response variable, and that makes it seem like there is a relationship between them"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#correlation-causation",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#correlation-causation",
    "title": "Scientific studies and confounding",
    "section": "Correlation != causation",
    "text": "Correlation != causation\n\n\n\n\n\n\n\n\n\n.footnote[ Randall Munroe CC BY-NC 2.5 http://xkcd.com/552/]"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#studies-and-conclusions",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#studies-and-conclusions",
    "title": "Scientific studies and confounding",
    "section": "Studies and conclusions",
    "text": "Studies and conclusions\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#survey-question",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#survey-question",
    "title": "Scientific studies and confounding",
    "section": "Survey question",
    "text": "Survey question\n\nA July 2019 YouGov survey asked 1633 GB and 1333 USA randomly selected adults which of the following statements about the global environment best describes their view:\n\nThe climate is changing and human activity is mainly responsible\n\nThe climate is changing and human activity is partly responsible, together with other factors\n\nThe climate is changing but human activity is not responsible at all\n\nThe climate is not changing"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#survey-data",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#survey-data",
    "title": "Scientific studies and confounding",
    "section": "Survey data",
    "text": "Survey data\n\n.small[]\n.footnote[ Source: YouGov - International Climate Change Survey]\n\n.question[ What percent of all respondents think the climate is changing and\nhuman activity is mainly responsible?\n]\n.small[]\n–\n\n(all <- 1340 / 2966)\n\n[1] 0.4517869\n\n\n\n.question[ What percent of GB respondents think the climate is changing and\nhuman activity is mainly responsible?\n]\n.small[]\n–\n\n(gb <- 833 / 1633)\n\n[1] 0.5101041\n\n\n\n.question[ What percent of US respondents think the climate is changing and\nhuman activity is mainly responsible?\n]\n.small[]\n–\n\n(us <- 507 / 1333)\n\n[1] 0.3803451\n\n\n\n.question[ Based on the percentages we calculated, does there appear to be a relationship between country and beliefs about climate change? If yes, could there be another variable that explains this relationship?]\n.pull-left[]"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#conditional-probability",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#conditional-probability",
    "title": "Scientific studies and confounding",
    "section": "Conditional probability",
    "text": "Conditional probability\nNotation: \\(P(A | B)\\): Probability of event A given event B\n\nWhat is the probability that it will be unseasonably warm tomorrow?\nWhat is the probability that it will be unseasonably warm tomorrow, given that it was unseasonably warm today?"
  },
  {
    "objectID": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#independence",
    "href": "slides/u2-d15-studies-confounding/u2-d15-studies-confounding.html#independence",
    "title": "Scientific studies and confounding",
    "section": "Independence",
    "text": "Independence\n\nIf knowing event A happened tells you something about event B happening, or vice versa, then events A and B are not independent\nIf not, they are said to be independent\n\\(P(A | B) = P(A)\\)"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html",
    "title": "Simpson’s paradox",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#berkeley-admission-data",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#berkeley-admission-data",
    "title": "Simpson’s paradox",
    "section": "Berkeley admission data",
    "text": "Berkeley admission data\n\nStudy carried out by the Graduate Division of the University of California, Berkeley in the early 70’s to evaluate whether there was a gender bias in graduate admissions.\nThe data come from six departments. For confidentiality we’ll call them A-F.\nWe have information on whether the applicant was male or female and whether they were admitted or rejected.\nFirst, we will evaluate whether the percentage of males admitted is indeed higher than females, overall. Next, we will calculate the same percentage for each department."
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#data",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#data",
    "title": "Simpson’s paradox",
    "section": "Data",
    "text": "Data\n.pull-left[] .pull-right[]\n\n.question[ What can you say about the overall gender distribution? Hint: Calculate the following probabilities: \\(P(Admit | Male)\\) and \\(P(Admit | Female)\\).]\n\nucbadmit %>%\n  count(gender, admit)\n\n# A tibble: 4 x 3\n  gender admit        n\n  <fct>  <fct>    <int>\n1 Female Rejected  1278\n2 Female Admitted   557\n3 Male   Rejected  1493\n4 Male   Admitted  1198\n\n\n\n\nucbadmit %>%\n  count(gender, admit) %>%\n  group_by(gender) %>%\n  mutate(prop_admit = n / sum(n))\n\n# A tibble: 4 x 4\n# Groups:   gender [2]\n  gender admit        n prop_admit\n  <fct>  <fct>    <int>      <dbl>\n1 Female Rejected  1278      0.696\n2 Female Admitted   557      0.304\n3 Male   Rejected  1493      0.555\n4 Male   Admitted  1198      0.445\n\n\n\n\\(P(Admit | Female)\\) = 0.304\n\\(P(Admit | Male)\\) = 0.445"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#overall-gender-distribution",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#overall-gender-distribution",
    "title": "Simpson’s paradox",
    "section": "Overall gender distribution",
    "text": "Overall gender distribution\n.panelset[]\n\n.question[ What can you say about the gender distribution by department ?]\n\nucbadmit %>%\n  count(dept, gender, admit)\n\n# A tibble: 24 x 4\n  dept  gender admit        n\n  <ord> <fct>  <fct>    <int>\n1 A     Female Rejected    19\n2 A     Female Admitted    89\n3 A     Male   Rejected   313\n4 A     Male   Admitted   512\n5 B     Female Rejected     8\n6 B     Female Admitted    17\n# ... with 18 more rows\n\n\n\n.question[ Let’s try again… What can you say about the gender distribution by department?]\n\nucbadmit %>%\n  count(dept, gender, admit) %>%\n  pivot_wider(names_from = dept, values_from = n)\n\n# A tibble: 4 x 8\n  gender admit        A     B     C     D     E     F\n  <fct>  <fct>    <int> <int> <int> <int> <int> <int>\n1 Female Rejected    19     8   391   244   299   317\n2 Female Admitted    89    17   202   131    94    24\n3 Male   Rejected   313   207   205   279   138   351\n4 Male   Admitted   512   353   120   138    53    22"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#gender-distribution-by-department",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#gender-distribution-by-department",
    "title": "Simpson’s paradox",
    "section": "Gender distribution, by department",
    "text": "Gender distribution, by department\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#case-for-gender-discrimination",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#case-for-gender-discrimination",
    "title": "Simpson’s paradox",
    "section": "Case for gender discrimination?",
    "text": "Case for gender discrimination?\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#closer-look-at-departments",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#closer-look-at-departments",
    "title": "Simpson’s paradox",
    "section": "Closer look at departments",
    "text": "Closer look at departments\n.panelset[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#relationship-between-two-variables",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#relationship-between-two-variables",
    "title": "Simpson’s paradox",
    "section": "Relationship between two variables",
    "text": "Relationship between two variables\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#relationship-between-two-variables-1",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#relationship-between-two-variables-1",
    "title": "Simpson’s paradox",
    "section": "Relationship between two variables",
    "text": "Relationship between two variables\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#considering-a-third-variable",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#considering-a-third-variable",
    "title": "Simpson’s paradox",
    "section": "Considering a third variable",
    "text": "Considering a third variable\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#relationship-between-three-variables",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#relationship-between-three-variables",
    "title": "Simpson’s paradox",
    "section": "Relationship between three variables",
    "text": "Relationship between three variables\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#simpsons-paradox-1",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#simpsons-paradox-1",
    "title": "Simpson’s paradox",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\n\nNot considering an important variable when studying a relationship can result in Simpson’s paradox\nSimpson’s paradox illustrates the effect that omission of an explanatory variable can have on the measure of association between another explanatory variable and a response variable\nThe inclusion of a third variable in the analysis can change the apparent relationship between the other two variables\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#what-does-group_by-do",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#what-does-group_by-do",
    "title": "Simpson’s paradox",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\ngroup_by() takes an existing data frame and converts it into a grouped data frame where subsequent operations are performed “once per group”\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#what-does-group_by-not-do",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#what-does-group_by-not-do",
    "title": "Simpson’s paradox",
    "section": "What does group_by() not do?",
    "text": "What does group_by() not do?\ngroup_by() does not sort the data, arrange() does\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#what-does-group_by-not-do-1",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#what-does-group_by-not-do-1",
    "title": "Simpson’s paradox",
    "section": "What does group_by() not do?",
    "text": "What does group_by() not do?\ngroup_by() does not create frequency tables, count() does\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#undo-grouping-with-ungroup",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#undo-grouping-with-ungroup",
    "title": "Simpson’s paradox",
    "section": "Undo grouping with ungroup()",
    "text": "Undo grouping with ungroup()\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#count-is-a-short-hand",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#count-is-a-short-hand",
    "title": "Simpson’s paradox",
    "section": "count() is a short-hand",
    "text": "count() is a short-hand\ncount() is a short-hand for group_by() and then summarise() to count the number of observations in each group\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#count-can-take-multiple-arguments",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#count-can-take-multiple-arguments",
    "title": "Simpson’s paradox",
    "section": "count can take multiple arguments",
    "text": "count can take multiple arguments\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#summarise-after-group_by",
    "href": "slides/u2-d16-simpsons-paradox/u2-d16-simpsons-paradox.html#summarise-after-group_by",
    "title": "Simpson’s paradox",
    "section": "summarise() after group_by()",
    "text": "summarise() after group_by()\n\ncount() ungroups after itself\nsummarise() peels off one layer of grouping by default, or you can specify a different behaviour\n\n\nucbadmit %>%\n  group_by(gender, admit) %>%\n  summarise(n = n()) \n\n`summarise()` has grouped output by 'gender'. You can override\nusing the `.groups` argument.\n\n\n# A tibble: 4 x 3\n# Groups:   gender [2]\n  gender admit        n\n  <fct>  <fct>    <int>\n1 Female Rejected  1278\n2 Female Admitted   557\n3 Male   Rejected  1493\n4 Male   Admitted  1198"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html",
    "title": "Doing data science",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#five-core-activities-of-data-analysis",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#five-core-activities-of-data-analysis",
    "title": "Doing data science",
    "section": "Five core activities of data analysis",
    "text": "Five core activities of data analysis\n\nStating and refining the question\nExploring the data\nBuilding formal statistical models\nInterpreting the results\nCommunicating the results\n\n.footnote[ Roger D. Peng and Elizabeth Matsui. “The Art of Data Science.” A Guide for Anyone Who Works with Data. Skybrude Consulting, LLC (2015).]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#six-types-of-questions",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#six-types-of-questions",
    "title": "Doing data science",
    "section": "Six types of questions",
    "text": "Six types of questions\n\nDescriptive: summarize a characteristic of a set of data\nExploratory: analyze to see if there are patterns, trends, or relationships between variables (hypothesis generating)\nInferential: analyze patterns, trends, or relationships in representative data from a population\nPredictive: make predictions for individuals or groups of individuals\nCausal: whether changing one factor will change another factor, on average, in a population\nMechanistic: explore “how” as opposed to whether\n\n.footnote[ Jeffery T. Leek and Roger D. Peng. “What is the question?.” Science 347.6228 (2015): 1314-1315.]"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#ex-covid-19-and-vitamin-d",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#ex-covid-19-and-vitamin-d",
    "title": "Doing data science",
    "section": "Ex: COVID-19 and Vitamin D",
    "text": "Ex: COVID-19 and Vitamin D"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#descriptive-frequency-of-hospitalisations-due-to-covid-19-in-a-set-of-data-collected-from-a-group-of-individuals",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#descriptive-frequency-of-hospitalisations-due-to-covid-19-in-a-set-of-data-collected-from-a-group-of-individuals",
    "title": "Doing data science",
    "section": "1. Descriptive: frequency of hospitalisations due to COVID-19 in a set of data collected from a group of individuals",
    "text": "1. Descriptive: frequency of hospitalisations due to COVID-19 in a set of data collected from a group of individuals"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#exploratory-examine-relationships-between-a-range-of-dietary-factors-and-covid-19-hospitalisations",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#exploratory-examine-relationships-between-a-range-of-dietary-factors-and-covid-19-hospitalisations",
    "title": "Doing data science",
    "section": "1. Exploratory: examine relationships between a range of dietary factors and COVID-19 hospitalisations",
    "text": "1. Exploratory: examine relationships between a range of dietary factors and COVID-19 hospitalisations\n\nInferential: examine whether any relationship between taking Vitamin D supplements and COVID-19 hospitalisations found in the sample hold for the population at large\n\n\n\n\n\n\n\n1. Predictive: what types of people will take Vitamin D supplements during the next year\n\n\n\n\n1. Causal: whether people with COVID-19 who were randomly assigned to take Vitamin D supplements or those who were not are hospitalised\n\n\n\n\nMechanistic: how increased vitamin D intake leads to a reduction in the number of viral illnesses"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#questions-to-data-science-problems",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#questions-to-data-science-problems",
    "title": "Doing data science",
    "section": "Questions to data science problems",
    "text": "Questions to data science problems\n\nDo you have appropriate data to answer your question?\nDo you have information on confounding variables?\nWas the data you’re working with collected in a way that introduces bias?\n\n–\n.question[ Suppose I want to estimate the average number of children in households in Edinburgh. I conduct a survey at an elementary school in Edinburgh and ask students at this elementary school how many children, including themselves, live in their house. Then, I take the average of the responses. Is this a biased or an unbiased estimate of the number of children in households in Edinburgh? If biased, will the value be an overestimate or underestimate?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#checklist",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#checklist",
    "title": "Doing data science",
    "section": "Checklist",
    "text": "Checklist\n\nFormulate your question\nRead in your data\nCheck the dimensions\nLook at the top and the bottom of your data\nValidate with at least one external data source\nMake a plot\nTry the easy solution first"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#formulate-your-question",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#formulate-your-question",
    "title": "Doing data science",
    "section": "Formulate your question",
    "text": "Formulate your question\n\nConsider scope:\n\nAre air pollution levels higher on the east coast than on the west coast?\nAre hourly ozone levels on average higher in New York City than they are in Los Angeles?\nDo counties in the eastern United States have higher ozone levels than counties in the western United States?\n\nMost importantly: “Do I have the right data to answer this question?”"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#read-in-your-data",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#read-in-your-data",
    "title": "Doing data science",
    "section": "Read in your data",
    "text": "Read in your data\n\nPlace your data in a folder called data\nRead it into R with read_csv() or friends (read_delim(), read_excel(), etc.)\n\n\nlibrary(readxl)\nfav_food <- read_excel(\"data/favourite-food.xlsx\")\nfav_food\n\n# A tibble: 5 x 6\n  `Student ID` `Full Name`      favourite.f~1 mealP~2 AGE   SES  \n         <dbl> <chr>            <chr>         <chr>   <chr> <chr>\n1            1 Sunil Huffmann   Strawberry y~ Lunch ~ 4     High \n2            2 Barclay Lynn     French fries  Lunch ~ 5     Midd~\n3            3 Jayendra Lyne    N/A           Breakf~ 7     Low  \n4            4 Leon Rossini     Anchovies     Lunch ~ 99999 Midd~\n5            5 Chidiegwu Dunkel Pizza         Breakf~ five  High \n# ... with abbreviated variable names 1: favourite.food,\n#   2: mealPlan"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#clean_names",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#clean_names",
    "title": "Doing data science",
    "section": "clean_names()",
    "text": "clean_names()\nIf the variable names are malformatted, use janitor::clean_names()\n\nlibrary(janitor)\nfav_food %>% clean_names()  \n\n# A tibble: 5 x 6\n  student_id full_name        favourite_food  meal_~1 age   ses  \n       <dbl> <chr>            <chr>           <chr>   <chr> <chr>\n1          1 Sunil Huffmann   Strawberry yog~ Lunch ~ 4     High \n2          2 Barclay Lynn     French fries    Lunch ~ 5     Midd~\n3          3 Jayendra Lyne    N/A             Breakf~ 7     Low  \n4          4 Leon Rossini     Anchovies       Lunch ~ 99999 Midd~\n5          5 Chidiegwu Dunkel Pizza           Breakf~ five  High \n# ... with abbreviated variable name 1: meal_plan"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#case-study-nyc-squirrels",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#case-study-nyc-squirrels",
    "title": "Doing data science",
    "section": "Case study: NYC Squirrels!",
    "text": "Case study: NYC Squirrels!\n\nThe Squirrel Census is a multimedia science, design, and storytelling project focusing on the Eastern gray (Sciurus carolinensis). They count squirrels and present their findings to the public.\nThis table contains squirrel data for each of the 3,023 sightings, including location coordinates, age, primary and secondary fur color, elevation, activities, communications, and interactions between squirrels and with humans.\n\n\n#install_github(\"mine-cetinkaya-rundel/nycsquirrels18\")\nlibrary(nycsquirrels18)"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#locate-the-codebook",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#locate-the-codebook",
    "title": "Doing data science",
    "section": "Locate the codebook",
    "text": "Locate the codebook\nmine-cetinkaya-rundel.github.io/nycsquirrels18/reference/squirrels.html\n\n–"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#check-the-dimensions",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#check-the-dimensions",
    "title": "Doing data science",
    "section": "Check the dimensions",
    "text": "Check the dimensions\n\ndim(squirrels)\n\n[1] 3023   35"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#look-at-the-top",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#look-at-the-top",
    "title": "Doing data science",
    "section": "Look at the top…",
    "text": "Look at the top…\n\nsquirrels %>% head()\n\n# A tibble: 6 x 35\n   long   lat unique_squ~1 hectare shift date       hecta~2 age  \n  <dbl> <dbl> <chr>        <chr>   <chr> <date>       <dbl> <chr>\n1 -74.0  40.8 13A-PM-1014~ 13A     PM    2018-10-14       4 <NA> \n2 -74.0  40.8 15F-PM-1010~ 15F     PM    2018-10-10       6 Adult\n3 -74.0  40.8 19C-PM-1018~ 19C     PM    2018-10-18       2 Adult\n4 -74.0  40.8 21B-AM-1019~ 21B     AM    2018-10-19       4 <NA> \n5 -74.0  40.8 23A-AM-1018~ 23A     AM    2018-10-18       2 Juve~\n6 -74.0  40.8 38H-PM-1012~ 38H     PM    2018-10-12       1 Adult\n# ... with 27 more variables: primary_fur_color <chr>,\n#   highlight_fur_color <chr>,\n#   combination_of_primary_and_highlight_color <chr>,\n#   color_notes <chr>, location <chr>,\n#   above_ground_sighter_measurement <chr>,\n#   specific_location <chr>, running <lgl>, chasing <lgl>,\n#   climbing <lgl>, eating <lgl>, foraging <lgl>, ..."
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#and-the-bottom",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#and-the-bottom",
    "title": "Doing data science",
    "section": "…and the bottom",
    "text": "…and the bottom\n.small[]"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#validate-with-at-least-one-external-data-source",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#validate-with-at-least-one-external-data-source",
    "title": "Doing data science",
    "section": "Validate with at least one external data source",
    "text": "Validate with at least one external data source\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#make-a-plot",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#make-a-plot",
    "title": "Doing data science",
    "section": "Make a plot",
    "text": "Make a plot\n\nggplot(squirrels, aes(x = long, y = lat)) +\n  geom_point(alpha = 0.2)\n\n\n\n\n\n\n\n\n–\n.pull-left-wide[ Hypothesis: There will be a higher density of sightings on the perimeter than inside the park.]"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#try-the-easy-solution-first",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#try-the-easy-solution-first",
    "title": "Doing data science",
    "section": "Try the easy solution first",
    "text": "Try the easy solution first\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#then-go-deeper",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#then-go-deeper",
    "title": "Doing data science",
    "section": "Then go deeper…",
    "text": "Then go deeper…\n.panelset[]"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#the-squirrel-is-staring-at-me",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#the-squirrel-is-staring-at-me",
    "title": "Doing data science",
    "section": "The squirrel is staring at me!",
    "text": "The squirrel is staring at me!\n\nsquirrels %>%\n  filter(str_detect(other_interactions, \"star\")) %>%\n  select(shift, age, other_interactions)\n\n# A tibble: 11 x 3\n  shift age   other_interactions                                 \n  <chr> <chr> <chr>                                              \n1 AM    Adult staring at us                                      \n2 PM    Adult he took 2 steps then turned and stared at me       \n3 PM    Adult stared                                             \n4 PM    Adult stared                                             \n5 PM    Adult stared                                             \n6 PM    Adult stared & then went back up tree—then ran to differ~\n# ... with 5 more rows"
  },
  {
    "objectID": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#communicating-for-your-audience",
    "href": "slides/u2-d17-doing-data-science/u2-d17-doing-data-science.html#communicating-for-your-audience",
    "title": "Doing data science",
    "section": "Communicating for your audience",
    "text": "Communicating for your audience\n\nAvoid: Jargon, uninterpreted results, lengthy output\nPay attention to: Organization, presentation, flow\nDon’t forget about: Code style, coding best practices, meaningful commits\nBe open to: Suggestions, feedback, taking (calculated) risks"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html",
    "title": "Web scraping",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#scraping-the-web-what-why",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#scraping-the-web-what-why",
    "title": "Web scraping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it’s time-consuming and prone to errors\n\n\n\n\n\n\n\n- Web scraping is the process of extracting this information automatically and transform it into a structured dataset\n\n\n\n\n- Two different scenarios: - Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy). - Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files.\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#hypertext-markup-language",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#hypertext-markup-language",
    "title": "Web scraping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\n\nMost of the data on the web is still largely available as HTML\nIt is structured (hierarchical / tree based), but it’’s often not available in a form useful for analysis (flat / tidy).\n\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n  </body>\n</html>"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#rvest",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#rvest",
    "title": "Web scraping",
    "section": "rvest",
    "text": "rvest\n.pull-left[ - The rvest package makes basic processing and manipulation of HTML data straight forward - It’s designed to work with pipelines built with %>%] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#core-rvest-functions",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#core-rvest-functions",
    "title": "Web scraping",
    "section": "Core rvest functions",
    "text": "Core rvest functions\n\nread_html - Read HTML data from a url or character string\nhtml_node - Select a specified node from HTML document\nhtml_nodes - Select specified nodes from HTML document\nhtml_table - Parse an HTML table into a data frame\nhtml_text - Extract tag pairs’ content\nhtml_name - Extract tags’ names\nhtml_attrs - Extract all of each tag’s attributes\nhtml_attr - Extract tags’ attribute value by name"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#selectorgadget",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#selectorgadget",
    "title": "Web scraping",
    "section": "SelectorGadget",
    "text": "SelectorGadget\n.pull-left-narrow[ - Open source tool that eases CSS selector generation and discovery - Easiest to use with the Chrome Extension - Find out more on the SelectorGadget vignette] .pull-right-wide[]"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#using-the-selectorgadget",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#using-the-selectorgadget",
    "title": "Web scraping",
    "section": "Using the SelectorGadget",
    "text": "Using the SelectorGadget"
  },
  {
    "objectID": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#using-the-selectorgadget-1",
    "href": "slides/u2-d18-web-scrape/u2-d18-web-scrape.html#using-the-selectorgadget-1",
    "title": "Web scraping",
    "section": "Using the SelectorGadget",
    "text": "Using the SelectorGadget\nThrough this process of selection and rejection, SelectorGadget helps you come up with the appropriate CSS selector for your needs"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html",
    "title": "Scraping top 250 movies on IMDB",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#top-250-movies-on-imdb-1",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#top-250-movies-on-imdb-1",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Top 250 movies on IMDB",
    "text": "Top 250 movies on IMDB\nTake a look at the source code, look for the tag table tag:  http://www.imdb.com/chart/top\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#first-check-if-youre-allowed",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#first-check-if-youre-allowed",
    "title": "Scraping top 250 movies on IMDB",
    "section": "First check if you’re allowed!",
    "text": "First check if you’re allowed!\n\nlibrary(robotstxt)\npaths_allowed(\"http://www.imdb.com\")\n\n[1] TRUE\n\n\nvs. e.g.\n\npaths_allowed(\"http://www.facebook.com\")\n\n[1] FALSE"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#plan",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#plan",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Plan",
    "text": "Plan"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#plan-1",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#plan-1",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Plan",
    "text": "Plan\n\nRead the whole page\nScrape movie titles and save as titles\nScrape years movies were made in and save as years\nScrape IMDB ratings and save as ratings\nCreate a data frame called imdb_top_250 with variables title, year, and rating\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#read-the-whole-page",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#read-the-whole-page",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Read the whole page",
    "text": "Read the whole page\n\npage <- read_html(\"https://www.imdb.com/chart/top/\")\npage\n\n{html_document}\n<html xmlns:og=\"http://ogp.me/ns#\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html ...\n[2] <body id=\"styleguide-v2\" class=\"fixed\">\\n            <img  ..."
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#a-webpage-in-r",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#a-webpage-in-r",
    "title": "Scraping top 250 movies on IMDB",
    "section": "A webpage in R",
    "text": "A webpage in R\n\nResult is a list with 2 elements\n\n\ntypeof(page)\n\n[1] \"list\"\n\n\n–\n\nthat we need to convert to something more familiar, like a data frame….\n\n\nclass(page)\n\n[1] \"xml_document\" \"xml_node\"    \n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-movie-titles",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-movie-titles",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Scrape movie titles",
    "text": "Scrape movie titles"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-the-nodes",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-the-nodes",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Scrape the nodes",
    "text": "Scrape the nodes\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#extract-the-text-from-the-nodes",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#extract-the-text-from-the-nodes",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Extract the text from the nodes",
    "text": "Extract the text from the nodes\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#save-as-titles",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#save-as-titles",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Save as titles",
    "text": "Save as titles\n.pull-left[] .pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-years-movies-were-made-in",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-years-movies-were-made-in",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Scrape years movies were made in",
    "text": "Scrape years movies were made in"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-the-nodes-1",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-the-nodes-1",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Scrape the nodes",
    "text": "Scrape the nodes\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#extract-the-text-from-the-nodes-1",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#extract-the-text-from-the-nodes-1",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Extract the text from the nodes",
    "text": "Extract the text from the nodes\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-the-text",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-the-text",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Clean up the text",
    "text": "Clean up the text\nWe need to go from \"(1994)\" to 1994:\n\nRemove ( and ): string manipulation\nConvert to numeric: as.numeric()"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#stringr",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#stringr",
    "title": "Scraping top 250 movies on IMDB",
    "section": "stringr",
    "text": "stringr\n.pull-left-wide[ - stringr provides a cohesive set of functions designed to make working with strings as easy as possible - Functions in stringr start with str_*(), e.g. - str_remove() to remove a pattern from a string] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-the-text-1",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-the-text-1",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Clean up the text",
    "text": "Clean up the text\n\npage %>%\n  html_nodes(\".secondaryInfo\") %>%\n  html_text() %>%\n  str_remove(\"\\\\(\") # remove (\n\n  [1] \"1994)\" \"1972)\" \"2008)\" \"1974)\" \"1957)\" \"1993)\" \"2003)\"\n  [8] \"1994)\" \"2001)\" \"1966)\" \"1994)\" \"1999)\" \"2010)\" \"2002)\"\n [15] \"1980)\" \"1999)\" \"1990)\" \"1975)\" \"1995)\" \"1954)\" \"1946)\"\n [22] \"1991)\" \"2002)\" \"1998)\" \"1997)\" \"1999)\" \"2014)\" \"1977)\"\n [29] \"1991)\" \"1985)\" \"2001)\" \"1960)\" \"2002)\" \"1994)\" \"2019)\"\n [36] \"1994)\" \"2000)\" \"1998)\" \"2006)\" \"1995)\" \"2006)\" \"1942)\"\n [43] \"2014)\" \"2011)\" \"1988)\" \"1962)\" \"1936)\" \"1968)\" \"1954)\"\n [50] \"1979)\" \"1931)\" \"1988)\" \"1979)\" \"2000)\" \"1981)\" \"2012)\"\n [57] \"2008)\" \"2006)\" \"1950)\" \"1957)\" \"1980)\" \"1940)\" \"1957)\"\n [64] \"2018)\" \"1986)\" \"1999)\" \"2022)\" \"2018)\" \"1964)\" \"2012)\"\n [71] \"2003)\" \"2019)\" \"1984)\" \"1995)\" \"1995)\" \"2017)\" \"2009)\"\n [78] \"1981)\" \"2019)\" \"1997)\" \"1984)\" \"1997)\" \"2016)\" \"2000)\"\n [85] \"2010)\" \"1952)\" \"2009)\" \"1963)\" \"1983)\" \"1968)\" \"2004)\"\n [92] \"1992)\" \"2018)\" \"2012)\" \"1962)\" \"1941)\" \"1931)\" \"1959)\"\n [99] \"1985)\" \"1958)\" \"2001)\" \"1971)\" \"1944)\" \"1960)\" \"1987)\"\n..."
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-the-text-2",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-the-text-2",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Clean up the text",
    "text": "Clean up the text\n\npage %>%\n  html_nodes(\".secondaryInfo\") %>%\n  html_text() %>%\n  str_remove(\"\\\\(\") %>% # remove (\n  str_remove(\"\\\\)\") # remove )\n\n  [1] \"1994\" \"1972\" \"2008\" \"1974\" \"1957\" \"1993\" \"2003\" \"1994\"\n  [9] \"2001\" \"1966\" \"1994\" \"1999\" \"2010\" \"2002\" \"1980\" \"1999\"\n [17] \"1990\" \"1975\" \"1995\" \"1954\" \"1946\" \"1991\" \"2002\" \"1998\"\n [25] \"1997\" \"1999\" \"2014\" \"1977\" \"1991\" \"1985\" \"2001\" \"1960\"\n [33] \"2002\" \"1994\" \"2019\" \"1994\" \"2000\" \"1998\" \"2006\" \"1995\"\n [41] \"2006\" \"1942\" \"2014\" \"2011\" \"1988\" \"1962\" \"1936\" \"1968\"\n [49] \"1954\" \"1979\" \"1931\" \"1988\" \"1979\" \"2000\" \"1981\" \"2012\"\n [57] \"2008\" \"2006\" \"1950\" \"1957\" \"1980\" \"1940\" \"1957\" \"2018\"\n [65] \"1986\" \"1999\" \"2022\" \"2018\" \"1964\" \"2012\" \"2003\" \"2019\"\n [73] \"1984\" \"1995\" \"1995\" \"2017\" \"2009\" \"1981\" \"2019\" \"1997\"\n [81] \"1984\" \"1997\" \"2016\" \"2000\" \"2010\" \"1952\" \"2009\" \"1963\"\n [89] \"1983\" \"1968\" \"2004\" \"1992\" \"2018\" \"2012\" \"1962\" \"1941\"\n [97] \"1931\" \"1959\" \"1985\" \"1958\" \"2001\" \"1971\" \"1944\" \"1960\"\n[105] \"1987\" \"1952\" \"1983\" \"1962\" \"1973\" \"2020\" \"1976\" \"1995\"\n..."
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#convert-to-numeric",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#convert-to-numeric",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Convert to numeric",
    "text": "Convert to numeric\n\npage %>%\n  html_nodes(\".secondaryInfo\") %>%\n  html_text() %>%\n  str_remove(\"\\\\(\") %>% # remove (\n  str_remove(\"\\\\)\") %>% # remove )\n  as.numeric()\n\n  [1] 1994 1972 2008 1974 1957 1993 2003 1994 2001 1966 1994 1999\n [13] 2010 2002 1980 1999 1990 1975 1995 1954 1946 1991 2002 1998\n [25] 1997 1999 2014 1977 1991 1985 2001 1960 2002 1994 2019 1994\n [37] 2000 1998 2006 1995 2006 1942 2014 2011 1988 1962 1936 1968\n [49] 1954 1979 1931 1988 1979 2000 1981 2012 2008 2006 1950 1957\n [61] 1980 1940 1957 2018 1986 1999 2022 2018 1964 2012 2003 2019\n [73] 1984 1995 1995 2017 2009 1981 2019 1997 1984 1997 2016 2000\n [85] 2010 1952 2009 1963 1983 1968 2004 1992 2018 2012 1962 1941\n [97] 1931 1959 1985 1958 2001 1971 1944 1960 1987 1952 1983 1962\n[109] 1973 2020 1976 1995 2009 2010 1997 2011 1927 1988 2000 1948\n[121] 1989 2019 2007 2004 1965 2005 2016 1921 1959 1950 2020 2018\n[133] 2013 1961 1985 1995 2021 1992 2006 2007 1998 1999 2001 1975\n[145] 1961 1948 2010 1993 1950 1963 2003 2007 2003 1980 1974 1980\n..."
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#save-as-years",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#save-as-years",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Save as years",
    "text": "Save as years\n.pull-left[] .pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-imdb-ratings",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-imdb-ratings",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Scrape IMDB ratings",
    "text": "Scrape IMDB ratings"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-the-nodes-2",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#scrape-the-nodes-2",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Scrape the nodes",
    "text": "Scrape the nodes\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#extract-the-text-from-the-nodes-2",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#extract-the-text-from-the-nodes-2",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Extract the text from the nodes",
    "text": "Extract the text from the nodes\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#convert-to-numeric-1",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#convert-to-numeric-1",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Convert to numeric",
    "text": "Convert to numeric\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#save-as-ratings",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#save-as-ratings",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Save as ratings",
    "text": "Save as ratings\n.pull-left[] .pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#create-a-data-frame-imdb_top_250",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#create-a-data-frame-imdb_top_250",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Create a data frame: imdb_top_250",
    "text": "Create a data frame: imdb_top_250\n\nimdb_top_250 <- tibble(\n  title = titles, \n  year = years, \n  rating = ratings\n  )\n\nimdb_top_250\n\n# A tibble: 250 x 3\n  title                     year rating\n  <chr>                    <dbl>  <dbl>\n1 The Shawshank Redemption  1994    9.2\n2 The Godfather             1972    9.2\n3 The Dark Knight           2008    9  \n4 The Godfather Part II     1974    9  \n5 12 Angry Men              1957    8.9\n6 Schindler's List          1993    8.9\n# ... with 244 more rows"
  },
  {
    "objectID": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-enhance",
    "href": "slides/u2-d19-top-250-imdb/u2-d19-top-250-imdb.html#clean-up-enhance",
    "title": "Scraping top 250 movies on IMDB",
    "section": "Clean up / enhance",
    "text": "Clean up / enhance\nMay or may not be a lot of work depending on how messy the data are\n\nSee if you like what you got:\n\n\nglimpse(imdb_top_250)\n\nRows: 250\nColumns: 3\n$ title  <chr> \"The Shawshank Redemption\", \"The Godfather\", \"Th~\n$ year   <dbl> 1994, 1972, 2008, 1974, 1957, 1993, 2003, 1994, ~\n$ rating <dbl> 9.2, 9.2, 9.0, 9.0, 8.9, 8.9, 8.9, 8.8, 8.8, 8.8~\n\n\n\nAdd a variable for rank\n\n\nimdb_top_250 <- imdb_top_250 %>%\n  mutate(rank = 1:nrow(imdb_top_250)) %>%\n  relocate(rank)\n\n\n\n\n# A tibble: 250 x 4\n    rank title                                        year rating\n   <int> <chr>                                       <dbl>  <dbl>\n 1     1 The Shawshank Redemption                     1994    9.2\n 2     2 The Godfather                                1972    9.2\n 3     3 The Dark Knight                              2008    9  \n 4     4 The Godfather Part II                        1974    9  \n 5     5 12 Angry Men                                 1957    8.9\n 6     6 Schindler's List                             1993    8.9\n 7     7 The Lord of the Rings: The Return of the K~  2003    8.9\n 8     8 Pulp Fiction                                 1994    8.8\n 9     9 The Lord of the Rings: The Fellowship of t~  2001    8.8\n10    10 The Good, the Bad and the Ugly               1966    8.8\n11    11 Forrest Gump                                 1994    8.8\n12    12 Fight Club                                   1999    8.7\n13    13 Inception                                    2010    8.7\n14    14 The Lord of the Rings: The Two Towers        2002    8.7\n15    15 Star Wars: Episode V - The Empire Strikes ~  1980    8.7\n16    16 The Matrix                                   1999    8.7\n17    17 Goodfellas                                   1990    8.7\n18    18 One Flew Over the Cuckoo's Nest              1975    8.6\n19    19 Se7en                                        1995    8.6\n20    20 Seven Samurai                                1954    8.6\n# ... with 230 more rows\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html",
    "title": "Web scraping considerations",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html#can-you-vs-should-you",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html#can-you-vs-should-you",
    "title": "Web scraping considerations",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”\n\n\n\n\n\n\n\n\n\n.footnote[.small[ Source: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox.]]"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html#can-you-vs-should-you-1",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html#can-you-vs-should-you-1",
    "title": "Web scraping considerations",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html#unreliable-formatting-at-the-source",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html#unreliable-formatting-at-the-source",
    "title": "Web scraping considerations",
    "section": "Unreliable formatting at the source",
    "text": "Unreliable formatting at the source"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html#data-broken-into-many-pages",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html#data-broken-into-many-pages",
    "title": "Web scraping considerations",
    "section": "Data broken into many pages",
    "text": "Data broken into many pages\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html#screen-scraping-vs.-apis",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html#screen-scraping-vs.-apis",
    "title": "Web scraping considerations",
    "section": "Screen scraping vs. APIs",
    "text": "Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files"
  },
  {
    "objectID": "slides/u2-d20-considerations/u2-d20-considerations.html#a-new-r-workflow",
    "href": "slides/u2-d20-considerations/u2-d20-considerations.html#a-new-r-workflow",
    "title": "Web scraping considerations",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in an R Markdown document, your analysis is re-run each time you knit\nIf web scraping in an R Markdown document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your R Markdown document"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html",
    "href": "slides/u2-d21-functions/u2-d21-functions.html",
    "title": "Functions",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#start-with",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#start-with",
    "title": "Functions",
    "section": "🏁 Start with",
    "text": "🏁 Start with"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#end-with",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#end-with",
    "title": "Functions",
    "section": "End with 🛑",
    "text": "End with 🛑\n\n\n# A tibble: 218 x 6\n   title                   date       locat~1 abstr~2 text  url  \n   <chr>                   <date>     <chr>   <chr>   <chr> <chr>\n 1 Coronavirus (COVID-19)~ 2021-04-20 St And~ Statem~ \"Goo~ http~\n 2 Coronavirus (COVID-19)~ 2021-04-13 St And~ Statem~ \"Tha~ http~\n 3 Coronavirus (COVID-19)~ 2021-04-06 St And~ Statem~ \"Goo~ http~\n 4 Coronavirus (COVID-19)~ 2021-03-30 St And~ Statem~ \"Tha~ http~\n 5 Coronavirus (COVID-19)~ 2021-03-24 Scotti~ Statem~ \"Tha~ http~\n 6 Coronavirus (Covid-19)~ 2021-03-23 The Sc~ Statem~ \"Pre~ http~\n 7 Coronavirus (COVID-19)~ 2021-03-18 Scotti~ Statem~ \"Tha~ http~\n 8 Coronavirus (COVID-19)~ 2021-03-17 St And~ Statem~ \"\\nG~ http~\n 9 Coronavirus (COVID-19)~ 2021-03-16 Scotti~ Statem~ \"Pre~ http~\n10 Coronavirus (COVID-19)~ 2021-03-15 St And~ Statem~ \"\\nG~ http~\n11 Coronavirus (COVID-19)~ 2021-03-11 Scotti~ Statem~ \"I c~ http~\n12 Coronavirus (COVID-19)~ 2021-03-09 Scotti~ Statem~ \"Pre~ http~\n13 Coronavirus (COVID-19)~ 2021-03-05 Scotti~ Parlia~ \"Hel~ http~\n14 Coronavirus (COVID-19)~ 2021-03-04 Scotti~ Parlia~ \"I w~ http~\n15 Coronavirus (COVID-19)~ 2021-03-02 Scotti~ Statem~ \"Pre~ http~\n# ... with 203 more rows, and abbreviated variable names\n#   1: location, 2: abstract\n\n\n\n\n.center[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#plan",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#plan",
    "title": "Functions",
    "section": "Plan",
    "text": "Plan\n\nScrape title, date, location, abstract, and text from a few COVID-19 speech pages to develop the code\nWrite a function that scrapes title, date, location, abstract, and text from COVID-19 speech pages\nScrape the urls of COVID-19 speeches from the main page\nUse this function to scrape from each individual COVID-19 speech from these urls and create a data frame with the columns title, date, location, abstract, text, and url\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#read-page-for-26-oct-speech",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#read-page-for-26-oct-speech",
    "title": "Functions",
    "section": "Read page for 26 Oct speech",
    "text": "Read page for 26 Oct speech\n\nurl <- \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-26-october/\"\nspeech_page <- read_html(url)\n\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#extract-title",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#extract-title",
    "title": "Functions",
    "section": "Extract title",
    "text": "Extract title\n.pull-left-wide[ ] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#extract-date",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#extract-date",
    "title": "Functions",
    "section": "Extract date",
    "text": "Extract date\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#extract-location",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#extract-location",
    "title": "Functions",
    "section": "Extract location",
    "text": "Extract location\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#extract-abstract",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#extract-abstract",
    "title": "Functions",
    "section": "Extract abstract",
    "text": "Extract abstract\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#extract-text",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#extract-text",
    "title": "Functions",
    "section": "Extract text",
    "text": "Extract text\n.pull-left-wide[] .pull-right-narrow[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#put-it-all-in-a-data-frame",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#put-it-all-in-a-data-frame",
    "title": "Functions",
    "section": "Put it all in a data frame",
    "text": "Put it all in a data frame\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#read-page-for-23-oct-speech",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#read-page-for-23-oct-speech",
    "title": "Functions",
    "section": "Read page for 23 Oct speech",
    "text": "Read page for 23 Oct speech\n\nurl <- \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-23-october/\"\nspeech_page <- read_html(url)\n\n\nspeech_page\n\n{html_document}\n<html dir=\"ltr\" lang=\"en\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html ...\n[2] <body class=\"fontawesome site-header__container\">\\r\\n\\r\\n\\ ..."
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#extract-components-of-23-oct-speech",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#extract-components-of-23-oct-speech",
    "title": "Functions",
    "section": "Extract components of 23 Oct speech",
    "text": "Extract components of 23 Oct speech\n\ntitle <- speech_page %>%\n  html_node(\".article-header__title\") %>%\n  html_text()\n\ndate <- speech_page %>%\n  html_node(\".content-data__list:nth-child(1) strong\") %>%\n  html_text() %>%\n  dmy()\n\nlocation <- speech_page %>%\n  html_node(\".content-data__list+ .content-data__list strong\") %>%\n  html_text()\n\nabstract <- speech_page %>%\n  html_node(\".leader--first-para p\") %>%\n  html_text()\n\ntext <- speech_page %>%\n  html_nodes(\"#preamble p\") %>%\n  html_text() %>%\n  list()"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#put-it-all-in-a-data-frame-1",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#put-it-all-in-a-data-frame-1",
    "title": "Functions",
    "section": "Put it all in a data frame",
    "text": "Put it all in a data frame\n.pull-left[] .pull-right[]\n\nclass: middle\n.larger[ .light-blue[ .hand[ this is getting tiring…]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#when-should-you-write-a-function",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#when-should-you-write-a-function",
    "title": "Functions",
    "section": "When should you write a function?",
    "text": "When should you write a function?\n\n\n\n\n\n\n.pull-left[]\n\n\n\n\n.pull-right[ When you’ve copied and pasted a block of code more than twice.]\n\n\n\n.question[ How many times will we need to copy and paste the code we developed to scrape data on all of First Minister’s COVID-19 speeches?]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#why-functions",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#why-functions",
    "title": "Functions",
    "section": "Why functions?",
    "text": "Why functions?\n\nAutomate common tasks in a more powerful and general way than copy-and-pasting:\n\nGive your function an evocative name that makes your code easier to understand\nAs requirements change, only need to update code in one place, instead of many\nEliminate chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another)\n\n\n–\n\nDown the line: Improve your reach as a data scientist by writing functions (and packages!) that others use\n\n\n.question[ Assuming that the page structure is the same for each speech page, how many “things” do you need to know for each speech page to scrape the data we want from it? ]\n.pull-left-wide[ .xsmall[]]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#turn-your-code-into-a-function",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#turn-your-code-into-a-function",
    "title": "Functions",
    "section": "Turn your code into a function",
    "text": "Turn your code into a function\n\nPick a short but informative name, preferably a verb.\n\n   \n\nscrape_speech <-"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#turn-your-code-into-a-function-1",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#turn-your-code-into-a-function-1",
    "title": "Functions",
    "section": "Turn your code into a function",
    "text": "Turn your code into a function\n\nPick a short but evocative name, preferably a verb.\nList inputs, or arguments, to the function inside function. If we had more the call would look like function(x, y, z).\n\n\n\nscrape_speech <- function(x){\n  \n  \n  \n  \n  \n}"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#turn-your-code-into-a-function-2",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#turn-your-code-into-a-function-2",
    "title": "Functions",
    "section": "Turn your code into a function",
    "text": "Turn your code into a function\n\nPick a short but informative name, preferably a verb.\nList inputs, or arguments, to the function inside function. If we had more the call would look like function(x, y, z).\nPlace the code you have developed in body of the function, a { block that immediately follows function(...).\n\n\nscrape_speech <- function(url){\n\n  # code we developed earlier to scrape info \n  # on single art piece goes here\n  \n}"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#scrape_speech",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#scrape_speech",
    "title": "Functions",
    "section": "scrape_speech()",
    "text": "scrape_speech()\n.pull-left-wide[ .small[]]"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#function-in-action",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#function-in-action",
    "title": "Functions",
    "section": "Function in action",
    "text": "Function in action\n\nscrape_speech(url = \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-26-october/\") %>%\n  glimpse()\n\nRows: 1\nColumns: 6\n$ title    <chr> NA\n$ date     <date> NA\n$ location <chr> NA\n$ abstract <chr> NA\n$ text     <list> <\"\\nGood afternoon, and thanks for joining us.~\n$ url      <chr> \"https://www.gov.scot/publications/coronaviru~"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#function-in-action-1",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#function-in-action-1",
    "title": "Functions",
    "section": "Function in action",
    "text": "Function in action\n\nscrape_speech(url = \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-23-october/\") %>%\n  glimpse()\n\nRows: 1\nColumns: 6\n$ title    <chr> NA\n$ date     <date> NA\n$ location <chr> NA\n$ abstract <chr> NA\n$ text     <list> <\"\\nGood afternoon everyone. Thank you very mu~\n$ url      <chr> \"https://www.gov.scot/publications/coronaviru~"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#function-in-action-2",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#function-in-action-2",
    "title": "Functions",
    "section": "Function in action",
    "text": "Function in action\n\nscrape_speech(url = \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-22-october/\") %>%\n  glimpse()\n\nRows: 1\nColumns: 6\n$ title    <chr> NA\n$ date     <date> NA\n$ location <chr> NA\n$ abstract <chr> NA\n$ text     <list> <\"\\nGood afternoon, let me start as usual with~\n$ url      <chr> \"https://www.gov.scot/publications/coronaviru~\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#what-goes-in-what-comes-out",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#what-goes-in-what-comes-out",
    "title": "Functions",
    "section": "What goes in / what comes out?",
    "text": "What goes in / what comes out?\n.pull-left-wide[ - They take input(s) defined in the function definition]\n\n.question[ What is going on here?]\n\nadd_2 <- function(x){\n  x + 2\n  1000\n}\n\n\nadd_2(3)\n\n[1] 1000\n\nadd_2(10)\n\n[1] 1000"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#naming-functions",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#naming-functions",
    "title": "Functions",
    "section": "Naming functions",
    "text": "Naming functions\n\n“There are only two hard things in Computer Science: cache invalidation and naming things.” - Phil Karlton"
  },
  {
    "objectID": "slides/u2-d21-functions/u2-d21-functions.html#naming-functions-1",
    "href": "slides/u2-d21-functions/u2-d21-functions.html#naming-functions-1",
    "title": "Functions",
    "section": "Naming functions",
    "text": "Naming functions\n\nNames should be short but clearly evoke what the function does\n\n\n\n\n\n\n\n- Names should be verbs, not nouns\n\n\n\n\n- Multi-word names should be separated by underscores (snake_case as opposed to camelCase)\n\n\n\n\nA family of functions should be named similarly (scrape_page(), scrape_speech() OR str_remove(), str_replace() etc.)\n\n– - Avoid overwriting existing (especially widely used) functions\n\n# JUST DON'T\nmean <- function(x){ \n  x * 3 \n  }"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html",
    "title": "Iteration",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#start-with",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#start-with",
    "title": "Iteration",
    "section": "🏁 Start with",
    "text": "🏁 Start with"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#end-with",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#end-with",
    "title": "Iteration",
    "section": "End with 🛑",
    "text": "End with 🛑\n\n\n# A tibble: 218 x 6\n   title                   date       locat~1 abstr~2 text  url  \n   <chr>                   <date>     <chr>   <chr>   <chr> <chr>\n 1 Coronavirus (COVID-19)~ 2021-04-20 St And~ Statem~ \"Goo~ http~\n 2 Coronavirus (COVID-19)~ 2021-04-13 St And~ Statem~ \"Tha~ http~\n 3 Coronavirus (COVID-19)~ 2021-04-06 St And~ Statem~ \"Goo~ http~\n 4 Coronavirus (COVID-19)~ 2021-03-30 St And~ Statem~ \"Tha~ http~\n 5 Coronavirus (COVID-19)~ 2021-03-24 Scotti~ Statem~ \"Tha~ http~\n 6 Coronavirus (Covid-19)~ 2021-03-23 The Sc~ Statem~ \"Pre~ http~\n 7 Coronavirus (COVID-19)~ 2021-03-18 Scotti~ Statem~ \"Tha~ http~\n 8 Coronavirus (COVID-19)~ 2021-03-17 St And~ Statem~ \"\\nG~ http~\n 9 Coronavirus (COVID-19)~ 2021-03-16 Scotti~ Statem~ \"Pre~ http~\n10 Coronavirus (COVID-19)~ 2021-03-15 St And~ Statem~ \"\\nG~ http~\n11 Coronavirus (COVID-19)~ 2021-03-11 Scotti~ Statem~ \"I c~ http~\n12 Coronavirus (COVID-19)~ 2021-03-09 Scotti~ Statem~ \"Pre~ http~\n13 Coronavirus (COVID-19)~ 2021-03-05 Scotti~ Parlia~ \"Hel~ http~\n14 Coronavirus (COVID-19)~ 2021-03-04 Scotti~ Parlia~ \"I w~ http~\n15 Coronavirus (COVID-19)~ 2021-03-02 Scotti~ Statem~ \"Pre~ http~\n# ... with 203 more rows, and abbreviated variable names\n#   1: location, 2: abstract"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#define-scrape_speech",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#define-scrape_speech",
    "title": "Iteration",
    "section": "Define scrape_speech()",
    "text": "Define scrape_speech()\n.pull-left-wide[ .small[]]"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#use-scrape_speech",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#use-scrape_speech",
    "title": "Iteration",
    "section": "Use scrape_speech()",
    "text": "Use scrape_speech()\n\nurl_26_oct <- \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-26-october/\"\nscrape_speech(url = url_26_oct)\n\n# A tibble: 1 x 6\n  title date   location abstract text       url                  \n  <chr> <date> <chr>    <chr>    <list>     <chr>                \n1 <NA>  NA     <NA>     <NA>     <chr [47]> https://www.gov.scot~\n\nurl_23_oct <- \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-23-october/\"\nscrape_speech(url = url_23_oct)\n\n# A tibble: 1 x 6\n  title date   location abstract text        url                 \n  <chr> <date> <chr>    <chr>    <list>      <chr>               \n1 <NA>  NA     <NA>     <NA>     <chr [134]> https://www.gov.sco~\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#inputs-1",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#inputs-1",
    "title": "Iteration",
    "section": "Inputs",
    "text": "Inputs\n.question[ You now have a function that will scrape the relevant info on speeches given the URL of the page of the speech. Where can we get a list of URLs of each of the speeches?]"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#all-urls",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#all-urls",
    "title": "Iteration",
    "section": "All URLs",
    "text": "All URLs\n\nall_speeches_page <- read_html(\"https://www.gov.scot/collections/first-ministers-speeches/\")\n\nall_speeches_page %>%\n  html_nodes(\".collections-list a\") %>%\n  html_attr(\"href\")\n\n  [1] \"/publications/motion-condolence/\"                                                                            \n  [2] \"/publications/tribute-majesty-queen/\"                                                                        \n  [3] \"/publications/programme-government-2022-2023-first-ministers-speech/\"                                        \n  [4] \"/publications/scotwind-supply-chain-summit-first-ministers-speech/\"                                          \n  [5] \"/publications/support-tech-scalers-first-ministers-speech-barclays-event-13-july-2022/\"                      \n  [6] \"/publications/royal-highland-show-first-ministers-speech-quality-meat-scotland-breakfast-event-24-june-2022/\"\n  [7] \"/publications/ministerial-statement-independence-referendum/\"                                                \n  [8] \"/publications/gathering-first-ministers-speech-15-june-2022/\"                                                \n  [9] \"/publications/scdi-forum-first-ministers-speech-13-june-2022/\"                                               \n [10] \"/publications/queens-platinum-jubilee-debate-first-ministers-statement/\"                                     \n..."
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#covid-19-urls-fragments",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#covid-19-urls-fragments",
    "title": "Iteration",
    "section": "COVID-19 URLs fragments",
    "text": "COVID-19 URLs fragments\n\nall_speeches_page %>%\n  html_nodes(\".collections-list a\") %>%\n  html_attr(\"href\") %>%\n  str_subset(\"covid-19\")\n\n  [1] \"/publications/coronavirus-covid-19-update-first-ministers-speech-tuesday-22-february-2022/\"     \n  [2] \"/publications/coronavirus-covid-19-update-first-ministers-statement-8-february-2022/\"           \n  [3] \"/publications/coronavirus-covid-19-update-first-ministers-statement-1-february-2022/\"           \n  [4] \"/publications/coronavirus-covid-19-update-first-ministers-statement-25-january-2022/\"           \n  [5] \"/publications/coronavirus-covid-19-update-first-ministers-statement-18-january-2022/\"           \n  [6] \"/publications/coronavirus-covid-19-update-first-ministers-statement-11-january-2022/\"           \n  [7] \"/publications/coronavirus-covid-19-update-first-ministers-statement-5-january-2022/\"            \n  [8] \"/publications/coronavirus-covid-19-update-first-ministers-statement-21-december-2021/\"          \n  [9] \"/publications/coronavirus-covid-19-update-first-ministers-speech-17-december-2021/\"             \n [10] \"/publications/coronavirus-covid-19-update-first-ministers-statement-14-december-2021/\"          \n..."
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#covid-19-urls",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#covid-19-urls",
    "title": "Iteration",
    "section": "COVID-19 URLs",
    "text": "COVID-19 URLs\n\nall_speeches_page %>%\n  html_nodes(\".collections-list a\") %>%\n  html_attr(\"href\") %>%\n  str_subset(\"covid-19\") %>%\n  str_c(\"https://www.gov.scot\", .)\n\n  [1] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-tuesday-22-february-2022/\"     \n  [2] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-8-february-2022/\"           \n  [3] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-1-february-2022/\"           \n  [4] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-25-january-2022/\"           \n  [5] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-18-january-2022/\"           \n  [6] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-11-january-2022/\"           \n  [7] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-5-january-2022/\"            \n  [8] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-21-december-2021/\"          \n  [9] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-17-december-2021/\"             \n [10] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-14-december-2021/\"          \n..."
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#save-covid-19-urls",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#save-covid-19-urls",
    "title": "Iteration",
    "section": "Save COVID-19 URLs",
    "text": "Save COVID-19 URLs\n\ncovid_speech_urls <- all_speeches_page %>%\n  html_nodes(\".collections-list a\") %>%\n  html_attr(\"href\") %>%\n  str_subset(\"covid-19\") %>%\n  str_c(\"https://www.gov.scot\", .)\n\ncovid_speech_urls\n\n  [1] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-tuesday-22-february-2022/\"     \n  [2] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-8-february-2022/\"           \n  [3] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-1-february-2022/\"           \n  [4] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-25-january-2022/\"           \n  [5] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-18-january-2022/\"           \n  [6] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-11-january-2022/\"           \n  [7] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-5-january-2022/\"            \n  [8] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-21-december-2021/\"          \n  [9] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-speech-17-december-2021/\"             \n [10] \"https://www.gov.scot/publications/coronavirus-covid-19-update-first-ministers-statement-14-december-2021/\"          \n...\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#define-the-task",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#define-the-task",
    "title": "Iteration",
    "section": "Define the task",
    "text": "Define the task\n\nGoal: Scrape info on all COVID-19 speeches of the First Minister\nSo far:\n\n\nscrape_speech(covid_speech_urls[1])\nscrape_speech(covid_speech_urls[2])\nscrape_speech(covid_speech_urls[3])\n\n\nWhat else do we need to do?\n\nRun the scrape_speech() function on all COVID-19 speech links\nCombine the resulting data frames from each run into one giant data frame"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#iteration-1",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#iteration-1",
    "title": "Iteration",
    "section": "Iteration",
    "text": "Iteration\n.question[ How can we tell R to apply the scrape_speech() function to each link in covid_speech_urls?]\n–\n\nOption 1: Write a for loop, i.e. explicitly tell R to visit a link, apply the function, store the result, then visit the next link, apply the function, append the result to the stored result from the previous link, and so on and so forth.\nOption 2: Map the function to each element in the list of links, and let R take care of the storing and appending of results.\nWe’ll go with Option 2!"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#how-does-mapping-work",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#how-does-mapping-work",
    "title": "Iteration",
    "section": "How does mapping work?",
    "text": "How does mapping work?\nSuppose we have exam 1 and exam 2 scores of 4 students stored in a list…\n\nexam_scores <- list(\n  exam1 <- c(80, 90, 70, 50),\n  exam2 <- c(85, 83, 45, 60)\n)\n\n–\n…and we find the mean score in each exam\n\nmap(exam_scores, mean)\n\n[[1]]\n[1] 72.5\n\n[[2]]\n[1] 68.25\n\n\n\n…and suppose we want the results as a numeric (double) vector\n\nmap_dbl(exam_scores, mean)\n\n[1] 72.50 68.25\n\n\n…or as a character string\n\nmap_chr(exam_scores, mean)\n\n[1] \"72.500000\" \"68.250000\""
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#map_something",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#map_something",
    "title": "Iteration",
    "section": "map_something",
    "text": "map_something\nFunctions for looping over an object and returning a value (of a specific type):\n\nmap() - returns a list\nmap_lgl() - returns a logical vector\nmap_int() - returns a integer vector\nmap_dbl() - returns a double vector\nmap_chr() - returns a character vector\nmap_df() / map_dfr() - returns a data frame by row binding\nmap_dfc() - returns a data frame by column binding\n…"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#go-to-each-page-scrape-speech",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#go-to-each-page-scrape-speech",
    "title": "Iteration",
    "section": "Go to each page, scrape speech",
    "text": "Go to each page, scrape speech\n\nMap the scrape_speech() function\nto each element of covid_speech_urls\nand return a data frame by row binding\n\n\ncovid_speeches <- map_dfr(covid_speech_urls, scrape_speech)\n\n\n\ncovid_speeches %>%\n  print(n = 15)\n\n# A tibble: 218 x 6\n   title                   date       locat~1 abstr~2 text  url  \n   <chr>                   <date>     <chr>   <chr>   <chr> <chr>\n 1 Coronavirus (COVID-19)~ 2021-04-20 St And~ Statem~ \"Goo~ http~\n 2 Coronavirus (COVID-19)~ 2021-04-13 St And~ Statem~ \"Tha~ http~\n 3 Coronavirus (COVID-19)~ 2021-04-06 St And~ Statem~ \"Goo~ http~\n 4 Coronavirus (COVID-19)~ 2021-03-30 St And~ Statem~ \"Tha~ http~\n 5 Coronavirus (COVID-19)~ 2021-03-24 Scotti~ Statem~ \"Tha~ http~\n 6 Coronavirus (Covid-19)~ 2021-03-23 The Sc~ Statem~ \"Pre~ http~\n 7 Coronavirus (COVID-19)~ 2021-03-18 Scotti~ Statem~ \"Tha~ http~\n 8 Coronavirus (COVID-19)~ 2021-03-17 St And~ Statem~ \"\\nG~ http~\n 9 Coronavirus (COVID-19)~ 2021-03-16 Scotti~ Statem~ \"Pre~ http~\n10 Coronavirus (COVID-19)~ 2021-03-15 St And~ Statem~ \"\\nG~ http~\n11 Coronavirus (COVID-19)~ 2021-03-11 Scotti~ Statem~ \"I c~ http~\n12 Coronavirus (COVID-19)~ 2021-03-09 Scotti~ Statem~ \"Pre~ http~\n13 Coronavirus (COVID-19)~ 2021-03-05 Scotti~ Parlia~ \"Hel~ http~\n14 Coronavirus (COVID-19)~ 2021-03-04 Scotti~ Parlia~ \"I w~ http~\n15 Coronavirus (COVID-19)~ 2021-03-02 Scotti~ Statem~ \"Pre~ http~\n# ... with 203 more rows, and abbreviated variable names\n#   1: location, 2: abstract"
  },
  {
    "objectID": "slides/u2-d22-iteration/u2-d22-iteration.html#what-could-go-wrong",
    "href": "slides/u2-d22-iteration/u2-d22-iteration.html#what-could-go-wrong",
    "title": "Iteration",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\ncovid_speeches <- map_dfr(covid_speech_urls, scrape_speech)\n\n\nThis will take a while to run\nIf you get HTTP Error 429 (Too many requests) you might want to slow down your hits by modifying your function to slow it down by adding a random wait (sleep) time between hitting each link\n\n\nscrape_speech <- function(url){\n  \n  # Sleep for randomly generated number of seconds\n  # Generated from a uniform distribution between 0 and 1\n  Sys.sleep(runif(1)) #<<\n  \n  # Rest of your function code goes here...\n}"
  },
  {
    "objectID": "slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html",
    "href": "slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html",
    "title": "Misrepresentation",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#original-study",
    "href": "slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#original-study",
    "title": "Misrepresentation",
    "section": "Original study",
    "text": "Original study\nMoore, Steven C., et al. “Association of leisure-time physical activity with risk of 26 types of cancer in 1.44 million adults.” JAMA internal medicine 176.6 (2016): 816-825.\n\nVolunteers were asked about their physical activity level over the preceding year.\nHalf exercised less than about 150 minutes per week, half exercised more.\nCompared to the bottom 10% of exercisers, the top 10% had lower rates of esophageal, liver, lung, endometrial, colon, and breast cancer.\nResearchers found no association between exercising and 13 other cancers (e.g. pancreatic, ovarian, and brain).\n\n.footnote[ .midi[ Carl Bergstrom and Jevin West. Calling Bullshit: The art of skepticism in a data-driven world.\nRandom House, 2020.\nSharon Begley. “Does exercise prevent cancer?”. StatNews. 16 May 2016. ]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#graph-detective",
    "href": "slides/u3-d01-misrepresentation/u3-d01-misrepresentation.html#graph-detective",
    "title": "Misrepresentation",
    "section": "Graph detective",
    "text": "Graph detective\n.center[ \n]\n.footnote[ .midi[ Lucy D’Agostino McGowan. Graph detective. Live Free or Dichotomize. 17 May 2020.]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u3-d02-privacy/u3-d02-privacy.html",
    "href": "slides/u3-d02-privacy/u3-d02-privacy.html",
    "title": "Data privacy",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u3-d02-privacy/u3-d02-privacy.html#ok-cupid-data-breach",
    "href": "slides/u3-d02-privacy/u3-d02-privacy.html#ok-cupid-data-breach",
    "title": "Data privacy",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames\n\n–\n.pull-left-wide[ >Some may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form. > >Researchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær]\n\n.question[ In analysis of data that individuals willingly shared publicly on a given platform (e.g. social media), how do you make sure you don’t violate reasonable expectations of privacy?]\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html",
    "title": "Algorithmic bias",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#google-translate",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#google-translate",
    "title": "Algorithmic bias",
    "section": "Google Translate",
    "text": "Google Translate"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#amazons-experimental-hiring-algorithm",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#amazons-experimental-hiring-algorithm",
    "title": "Algorithmic bias",
    "section": "Amazon’s experimental hiring algorithm",
    "text": "Amazon’s experimental hiring algorithm\n\nUsed AI to give job candidates scores ranging from one to five stars – much like shoppers rate products on Amazon\nAmazon’s system was not rating candidates for software developer jobs and other technical posts in a gender-neutral way; it taught itself that male candidates were preferable\n\n.pull-left-wide[ >Gender bias was not the only issue. Problems with the data that underpinned the models’ judgments meant that unqualified candidates were often recommended for all manner of jobs, the people said.]\n.footnote[ Jeffrey Dastin. Amazon scraps secret AI recruiting tool that showed bias against women.\nReuters. 10 Oct 2018.]\n\nclass: middle"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#facial-recognition",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#facial-recognition",
    "title": "Algorithmic bias",
    "section": "Facial recognition",
    "text": "Facial recognition\n\n\n\n\n\n\n\n\n\n.footnote[ .midi[ Ian Tucker. ‘A white mask worked better’: why algorithms are not colour blind.\nThe Guardian. 28 May 2017.]]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#criminal-sentencing",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#criminal-sentencing",
    "title": "Algorithmic bias",
    "section": "Criminal Sentencing",
    "text": "Criminal Sentencing\n.center[ There’s software used across the country to predict future criminals.\nAnd it’s biased against blacks.]\n\n\n\n\n\n\n\n\n\n.footnote[ .midi[ Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine Bias. 23 May 2016. ProPublica.]]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#a-tale-of-two-convicts",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#a-tale-of-two-convicts",
    "title": "Algorithmic bias",
    "section": "A tale of two convicts",
    "text": "A tale of two convicts\n.pull-left[ ] – .pull-right[ ]\n\nclass: middle\n\n“Although these measures were crafted with the best of intentions, I am concerned that they inadvertently undermine our efforts to ensure individualized and equal justice,” he said, adding, “they may exacerbate unwarranted and unjust disparities that are already far too common in our criminal justice system and in our society.”\nThen U.S. Attorney General Eric Holder (2014)"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#propublica-analysis",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#propublica-analysis",
    "title": "Algorithmic bias",
    "section": "ProPublica analysis",
    "text": "ProPublica analysis\n\nData:\nRisk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014 + whether they were charged with new crimes over the next two years"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#propublica-analysis-1",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#propublica-analysis-1",
    "title": "Algorithmic bias",
    "section": "ProPublica analysis",
    "text": "ProPublica analysis\n\nResults:\n\n20% of those predicted to commit violent crimes actually did\nAlgorithm had higher accuracy (61%) when full range of crimes taken into account (e.g. misdemeanors)\n\n\n\n\n\n\n\n\n\n\n\nAlgorithm was more likely to falsely flag black defendants as future criminals, at almost twice the rate as white defendants\nWhite defendants were mislabeled as low risk more often than black defendants"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#how-to-write-a-racist-ai-without-trying",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#how-to-write-a-racist-ai-without-trying",
    "title": "Algorithmic bias",
    "section": "How to write a racist AI without trying",
    "text": "How to write a racist AI without trying\n.center[ \n]\n.footnote[ .midi[ Thomas Lumley. How to write a racist AI in R without really trying.\nBiased and Inefficient. 27 September 2018.]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#machine-bias",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#machine-bias",
    "title": "Algorithmic bias",
    "section": "Machine Bias",
    "text": "Machine Bias\n.pull-left[] .pull-right[ Machine Bias\n by Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#ethics-and-data-science",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#ethics-and-data-science",
    "title": "Algorithmic bias",
    "section": "Ethics and Data Science",
    "text": "Ethics and Data Science\n.pull-left[] .pull-right[ Ethics and Data Science\n by Mike Loukides, Hilary Mason, DJ Patil\n(Free Kindle download)]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#weapons-of-math-destruction",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#weapons-of-math-destruction",
    "title": "Algorithmic bias",
    "section": "Weapons of Math Destruction",
    "text": "Weapons of Math Destruction\n.pull-left[] .pull-right[ Weapons of Math Destruction\nHow Big Data Increases Inequality and Threatens Democracy\n by Cathy O’Neil]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#algorithms-of-oppression",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#algorithms-of-oppression",
    "title": "Algorithmic bias",
    "section": "Algorithms of Oppression",
    "text": "Algorithms of Oppression\n.pull-left[] .pull-right[ Algorithms of Oppression\nHow Search Engines Reinforce Racism\n by Safiya Umoja Noble]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#parting-thoughts",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#parting-thoughts",
    "title": "Algorithmic bias",
    "section": "Parting thoughts",
    "text": "Parting thoughts\n\nAt some point during your data science learning journey you will learn tools that can be used unethically\nYou might also be tempted to use your knowledge in a way that is ethically questionable either because of business goals or for the pursuit of further knowledge (or because your boss told you to do so)\n\n.question[ How do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?]"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#do-good-with-data",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#do-good-with-data",
    "title": "Algorithmic bias",
    "section": "Do good with data",
    "text": "Do good with data\n\nData Science for Social Good:\n\nThe Alan Turing Institute\nUniversity of Chicago\n\nDataKind: DataKind brings high-impact organizations together with leading data scientists to use data science in the service of humanity.\nSign the Manifesto for Data Practices: datapractices.org/manifesto"
  },
  {
    "objectID": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#further-watching",
    "href": "slides/u3-d03-algorithmic-bias/u3-d03-algorithmic-bias.html#further-watching",
    "title": "Algorithmic bias",
    "section": "Further watching",
    "text": "Further watching\n.center[ \n]\n.footnote[ .midi[ Julien Cornebise. AI for Good in the R and Python ecosystems. useR 2019.]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html",
    "title": "The language of models",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#modelling",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#modelling",
    "title": "The language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but remember there are many many other types of models too!)\n\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#paris-paintings",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#paris-paintings",
    "title": "The language of models",
    "section": "Paris Paintings",
    "text": "Paris Paintings\n\npp <- read_csv(\"data/paris-paintings.csv\", na = c(\"n/a\", \"\", \"NA\"))\n\n\nSource: Printed catalogues of 28 auction sales in Paris, 1764 - 1780\nData curators Sandra van Ginhoven and Hilary Coe Cronheim (who were PhD students in the Duke Art, Law, and Markets Initiative at the time of putting together this dataset) translated and tabulated the catalogues\n3393 paintings, their prices, and descriptive details from sales catalogues over 60 variables"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#auctions-today",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#auctions-today",
    "title": "The language of models",
    "section": "Auctions today",
    "text": "Auctions today\n.center[ ]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#auctions-back-in-the-day",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#auctions-back-in-the-day",
    "title": "The language of models",
    "section": "Auctions back in the day",
    "text": "Auctions back in the day\n\n\n\n\n\n\n\n\n\n.footnote[ .small[ Pierre-Antoine de Machy, Public Sale at the Hôtel Bullion, Musée Carnavalet, Paris (18th century)]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#paris-auction-market",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#paris-auction-market",
    "title": "The language of models",
    "section": "Paris auction market",
    "text": "Paris auction market\n\n\n\n\n\n\n\n\n\n.footnote[ .small[ Plot credit: Sandra van Ginhoven]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#départ-pour-la-chasse",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#départ-pour-la-chasse",
    "title": "The language of models",
    "section": "Départ pour la chasse",
    "text": "Départ pour la chasse"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#auction-catalog-text",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#auction-catalog-text",
    "title": "The language of models",
    "section": "Auction catalog text",
    "text": "Auction catalog text\n.pull-left[] .pull-right[ .small[ Two paintings very rich in composition, of a beautiful execution, and whose merit is very remarkable, each 17 inches 3 lines high, 23 inches wide; the first, painted on wood, comes from the Cabinet of Madame la Comtesse de Verrue; it represents a departure for the hunt: it shows in the front a child on a white horse, a man who gives the horn to gather the dogs, a falconer and other figures nicely distributed across the width of the painting; two horses drinking from a fountain; on the right in the corner a lovely country house topped by a terrace, on which people are at the table, others who play instruments; trees and fabriques pleasantly enrich the background.]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npp %>%\n  filter(name == \"R1777-89a\") %>%\n  glimpse()\n\n.small[ .pull-left[] .pull-right[]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#heights",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#heights",
    "title": "The language of models",
    "section": "Heights",
    "text": "Heights\n.small[]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#widths",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#widths",
    "title": "The language of models",
    "section": "Widths",
    "text": "Widths\n.small[]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#models-as-functions",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#models-as-functions",
    "title": "The language of models",
    "section": "Models as functions",
    "text": "Models as functions\n\nWe can represent relationships between variables using functions\nA function is a mathematical concept: the relationship between an output and one or more inputs\n\nPlug in the inputs and receive back the output\nExample: The formula \\(y = 3x + 7\\) is a function with input \\(x\\) and output \\(y\\). If \\(x\\) is \\(5\\), \\(y\\) is \\(22\\), \\(y = 3 \\times 5 + 7 = 22\\)"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#height-as-a-function-of-width",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#height-as-a-function-of-width",
    "title": "The language of models",
    "section": "Height as a function of width",
    "text": "Height as a function of width\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#without-the-measure-of-uncertainty",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#without-the-measure-of-uncertainty",
    "title": "The language of models",
    "section": "… without the measure of uncertainty",
    "text": "… without the measure of uncertainty\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#with-different-cosmetic-choices",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#with-different-cosmetic-choices",
    "title": "The language of models",
    "section": "… with different cosmetic choices",
    "text": "… with different cosmetic choices\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#other-smoothing-methods-gam",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#other-smoothing-methods-gam",
    "title": "The language of models",
    "section": "Other smoothing methods: gam",
    "text": "Other smoothing methods: gam\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#other-smoothing-methods-loess",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#other-smoothing-methods-loess",
    "title": "The language of models",
    "section": "Other smoothing methods: loess",
    "text": "Other smoothing methods: loess\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#vocabulary",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#vocabulary",
    "title": "The language of models",
    "section": "Vocabulary",
    "text": "Vocabulary\n\nResponse variable: Variable whose behavior or variation you are trying to understand, on the y-axis\n\n\n\n\n\n\n\n- Explanatory variables: Other variables that you want to use to explain the variation in the response, on the x-axis\n\n\n\n\n- Predicted value: Output of the model function - The model function gives the typical (expected) value of the response variable conditioning on the explanatory variables\n\n\n\n\nResiduals: A measure of how far each case is from its predicted value (based on a particular model)\n\nResidual = Observed value - Predicted value\nTells how far above/below the expected value each case is"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#residuals",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#residuals",
    "title": "The language of models",
    "section": "Residuals",
    "text": "Residuals\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code] .small[]]]\n\n.question[ The plot below displays the relationship between height and width of paintings. The only difference from the previous plots is that it uses a smaller alpha value, making the points somewhat transparent. What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#landscape-paintings",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#landscape-paintings",
    "title": "The language of models",
    "section": "Landscape paintings",
    "text": "Landscape paintings\n\nLandscape painting is the depiction in art of landscapes – natural scenery such as mountains, valleys, trees, rivers, and forests, especially where the main subject is a wide view – with its elements arranged into a coherent composition.1\n\nLandscape paintings tend to be wider than they are long.\n\nPortrait painting is a genre in painting, where the intent is to depict a human subject.2\n\nPortrait paintings tend to be longer than they are wide.\n\n\n.footnote[ [1] Source: Wikipedia, Landscape painting]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#multiple-explanatory-variables",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#multiple-explanatory-variables",
    "title": "The language of models",
    "section": "Multiple explanatory variables",
    "text": "Multiple explanatory variables\n.panelset[ .panel[.panel-name[Plot] .pull-left-narrow[ .question[ How, if at all, does the relationship between width and height of paintings vary by whether or not they have any landscape elements?]] .pull-right-wide[]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#extending-regression-lines",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#extending-regression-lines",
    "title": "The language of models",
    "section": "Extending regression lines",
    "text": "Extending regression lines\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#models---upsides-and-downsides",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#models---upsides-and-downsides",
    "title": "The language of models",
    "section": "Models - upsides and downsides",
    "text": "Models - upsides and downsides\n\nModels can sometimes reveal patterns that are not evident in a graph of the data. This is a great advantage of modeling over simple visual inspection of data.\nThere is a real risk, however, that a model is imposing structure that is not really there on the scatter of data, just as people imagine animal shapes in the stars. A skeptical approach is always warranted."
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#variation-around-the-model",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#variation-around-the-model",
    "title": "The language of models",
    "section": "Variation around the model…",
    "text": "Variation around the model…\nis just as important as the model, if not more!\nStatistics is the explanation of variation in the context of what remains unexplained.\n\nThe scatter suggests that there might be other factors that account for large parts of painting-to-painting variability, or perhaps just that randomness plays a big role.\nAdding more explanatory variables to a model can sometimes usefully reduce the size of the scatter around the model. (We’ll talk more about this later.)"
  },
  {
    "objectID": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#how-do-we-use-models",
    "href": "slides/u4-d01-language-of-models/u4-d01-language-of-models.html#how-do-we-use-models",
    "title": "The language of models",
    "section": "How do we use models?",
    "text": "How do we use models?\n\nExplanation: Characterize the relationship between \\(y\\) and \\(x\\) via slopes for numerical explanatory variables or differences for categorical explanatory variables\nPrediction: Plug in \\(x\\), get the predicted \\(y\\)"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html",
    "title": "Fitting and interpreting models",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#data-paris-paintings",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#data-paris-paintings",
    "title": "Fitting and interpreting models",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings\n\npp <- read_csv(\"data/paris-paintings.csv\", na = c(\"n/a\", \"\", \"NA\"))\n\n\nNumber of observations: 3393\nNumber of variables: 61"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#goal-predict-height-from-width",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#goal-predict-height-from-width",
    "title": "Fitting and interpreting models",
    "section": "Goal: Predict height from width",
    "text": "Goal: Predict height from width\n\\[\\widehat{height}_{i} = \\beta_0 + \\beta_1 \\times width_{i}\\]"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#step-1-specify-model",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#step-1-specify-model",
    "title": "Fitting and interpreting models",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#step-2-set-model-fitting-engine",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#step-2-set-model-fitting-engine",
    "title": "Fitting and interpreting models",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\nlinear_reg() %>%\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#step-3-fit-model-estimate-parameters",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#step-3-fit-model-estimate-parameters",
    "title": "Fitting and interpreting models",
    "section": "Step 3: Fit model & estimate parameters",
    "text": "Step 3: Fit model & estimate parameters\n… using formula syntax\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(Height_in ~ Width_in, data = pp)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Height_in ~ Width_in, data = data)\n\nCoefficients:\n(Intercept)     Width_in  \n     3.6214       0.7808"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#a-closer-look-at-model-output",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#a-closer-look-at-model-output",
    "title": "Fitting and interpreting models",
    "section": "A closer look at model output",
    "text": "A closer look at model output\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Height_in ~ Width_in, data = data)\n\nCoefficients:\n(Intercept)     Width_in  \n     3.6214       0.7808  \n\n\n.large[]"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#a-tidy-look-at-model-output",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#a-tidy-look-at-model-output",
    "title": "Fitting and interpreting models",
    "section": "A tidy look at model output",
    "text": "A tidy look at model output\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(Height_in ~ Width_in, data = pp) %>%\n  tidy()\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    3.62    0.254        14.3 8.82e-45\n2 Width_in       0.781   0.00950      82.1 0       \n\n\n.large[]"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#slope-and-intercept",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#slope-and-intercept",
    "title": "Fitting and interpreting models",
    "section": "Slope and intercept",
    "text": "Slope and intercept\n.large[]\n–\n\nSlope: For each additional inch the painting is wider, the height is expected to be higher, on average, by 0.781 inches.\n\n\n\n\n\n\n\n- Intercept: Paintings that are 0 inches wide are expected to be 3.62 inches high, on average. (Does this make sense?)"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#correlation-does-not-imply-causation",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#correlation-does-not-imply-causation",
    "title": "Fitting and interpreting models",
    "section": "Correlation does not imply causation",
    "text": "Correlation does not imply causation\nRemember this when interpreting model coefficients\n\n\n\n\n\n\n\n\n\n.footnote[ Source: XKCD, Cell phones]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#linear-model-with-a-single-predictor",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#linear-model-with-a-single-predictor",
    "title": "Fitting and interpreting models",
    "section": "Linear model with a single predictor",
    "text": "Linear model with a single predictor\n\nWe’re interested in \\(\\beta_0\\) (population parameter for the intercept) and \\(\\beta_1\\) (population parameter for the slope) in the following model:\n\n\\[\\hat{y}_{i} = \\beta_0 + \\beta_1~x_{i}\\]\n\n\n\n\n\n\n- Tough luck, you can’t have them…\n\n\n\n\n- So we use sample statistics to estimate them:\n\n\n\\[\\hat{y}_{i} = b_0 + b_1~x_{i}\\]"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#least-squares-regression",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#least-squares-regression",
    "title": "Fitting and interpreting models",
    "section": "Least squares regression",
    "text": "Least squares regression\n\nThe regression line minimizes the sum of squared residuals.\n\n\n\n\n\n\n\n- If \\(e_i = y_i - \\hat{y}_i\\), then, the regression line minimizes \\(\\sum_{i = 1}^n e_i^2\\)."
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#visualizing-residuals",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#visualizing-residuals",
    "title": "Fitting and interpreting models",
    "section": "Visualizing residuals",
    "text": "Visualizing residuals"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#visualizing-residuals-cont.",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#visualizing-residuals-cont.",
    "title": "Fitting and interpreting models",
    "section": "Visualizing residuals (cont.)",
    "text": "Visualizing residuals (cont.)"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#visualizing-residuals-cont.-1",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#visualizing-residuals-cont.-1",
    "title": "Fitting and interpreting models",
    "section": "Visualizing residuals (cont.)",
    "text": "Visualizing residuals (cont.)"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#properties-of-least-squares-regression",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#properties-of-least-squares-regression",
    "title": "Fitting and interpreting models",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(x\\) and average \\(y\\), \\((\\bar{x}, \\bar{y})\\):\n\n\\[\\bar{y} = b_0 + b_1 \\bar{x} ~ \\rightarrow ~ b_0 = \\bar{y} - b_1 \\bar{x}\\]\n\n\n\n\n\n\n- The slope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_y}{s_x}\\)\n\n\n\n\n- The sum of the residuals is zero: \\(\\sum_{i = 1}^n e_i = 0\\)\n\n\n\n\nThe residuals and \\(x\\) values are uncorrelated\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#categorical-predictor-with-2-levels",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#categorical-predictor-with-2-levels",
    "title": "Fitting and interpreting models",
    "section": "Categorical predictor with 2 levels",
    "text": "Categorical predictor with 2 levels\n.pull-left-narrow[ .small[]] .pull-right-wide[ - landsALL = 0: No landscape features - landsALL = 1: Some landscape features]"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#height-landscape-features",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#height-landscape-features",
    "title": "Fitting and interpreting models",
    "section": "Height & landscape features",
    "text": "Height & landscape features\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(Height_in ~ factor(landsALL), data = pp) %>%\n  tidy()\n\n# A tibble: 2 x 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)          22.7      0.328      69.1 0       \n2 factor(landsALL)1    -5.65     0.532     -10.6 7.97e-26"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#height-landscape-features-1",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#height-landscape-features-1",
    "title": "Fitting and interpreting models",
    "section": "Height & landscape features",
    "text": "Height & landscape features\n\\[\\widehat{Height_{in}} = 22.7 - 5.645~landsALL\\]\n\nSlope: Paintings with landscape features are expected, on average, to be 5.645 inches shorter than paintings that without landscape features\n\nCompares baseline level (landsALL = 0) to the other level (landsALL = 1)\n\nIntercept: Paintings that don’t have landscape features are expected, on average, to be 22.7 inches tall"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#relationship-between-height-and-school",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#relationship-between-height-and-school",
    "title": "Fitting and interpreting models",
    "section": "Relationship between height and school",
    "text": "Relationship between height and school\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(Height_in ~ school_pntg, data = pp) %>%\n  tidy()\n\n# A tibble: 7 x 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#dummy-variables",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#dummy-variables",
    "title": "Fitting and interpreting models",
    "section": "Dummy variables",
    "text": "Dummy variables\n\n\n# A tibble: 7 x 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780  \n\n\n\nWhen the categorical explanatory variable has many levels, they’re encoded to dummy variables\nEach coefficient describes the expected difference between heights in that particular school compared to the baseline level"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#categorical-predictor-with-3-levels",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#categorical-predictor-with-3-levels",
    "title": "Fitting and interpreting models",
    "section": "Categorical predictor with 3+ levels",
    "text": "Categorical predictor with 3+ levels\n.pull-left-wide[] .pull-right-narrow[ .small[]]"
  },
  {
    "objectID": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#relationship-between-height-and-school-1",
    "href": "slides/u4-d02-fitting-interpreting-models/u4-d02-fitting-interpreting-models.html#relationship-between-height-and-school-1",
    "title": "Fitting and interpreting models",
    "section": "Relationship between height and school",
    "text": "Relationship between height and school\n.small[]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html",
    "title": "Modeling non-linear relationships",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#data-paris-paintings",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#data-paris-paintings",
    "title": "Modeling non-linear relationships",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings\n\npp <- read_csv(\"data/paris-paintings.csv\", na = c(\"n/a\", \"\", \"NA\"))\n\n\nNumber of observations: 3393\nNumber of variables: 61"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#linear-models",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#linear-models",
    "title": "Modeling non-linear relationships",
    "section": "“Linear” models",
    "text": "“Linear” models\n\nWe’re fitting a “linear” model, which assumes a linear relationship between our explanatory and response variables.\nBut how do we assess this?"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#graphical-diagnostic-residuals-plot",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#graphical-diagnostic-residuals-plot",
    "title": "Modeling non-linear relationships",
    "section": "Graphical diagnostic: residuals plot",
    "text": "Graphical diagnostic: residuals plot\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#more-on-augment",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#more-on-augment",
    "title": "Modeling non-linear relationships",
    "section": "More on augment()",
    "text": "More on augment()\n\nglimpse(ht_wt_fit_aug)\n\nRows: 3,135\nColumns: 9\n$ .rownames  <chr> \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",~\n$ Height_in  <dbl> 37, 18, 13, 14, 14, 7, 6, 6, 15, 9, 9, 16, 1~\n$ Width_in   <dbl> 29.5, 14.0, 16.0, 18.0, 18.0, 10.0, 13.0, 13~\n$ .fitted    <dbl> 26.65490, 14.55256, 16.11415, 17.67574, 17.6~\n$ .resid     <dbl> 10.3451004, 3.4474447, -3.1141481, -3.675740~\n$ .hat       <dbl> 0.0003991488, 0.0003961825, 0.0003611963, 0.~\n$ .sigma     <dbl> 8.303538, 8.305367, 8.305409, 8.305336, 8.30~\n$ .cooksd    <dbl> 3.099689e-04, 3.416655e-05, 2.541574e-05, 3.~\n$ .std.resid <dbl> 1.24600543, 0.41522347, -0.37507338, -0.4427~"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#looking-for",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#looking-for",
    "title": "Modeling non-linear relationships",
    "section": "Looking for…",
    "text": "Looking for…\n\nResiduals distributed randomly around 0\nWith no visible pattern along the x or y axes"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for",
    "title": "Modeling non-linear relationships",
    "section": "Not looking for…",
    "text": "Not looking for…\n.large[ Fan shapes]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for-1",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for-1",
    "title": "Modeling non-linear relationships",
    "section": "Not looking for…",
    "text": "Not looking for…\n.large[ Groups of patterns]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for-2",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for-2",
    "title": "Modeling non-linear relationships",
    "section": "Not looking for…",
    "text": "Not looking for…\n.large[ Residuals correlated with predicted values]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for-3",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#not-looking-for-3",
    "title": "Modeling non-linear relationships",
    "section": "Not looking for…",
    "text": "Not looking for…\n.large[ Any patterns!]\n\n\n\n\n\n\n\n\n\n\n.question[ What patterns does the residuals plot reveal that should make us question whether a linear model is a good fit for modeling the relationship between height and width of paintings?]\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#data-paris-paintings-1",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#data-paris-paintings-1",
    "title": "Modeling non-linear relationships",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#price-vs.-width",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#price-vs.-width",
    "title": "Modeling non-linear relationships",
    "section": "Price vs. width",
    "text": "Price vs. width"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#focus-on-paintings-with-width_in-100",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#focus-on-paintings-with-width_in-100",
    "title": "Modeling non-linear relationships",
    "section": "Focus on paintings with Width_in < 100",
    "text": "Focus on paintings with Width_in < 100\nThat is, paintings with width < 2.54 m\n\npp_wt_lt_100 <- pp %>% \n  filter(Width_in < 100)"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#price-vs.-width-1",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#price-vs.-width-1",
    "title": "Modeling non-linear relationships",
    "section": "Price vs. width",
    "text": "Price vs. width\n.question[ Which plot shows a more linear relationship?]\n.small[]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#price-vs.-width-residuals",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#price-vs.-width-residuals",
    "title": "Modeling non-linear relationships",
    "section": "Price vs. width, residuals",
    "text": "Price vs. width, residuals\n.question[ Which plot shows a residuals that are uncorrelated with predicted values from the model? Also, what is the unit of the residuals?]\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#transforming-the-data",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#transforming-the-data",
    "title": "Modeling non-linear relationships",
    "section": "Transforming the data",
    "text": "Transforming the data\n\nWe saw that price has a right-skewed distribution, and the relationship between price and width of painting is non-linear.\n\n\n\n\n\n\n\n- In these situations a transformation applied to the response variable may be useful.\n\n\n\n\n- In order to decide which transformation to use, we should examine the distribution of the response variable.\n\n\n\n\nThe extremely right skewed distribution suggests that a log transformation may be useful.\n\nlog = natural log, \\(ln\\)\nDefault base of the log function in R is the natural log:  log(x, base = exp(1))"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#logged-price-vs.-width",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#logged-price-vs.-width",
    "title": "Modeling non-linear relationships",
    "section": "Logged price vs. width",
    "text": "Logged price vs. width\n.question[ How do we interpret the slope of this model?]"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#models-with-log-transformation",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#models-with-log-transformation",
    "title": "Modeling non-linear relationships",
    "section": "Models with log transformation",
    "text": "Models with log transformation\n\nlinear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(log(price) ~ Width_in, data = pp_wt_lt_100) %>%\n  tidy()\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.67     0.0585      79.9  0       \n2 Width_in      0.0192   0.00226      8.48 3.36e-17"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#interpreting-the-slope",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#interpreting-the-slope",
    "title": "Modeling non-linear relationships",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\\[ \\widehat{log(price)} = 4.67 + 0.0192 Width \\]\n\n\n\n\n\n\n- For each additional inch the painting is wider, the log price of the painting is expected to be higher, on average, by 0.0192 livres.\n\n\n\n\n- which is not a very useful statement…"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#working-with-logs",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#working-with-logs",
    "title": "Modeling non-linear relationships",
    "section": "Working with logs",
    "text": "Working with logs\n\nSubtraction and logs: \\(log(a) − log(b) = log(a / b)\\)\n\n\n\n\n\n\n\n- Natural logarithm: \\(e^{log(x)} = x\\)\n\n\n\n\n- We can use these identities to “undo” the log transformation"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#interpreting-the-slope-1",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#interpreting-the-slope-1",
    "title": "Modeling non-linear relationships",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\nThe slope coefficient for the log transformed model is 0.0192, meaning the log price difference between paintings whose widths are one inch apart is predicted to be 0.0192 log livres.\n–\n.question[ Using this information, and properties of logs that we just reviewed, fill in the blanks in the following alternate interpretation of the slope:]\n\n\nFor each additional inch the painting is wider, the price of the painting is expected to be ___ , on average, by a factor of ___.\n\n\\[ log(\\text{price for width x+1}) - log(\\text{price for width x}) = 0.0192 \\]\n–\n\\[ log\\left(\\frac{\\text{price for width x+1}}{\\text{price for width x}}\\right) = 0.0192 \\]\n–\n\\[ e^{log\\left(\\frac{\\text{price for width x+1}}{\\text{price for width x}}\\right)} = e^{0.0192} \\]\n–\n\\[ \\frac{\\text{price for width x+1}}{\\text{price for width x}} \\approx 1.02 \\]\n–\nFor each additional inch the painting is wider, the price of the painting is expected to be higher, on average, by a factor of 1.02."
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#recap",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#recap",
    "title": "Modeling non-linear relationships",
    "section": "Recap",
    "text": "Recap\n\nNon-constant variance is one of the most common model violations, however it is usually fixable by transforming the response (y) variable.\n\n\n\n\n\n\n\n- The most common transformation when the response variable is right skewed is the log transform: \\(log(y)\\), especially useful when the response variable is (extremely) right skewed.\n\n\n\n\n- This transformation is also useful for variance stabilization.\n\n\n\n\nWhen using a log transformation on the response variable the interpretation of the slope changes: “For each unit increase in x, y is expected on average to be higher/lower  by a factor of \\(e^{b_1}\\).”\n\n\n\n\n\n\n\n- Another useful transformation is the square root: \\(\\sqrt{y}\\), especially useful when the response variable is counts."
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#transform-or-learn-more",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#transform-or-learn-more",
    "title": "Modeling non-linear relationships",
    "section": "Transform, or learn more?",
    "text": "Transform, or learn more?\n\nData transformations may also be useful when the relationship is non-linear\nHowever in those cases a polynomial regression may be more appropriate\n\nThis is beyond the scope of this course, but you’re welcomed to try it for your final project, and I’d be happy to provide further guidance"
  },
  {
    "objectID": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#aside-when-y-0",
    "href": "slides/u4-d03-modeling-nonlinear-relationships/u4-d03-modeling-nonlinear-relationships.html#aside-when-y-0",
    "title": "Modeling non-linear relationships",
    "section": "Aside: when \\(y = 0\\)",
    "text": "Aside: when \\(y = 0\\)\nIn some cases the value of the response variable might be 0, and\n\nlog(0)\n\n[1] -Inf\n\n\n–\nThe trick is to add a very small number to the value of the response variable for these cases so that the log function can still be applied:\n\nlog(0 + 0.00001)\n\n[1] -11.51293"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html",
    "title": "Models with multiple predictors",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#data-book-weight-and-volume",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#data-book-weight-and-volume",
    "title": "Models with multiple predictors",
    "section": "Data: Book weight and volume",
    "text": "Data: Book weight and volume\nThe allbacks data frame gives measurements on the volume and weight of 15 books, some of which are paperback and some of which are hardback\n.pull-left[ - Volume - cubic centimetres - Area - square centimetres - Weight - grams] .pull-right[ .small[]]\n.footnote[ .small[ These books are from the bookshelf of J. H. Maindonald at Australian National University.]]"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#book-weight-vs.-volume",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#book-weight-vs.-volume",
    "title": "Models with multiple predictors",
    "section": "Book weight vs. volume",
    "text": "Book weight vs. volume\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#book-weight-vs.-volume-and-cover",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#book-weight-vs.-volume-and-cover",
    "title": "Models with multiple predictors",
    "section": "Book weight vs. volume and cover",
    "text": "Book weight vs. volume and cover\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#interpretation-of-estimates",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#interpretation-of-estimates",
    "title": "Models with multiple predictors",
    "section": "Interpretation of estimates",
    "text": "Interpretation of estimates\n\n\n# A tibble: 3 x 5\n  term        estimate std.error statistic      p.value\n  <chr>          <dbl>     <dbl>     <dbl>        <dbl>\n1 (Intercept)  198.      59.2         3.34 0.00584     \n2 volume         0.718    0.0615     11.7  0.0000000660\n3 coverpb     -184.      40.5        -4.55 0.000672    \n\n\n\n\n\n\n\n\n- Slope - volume: All else held constant, for each additional cubic centimetre books are larger in volume, we would expect the weight to be higher, on average, by 0.718 grams.\n\n\n\n\n- Slope - cover: All else held constant, paperback books are weigh, on average, by 184 grams less than hardcover books.\n\n\n\n\nIntercept: Hardcover books with 0 volume are expected to weigh 198 grams, on average. (Doesn’t make sense in context.)"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#main-vs.-interaction-effects",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#main-vs.-interaction-effects",
    "title": "Models with multiple predictors",
    "section": "Main vs. interaction effects",
    "text": "Main vs. interaction effects\n.question[ Suppose we want to predict weight of books from their volume and cover type (hardback vs. paperback). Do you think a model with main effects or interaction effects is more appropriate? Explain your reasoning.]"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#in-pursuit-of-occams-razor",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#in-pursuit-of-occams-razor",
    "title": "Models with multiple predictors",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\nOccam’s Razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.\n\n\n\n\n\n\n\n- Model selection follows this principle.\n\n\n\n\n- We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model.\n\n\n\n\nIn other words, we prefer the simplest best model, i.e. parsimonious model.\n\n\n.pull-left[] .pull-right[ .question[ Visually, which of the two models is preferable under Occam’s razor?]]"
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#r-squared",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#r-squared",
    "title": "Models with multiple predictors",
    "section": "R-squared",
    "text": "R-squared\n\n\\(R^2\\) is the percentage of variability in the response variable explained by the regression model.\n\n\nglance(book_main_fit)$r.squared\n\n[1] 0.9274776\n\nglance(book_int_fit)$r.squared\n\n[1] 0.9297137\n\n\n\n\n\n\n\n\n- Clearly the model with interactions has a higher \\(R^2\\).\n\n\n\n\n- However using \\(R^2\\) for model selection in models with multiple explanatory variables is not a good idea as \\(R^2\\) increases when any variable is added to the model."
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#adjusted-r-squared",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#adjusted-r-squared",
    "title": "Models with multiple predictors",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared\n… a (more) objective measure for model selection\n\nAdjusted \\(R^2\\) doesn’t increase if the new variable does not provide any new informaton or is completely unrelated, as it applies a penalty for number of variables included in the model.\nThis makes adjusted \\(R^2\\) a preferable metric for model selection in multiple regression models."
  },
  {
    "objectID": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#comparing-models",
    "href": "slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#comparing-models",
    "title": "Models with multiple predictors",
    "section": "Comparing models",
    "text": "Comparing models\n.pull-left[] .pull-right[]\n–\n.pull-left-wide[ .small[ - Is R-sq higher for int model?]]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html",
    "title": "More models with multiple predictors",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#the-data",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#the-data",
    "title": "More models with multiple predictors",
    "section": "The data",
    "text": "The data\n\npp <- read_csv(\n  \"data/paris-paintings.csv\",\n  na = c(\"n/a\", \"\", \"NA\")\n) %>%\n  mutate(log_price = log(price))"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#multiple-predictors",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#multiple-predictors",
    "title": "More models with multiple predictors",
    "section": "Multiple predictors",
    "text": "Multiple predictors\n\nResponse variable: log_price\nExplanatory variables: Width and height\n\n\npp_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(log_price ~ Width_in + Height_in, data = pp)\ntidy(pp_fit)\n\n# A tibble: 3 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.77     0.0579      82.4  0       \n2 Width_in      0.0269   0.00373      7.22 6.58e-13\n3 Height_in    -0.0133   0.00395     -3.36 7.93e- 4"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#linear-model-with-multiple-predictors",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#linear-model-with-multiple-predictors",
    "title": "More models with multiple predictors",
    "section": "Linear model with multiple predictors",
    "text": "Linear model with multiple predictors\n\n\n# A tibble: 3 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.77     0.0579      82.4  0       \n2 Width_in      0.0269   0.00373      7.22 6.58e-13\n3 Height_in    -0.0133   0.00395     -3.36 7.93e- 4\n\n\n\n\\[\\widehat{log\\_price} = 4.77 + 0.0269 \\times width - 0.0133 \\times height\\]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#visualizing-models-with-multiple-predictors",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#visualizing-models-with-multiple-predictors",
    "title": "More models with multiple predictors",
    "section": "Visualizing models with multiple predictors",
    "text": "Visualizing models with multiple predictors\n.panelset[ .panel[.panel-name[Plot] .pull-left-wide[]] .panel[.panel-name[Code]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#price-surface-area-and-living-artist",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#price-surface-area-and-living-artist",
    "title": "More models with multiple predictors",
    "section": "Price, surface area, and living artist",
    "text": "Price, surface area, and living artist\n\nExplore the relationship between price of paintings and surface area, conditioned on whether or not the artist is still living\nFirst visualize and explore, then model\nBut first, prep the data\n\n.midi[]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#typical-surface-area",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#typical-surface-area",
    "title": "More models with multiple predictors",
    "section": "Typical surface area",
    "text": "Typical surface area\n.panelset[ .panel[.panel-name[Plot] .pull-left-narrow[ Typical surface area appears to be less than 1000 square inches (~ 80cm x 80cm). There are very few paintings that have surface area above 5000 square inches.] .pull-right-wide[]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#narrowing-the-scope",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#narrowing-the-scope",
    "title": "More models with multiple predictors",
    "section": "Narrowing the scope",
    "text": "Narrowing the scope\n.panelset[ .panel[.panel-name[Plot] For simplicity let’s focus on the paintings with Surface < 5000:] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#facet-to-get-a-better-look",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#facet-to-get-a-better-look",
    "title": "More models with multiple predictors",
    "section": "Facet to get a better look",
    "text": "Facet to get a better look\n.panelset[ .panel[.panel-name[Plot]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#two-ways-to-model",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#two-ways-to-model",
    "title": "More models with multiple predictors",
    "section": "Two ways to model",
    "text": "Two ways to model\n\nMain effects: Assuming relationship between surface and logged price does not vary by whether or not the artist is living.\nInteraction effects: Assuming relationship between surface and logged price varies by whether or not the artist is living."
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interacting-explanatory-variables",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interacting-explanatory-variables",
    "title": "More models with multiple predictors",
    "section": "Interacting explanatory variables",
    "text": "Interacting explanatory variables\n\nIncluding an interaction effect in the model allows for different slopes, i.e.  nonparallel lines.\nThis implies that the regression coefficient for an explanatory variable would change as another explanatory variable changes.\nThis can be accomplished by adding an interaction variable: the product of two explanatory variables."
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#two-ways-to-model-1",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#two-ways-to-model-1",
    "title": "More models with multiple predictors",
    "section": "Two ways to model",
    "text": "Two ways to model\n.pull-left-narrow[ - Main effects: Assuming relationship between surface and logged price does not vary by whether or not the artist is living - Interaction effects: Assuming relationship between surface and logged price varies by whether or not the artist is living] .pull-right-wide[]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#fit-model-with-main-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#fit-model-with-main-effects",
    "title": "More models with multiple predictors",
    "section": "Fit model with main effects",
    "text": "Fit model with main effects\n\nResponse variable: log_price\nExplanatory variables: Surface area and artistliving\n\n.midi[]\n–\n\\[\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times artistliving\\]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#solving-the-model",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#solving-the-model",
    "title": "More models with multiple predictors",
    "section": "Solving the model",
    "text": "Solving the model\n\nNon-living artist: Plug in 0 for artistliving\n\n\\(\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times 0\\)\n\\(= 4.88 + 0.000265 \\times surface\\)\n\n\n\n\n\n\n- Living artist: Plug in 1 for artistliving\n\n\n\\(\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times 1\\) \\(= 5.017 + 0.000265 \\times surface\\)"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#visualizing-main-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#visualizing-main-effects",
    "title": "More models with multiple predictors",
    "section": "Visualizing main effects",
    "text": "Visualizing main effects\n.pull-left-narrow[ - Same slope: Rate of change in price as the surface area increases does not vary between paintings by living and non-living artists. - Different intercept: Paintings by living artists are consistently more expensive than paintings by non-living artists.] .pull-right-wide[]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interpreting-main-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interpreting-main-effects",
    "title": "More models with multiple predictors",
    "section": "Interpreting main effects",
    "text": "Interpreting main effects\n.midi[]\n\nAll else held constant, for each additional square inch in painting’s surface area, the price of the painting is predicted, on average, to be higher by a factor of 1.\nAll else held constant, paintings by a living artist are predicted, on average, to be higher by a factor of 1.15 compared to paintings by an artist who is no longer alive.\nPaintings that are by an artist who is not alive and that have a surface area of 0 square inches are predicted, on average, to be 132 livres."
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#main-vs.-interaction-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#main-vs.-interaction-effects",
    "title": "More models with multiple predictors",
    "section": "Main vs. interaction effects",
    "text": "Main vs. interaction effects\n\nThe way we specified our main effects model only lets artistliving affect the intercept.\nModel implicitly assumes that paintings with living and deceased artists have the same slope and only allows for different intercepts.\n\n.question[ What seems more appropriate in this case? + Same slope and same intercept for both colours + Same slope and different intercept for both colours + Different slope and different intercept for both colours]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interaction-surface-artistliving",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interaction-surface-artistliving",
    "title": "More models with multiple predictors",
    "section": "Interaction: Surface * artistliving",
    "text": "Interaction: Surface * artistliving"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#fit-model-with-interaction-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#fit-model-with-interaction-effects",
    "title": "More models with multiple predictors",
    "section": "Fit model with interaction effects",
    "text": "Fit model with interaction effects\n\nResponse variable: log_price\nExplanatory variables: Surface area, artistliving, and their interaction\n\n.midi[]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#linear-model-with-interaction-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#linear-model-with-interaction-effects",
    "title": "More models with multiple predictors",
    "section": "Linear model with interaction effects",
    "text": "Linear model with interaction effects\n.midi[]\n\\[\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface - 0.126 \\times artistliving\\]\n\\[+ ~ 0.00048 \\times surface * artistliving\\]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interpretation-of-interaction-effects",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#interpretation-of-interaction-effects",
    "title": "More models with multiple predictors",
    "section": "Interpretation of interaction effects",
    "text": "Interpretation of interaction effects\n\nRate of change in price as the surface area of the painting increases does vary between paintings by living and non-living artists (different slopes),\nSome paintings by living artists are more expensive than paintings by non-living artists, and some are not (different intercept).\n\n.small[ .pull-left[ - Non-living artist: \\(\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface\\) \\(- 0.126 \\times 0 + 0.00048 \\times surface \\times 0\\) \\(= 4.91 + 0.00021 \\times surface\\) - Living artist: \\(\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface\\) \\(- 0.126 \\times 1 + 0.00048 \\times surface \\times 1\\) \\(= 4.91 + 0.00021 \\times surface\\) \\(- 0.126 + 0.00048 \\times surface\\) \\(= 4.784 + 0.00069 \\times surface\\)] .pull-right[]]"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#comparing-models",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#comparing-models",
    "title": "More models with multiple predictors",
    "section": "Comparing models",
    "text": "Comparing models\nIt appears that adding the interaction actually increased adjusted \\(R^2\\), so we should indeed use the model with the interactions.\n\nglance(pp_main_fit)$adj.r.squared\n\n[1] 0.01258977\n\nglance(pp_int_fit)$adj.r.squared\n\n[1] 0.01676753"
  },
  {
    "objectID": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#third-order-interactions",
    "href": "slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#third-order-interactions",
    "title": "More models with multiple predictors",
    "section": "Third order interactions",
    "text": "Third order interactions\n\nCan you? Yes\nShould you? Probably not if you want to interpret these interactions in context of the data."
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html",
    "title": "Logistic regression",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#spam-filters",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#spam-filters",
    "title": "Logistic regression",
    "section": "Spam filters",
    "text": "Spam filters\n.pull-left-narrow[ - Data from 3921 emails and 21 variables on them - Outcome: whether the email is spam or not - Predictors: number of characters, whether the email had “Re:” in the subject, time at which email was sent, number of times the word “inherit” shows up in the email, etc.] .pull-right-wide[ .small[]]\n\n.question[ Would you expect longer or shorter emails to be spam?]\n–\n.pull-left[] .pull-right[]\n\n.question[ Would you expect emails that have subjects starting with “Re:”, “RE:”, “re:”, or “rE:” to be spam or not?]\n–"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#modelling-spam",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#modelling-spam",
    "title": "Logistic regression",
    "section": "Modelling spam",
    "text": "Modelling spam\n\nBoth number of characters and whether the message has “re:” in the subject might be related to whether the email is spam. How do we come up with a model that will let us explore this relationship?\n\n\n\n\n\n\n\n- For simplicity, we’ll focus on the number of characters (num_char) as predictor, but the model we describe can be expanded to take multiple predictors as well."
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#modelling-spam-1",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#modelling-spam-1",
    "title": "Logistic regression",
    "section": "Modelling spam",
    "text": "Modelling spam\nThis isn’t something we can reasonably fit a linear model to – we need something different!"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#framing-the-problem",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#framing-the-problem",
    "title": "Logistic regression",
    "section": "Framing the problem",
    "text": "Framing the problem\n\nWe can treat each outcome (spam and not) as successes and failures arising from separate Bernoulli trials\n\nBernoulli trial: a random experiment with exactly two possible outcomes, “success” and “failure”, in which the probability of success is the same every time the experiment is conducted\n\n\n\n\n\n\n\n\n- Each Bernoulli trial can have a separate probability of success\n\n\n\n\n- We can then use the predictor variables to model that probability of success, \\(p_i\\)\n\n\n\n\nWe can’t just use a linear model for \\(p_i\\) (since \\(p_i\\) must be between 0 and 1) but we can transform the linear model to have the appropriate range"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#generalized-linear-models",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#generalized-linear-models",
    "title": "Logistic regression",
    "section": "Generalized linear models",
    "text": "Generalized linear models\n\nThis is a very general way of addressing many problems in regression and the resulting models are called generalized linear models (GLMs)\n\n\n\n\n\n\n\n- Logistic regression is just one example"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#three-characteristics-of-glms",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#three-characteristics-of-glms",
    "title": "Logistic regression",
    "section": "Three characteristics of GLMs",
    "text": "Three characteristics of GLMs\nAll GLMs have the following three characteristics:\n\nA probability distribution describing a generative model for the outcome variable\n\n\n\n\n\n\n\n2. A linear model:\n\n\n\n\n3. A link function that relates the linear model to the parameter of the outcome distribution\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#logistic-regression-1",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#logistic-regression-1",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nLogistic regression is a GLM used to model a binary categorical outcome using numerical and categorical predictors\n\n\n\n\n\n\n\n- To finish specifying the Logistic model we just need to define a reasonable link function that connects \\(\\eta_i\\) to \\(p_i\\): logit function\n\n\n\n\n- Logit function: For \\(0\\le p \\le 1\\)\n\n\n\\[logit(p) = \\log\\left(\\frac{p}{1-p}\\right)\\]"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#logit-function-visualised",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#logit-function-visualised",
    "title": "Logistic regression",
    "section": "Logit function, visualised",
    "text": "Logit function, visualised"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#properties-of-the-logit",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#properties-of-the-logit",
    "title": "Logistic regression",
    "section": "Properties of the logit",
    "text": "Properties of the logit\n\nThe logit function takes a value between 0 and 1 and maps it to a value between \\(-\\infty\\) and \\(\\infty\\)\n\n\n\n\n\n\n\n- Inverse logit (logistic) function:\n\n\n\n\n- The inverse logit function takes a value between \\(-\\infty\\) and \\(\\infty\\) and maps it to a value between 0 and 1\n\n\n\n\nThis formulation is also useful for interpreting the model, since the logit can be interpreted as the log odds of a success – more on this later"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#the-logistic-regression-model",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#the-logistic-regression-model",
    "title": "Logistic regression",
    "section": "The logistic regression model",
    "text": "The logistic regression model\n\nBased on the three GLM criteria we have\n\n\\(y_i \\sim \\text{Bern}(p_i)\\)\n\\(\\eta_i = \\beta_0+\\beta_1 x_{1,i} + \\cdots + \\beta_n x_{n,i}\\)\n\\(\\text{logit}(p_i) = \\eta_i\\)\n\n\n\n\n\n\n\n\n- From which we get\n\n\n\\[p_i = \\frac{\\exp(\\beta_0+\\beta_1 x_{1,i} + \\cdots + \\beta_k x_{k,i})}{1+\\exp(\\beta_0+\\beta_1 x_{1,i} + \\cdots + \\beta_k x_{k,i})}\\]"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#modeling-spam",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#modeling-spam",
    "title": "Logistic regression",
    "section": "Modeling spam",
    "text": "Modeling spam\nIn R we fit a GLM in the same way as a linear model except we\n\nspecify the model with logistic_reg()\nuse \"glm\" instead of \"lm\" as the engine\ndefine family = \"binomial\" for the link function to be used in the model\n\n–\n\nspam_fit <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  fit(spam ~ num_char, data = email, family = \"binomial\")\n\ntidy(spam_fit)\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)  -1.80     0.0716     -25.1  2.04e-139\n2 num_char     -0.0621   0.00801     -7.75 9.50e- 15"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#spam-model",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#spam-model",
    "title": "Logistic regression",
    "section": "Spam model",
    "text": "Spam model\n\ntidy(spam_fit)\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)  -1.80     0.0716     -25.1  2.04e-139\n2 num_char     -0.0621   0.00801     -7.75 9.50e- 15\n\n\n–\nModel:\n\\[\\log\\left(\\frac{p}{1-p}\\right) = -1.80-0.0621\\times \\text{num_char}\\]"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#pspam-for-an-email-with-2000-characters",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#pspam-for-an-email-with-2000-characters",
    "title": "Logistic regression",
    "section": "P(spam) for an email with 2000 characters",
    "text": "P(spam) for an email with 2000 characters\n\\[\\log\\left(\\frac{p}{1-p}\\right) = -1.80-0.0621\\times 2\\]\n–\n\\[\\frac{p}{1-p} = \\exp(-1.9242) = 0.15 \\rightarrow p = 0.15 \\times (1 - p)\\]\n–\n\\[p = 0.15 - 0.15p \\rightarrow 1.15p = 0.15\\]\n–\n\\[p = 0.15 / 1.15 = 0.13\\]\n\n.question[ What is the probability that an email with 15000 characters is spam? What about an email with 40000 characters?]\n–\n.pull-left[] .pull-right[ - .light-blue[2K chars: P(spam) = 0.13] - .yellow[15K chars, P(spam) = 0.06] - .green[40K chars, P(spam) = 0.01]]\n\n.question[ Would you prefer an email with 2000 characters to be labelled as spam or not? How about 40,000 characters?]\n\n\n\n\n\n\n\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#false-positive-and-negative",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#false-positive-and-negative",
    "title": "Logistic regression",
    "section": "False positive and negative",
    "text": "False positive and negative\n\n\n\n\n\n\n\n\n\nEmail is spam\nEmail is not spam\n\n\n\n\nEmail labelled spam\nTrue positive\nFalse positive (Type 1 error)\n\n\nEmail labelled not spam\nFalse negative (Type 2 error)\nTrue negative\n\n\n\n\n\n\n\n\n\n- False negative rate = P(Labelled not spam | Email spam) = FN / (TP + FN)\n\n\n- False positive rate = P(Labelled spam | Email not spam) = FP / (FP + TN)"
  },
  {
    "objectID": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#sensitivity-and-specificity-1",
    "href": "slides/u4-d06-logistic-reg/u4-d06-logistic-reg.html#sensitivity-and-specificity-1",
    "title": "Logistic regression",
    "section": "Sensitivity and specificity",
    "text": "Sensitivity and specificity\n\n\n\n\n\n\n\n\n\nEmail is spam\nEmail is not spam\n\n\n\n\nEmail labelled spam\nTrue positive\nFalse positive (Type 1 error)\n\n\nEmail labelled not spam\nFalse negative (Type 2 error)\nTrue negative\n\n\n\n–\n\nSensitivity = P(Labelled spam | Email spam) = TP / (TP + FN)\n\nSensitivity = 1 − False negative rate\n\nSpecificity = P(Labelled not spam | Email not spam) = TN / (FP + TN)\n\nSpecificity = 1 − False positive rate\n\n\n\n.question[ If you were designing a spam filter, would you want sensitivity and specificity to be high or low? What are the trade-offs associated with each decision? ]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html",
    "title": "Prediction and overfitting",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#goal-building-a-spam-filter",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#goal-building-a-spam-filter",
    "title": "Prediction and overfitting",
    "section": "Goal: Building a spam filter",
    "text": "Goal: Building a spam filter\n\nData: Set of emails and we know if each email is spam/not and other features\nUse logistic regression to predict the probability that an incoming email is spam\nUse model selection to pick the model with the best predictive performance\n\n\n\n\n\n\n\n- Building a model to predict the probability that an email is spam is only half of the battle! We also need a decision rule about which emails get flagged as spam (e.g. what probability should we use as out cutoff?)\n\n\n\n\n- A simple approach: choose a single threshold probability and any email that exceeds that probability is flagged as spam"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#a-multiple-regression-approach",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#a-multiple-regression-approach",
    "title": "Prediction and overfitting",
    "section": "A multiple regression approach",
    "text": "A multiple regression approach\n.panelset[ .panel[.panel-name[Output] .small[]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#prediction-1",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#prediction-1",
    "title": "Prediction and overfitting",
    "section": "Prediction",
    "text": "Prediction\n\nThe mechanics of prediction is easy:\n\nPlug in values of predictors to the model equation\nCalculate the predicted value of the response variable, \\(\\hat{y}\\)\n\n\n\n\n\n\n\n\n- Getting it right is hard! - There is no guarantee the model estimates you have are correct - Or that your model will perform as well with new data as it did with your sample data"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#underfitting-and-overfitting",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#underfitting-and-overfitting",
    "title": "Prediction and overfitting",
    "section": "Underfitting and overfitting",
    "text": "Underfitting and overfitting"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#spending-our-data",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#spending-our-data",
    "title": "Prediction and overfitting",
    "section": "Spending our data",
    "text": "Spending our data\n\nSeveral steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available can lead to overfitting\nAllocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we’ve done so far)\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#splitting-data-1",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#splitting-data-1",
    "title": "Prediction and overfitting",
    "section": "Splitting data",
    "text": "Splitting data\n\nTraining set:\n\nSandbox for model building\nSpend most of your time using the training set to develop the model\nMajority of the data (usually 80%)\n\nTesting set:\n\nHeld in reserve to determine efficacy of one or two chosen models\nCritical to look at it once, otherwise it becomes part of the modeling process\nRemainder of the data (usually 20%)"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#performing-the-split",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#performing-the-split",
    "title": "Prediction and overfitting",
    "section": "Performing the split",
    "text": "Performing the split\n\n# Fix random numbers by setting the seed \n# Enables analysis to be reproducible when random numbers are used \nset.seed(1116)\n\n# Put 80% of the data into the training set \nemail_split <- initial_split(email, prop = 0.80)\n\n# Create data frames for the two sets:\ntrain_data <- training(email_split)\ntest_data  <- testing(email_split)"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#peek-at-the-split",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#peek-at-the-split",
    "title": "Prediction and overfitting",
    "section": "Peek at the split",
    "text": "Peek at the split\n.small[ .pull-left[] .pull-right[]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#fit-a-model-to-the-training-dataset",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#fit-a-model-to-the-training-dataset",
    "title": "Prediction and overfitting",
    "section": "Fit a model to the training dataset",
    "text": "Fit a model to the training dataset\n\nemail_fit <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  fit(spam ~ ., data = train_data, family = \"binomial\")\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#categorical-predictors",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#categorical-predictors",
    "title": "Prediction and overfitting",
    "section": "Categorical predictors",
    "text": "Categorical predictors"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#from-and-sent_email",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#from-and-sent_email",
    "title": "Prediction and overfitting",
    "section": "from and sent_email",
    "text": "from and sent_email\n.pull-left[ - from: Whether the message was listed as from anyone (this is usually set by default for regular outgoing email)] .pull-right[ - sent_email: Indicator for whether the sender had been sent an email in the last 30 days]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#numerical-predictors",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#numerical-predictors",
    "title": "Prediction and overfitting",
    "section": "Numerical predictors",
    "text": "Numerical predictors\n.small[]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#fit-a-model-to-the-training-dataset-1",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#fit-a-model-to-the-training-dataset-1",
    "title": "Prediction and overfitting",
    "section": "Fit a model to the training dataset",
    "text": "Fit a model to the training dataset\n\nemail_fit <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  fit(spam ~ . - from - sent_email - viagra, data = train_data, family = \"binomial\") #<<\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#predict-outcome-on-the-testing-dataset",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#predict-outcome-on-the-testing-dataset",
    "title": "Prediction and overfitting",
    "section": "Predict outcome on the testing dataset",
    "text": "Predict outcome on the testing dataset\n\npredict(email_fit, test_data)\n\n# A tibble: 785 x 1\n  .pred_class\n  <fct>      \n1 0          \n2 0          \n3 0          \n4 0          \n5 0          \n6 0          \n# ... with 779 more rows"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#predict-probabilities-on-the-testing-dataset",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#predict-probabilities-on-the-testing-dataset",
    "title": "Prediction and overfitting",
    "section": "Predict probabilities on the testing dataset",
    "text": "Predict probabilities on the testing dataset\n\nemail_pred <- predict(email_fit, test_data, type = \"prob\") %>%\n  bind_cols(test_data %>% select(spam, time))\n\nemail_pred\n\n# A tibble: 785 x 4\n  .pred_0 .pred_1 spam  time               \n    <dbl>   <dbl> <fct> <dttm>             \n1   0.993 0.00709 0     2012-01-01 11:55:06\n2   0.998 0.00181 0     2012-01-01 13:38:32\n3   0.981 0.0191  0     2012-01-01 23:42:16\n4   0.999 0.00124 0     2012-01-02 09:12:51\n5   0.988 0.0121  0     2012-01-02 10:45:36\n6   0.830 0.170   0     2012-01-02 15:55:03\n# ... with 779 more rows"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#a-closer-look-at-predictions",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#a-closer-look-at-predictions",
    "title": "Prediction and overfitting",
    "section": "A closer look at predictions",
    "text": "A closer look at predictions\n.pull-left-wide[]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#evaluate-the-performance",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#evaluate-the-performance",
    "title": "Prediction and overfitting",
    "section": "Evaluate the performance",
    "text": "Evaluate the performance\nReceiver operating characteristic (ROC) curve+ which plot true positive rate vs. false positive rate (1 - specificity)\n.pull-left[] .pull-right[]\n.footnote[ .small[ +Originally developed for operators of military radar receivers, hence the name.]]"
  },
  {
    "objectID": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#evaluate-the-performance-1",
    "href": "slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#evaluate-the-performance-1",
    "title": "Prediction and overfitting",
    "section": "Evaluate the performance",
    "text": "Evaluate the performance\nFind the area under the curve:\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html",
    "title": "Feature engineering",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#feature-engineering-1",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#feature-engineering-1",
    "title": "Feature engineering",
    "section": "Feature engineering",
    "text": "Feature engineering\n\nWe prefer simple models when possible, but parsimony does not mean sacrificing accuracy (or predictive performance) in the interest of simplicity\n\n\n\n\n\n\n\n- Variables that go into the model and how they are represented are just as critical to success of the model\n\n\n\n\n- Feature engineering allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance)"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#same-training-and-testing-sets-as-before",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#same-training-and-testing-sets-as-before",
    "title": "Feature engineering",
    "section": "Same training and testing sets as before",
    "text": "Same training and testing sets as before\n\n# Fix random numbers by setting the seed \n# Enables analysis to be reproducible when random numbers are used \nset.seed(1116)\n\n# Put 80% of the data into the training set \nemail_split <- initial_split(email, prop = 0.80)\n\n# Create data frames for the two sets:\ntrain_data <- training(email_split)\ntest_data  <- testing(email_split)"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#a-simple-approach-mutate",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#a-simple-approach-mutate",
    "title": "Feature engineering",
    "section": "A simple approach: mutate()",
    "text": "A simple approach: mutate()\n\ntrain_data %>%\n  mutate(\n    date = lubridate::date(time),\n    dow  = wday(time),\n    month = month(time)\n    ) %>%\n  select(time, date, dow, month) %>%\n  sample_n(size = 5) # shuffle to show a variety\n\n# A tibble: 5 x 4\n  time                date         dow month\n  <dttm>              <date>     <dbl> <dbl>\n1 2012-03-15 13:51:35 2012-03-15     5     3\n2 2012-03-03 08:24:02 2012-03-03     7     3\n3 2012-01-18 10:55:23 2012-01-18     4     1\n4 2012-02-24 22:08:59 2012-02-24     6     2\n5 2012-01-11 07:18:51 2012-01-11     4     1"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#modeling-workflow-revisited",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#modeling-workflow-revisited",
    "title": "Feature engineering",
    "section": "Modeling workflow, revisited",
    "text": "Modeling workflow, revisited\n\nCreate a recipe for feature engineering steps to be applied to the training data\n\n\n\n\n\n\n\n- Fit the model to the training data after these steps have been applied\n\n\n\n\n- Using the model estimates from the training data, predict outcomes for the test data\n\n\n\n\nEvaluate the performance of the model on the test data\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#initiate-a-recipe",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#initiate-a-recipe",
    "title": "Feature engineering",
    "section": "Initiate a recipe",
    "text": "Initiate a recipe\n\nemail_rec <- recipe(\n  spam ~ .,          # formula\n  data = train_data  # data to use for cataloguing names and types of variables\n  )\n\nsummary(email_rec)\n\n.xsmall[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#remove-certain-variables",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#remove-certain-variables",
    "title": "Feature engineering",
    "section": "Remove certain variables",
    "text": "Remove certain variables\n\nemail_rec <- email_rec %>%\n  step_rm(from, sent_email)\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#feature-engineer-date",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#feature-engineer-date",
    "title": "Feature engineering",
    "section": "Feature engineer date",
    "text": "Feature engineer date\n\nemail_rec <- email_rec %>%\n  step_date(time, features = c(\"dow\", \"month\")) %>%\n  step_rm(time)\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#discretize-numeric-variables",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#discretize-numeric-variables",
    "title": "Feature engineering",
    "section": "Discretize numeric variables",
    "text": "Discretize numeric variables\n\nemail_rec <- email_rec %>%\n  step_cut(cc, attach, dollar, breaks = c(0, 1)) %>%\n  step_cut(inherit, password, breaks = c(0, 1, 5, 10, 20))\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#create-dummy-variables",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#create-dummy-variables",
    "title": "Feature engineering",
    "section": "Create dummy variables",
    "text": "Create dummy variables\n\nemail_rec <- email_rec %>%\n  step_dummy(all_nominal(), -all_outcomes())\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#remove-zero-variance-variables",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#remove-zero-variance-variables",
    "title": "Feature engineering",
    "section": "Remove zero variance variables",
    "text": "Remove zero variance variables\nVariables that contain only a single value\n\nemail_rec <- email_rec %>%\n  step_zv(all_predictors())\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#all-in-one-place",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#all-in-one-place",
    "title": "Feature engineering",
    "section": "All in one place",
    "text": "All in one place\n\nemail_rec <- recipe(spam ~ ., data = email) %>%\n  step_rm(from, sent_email) %>%\n  step_date(time, features = c(\"dow\", \"month\")) %>%               \n  step_rm(time) %>%\n  step_cut(cc, attach, dollar, breaks = c(0, 1)) %>%\n  step_cut(inherit, password, breaks = c(0, 1, 5, 10, 20)) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_predictors())\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#define-model",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#define-model",
    "title": "Feature engineering",
    "section": "Define model",
    "text": "Define model\n\nemail_mod <- logistic_reg() %>% \n  set_engine(\"glm\")\n\nemail_mod\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#define-workflow",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#define-workflow",
    "title": "Feature engineering",
    "section": "Define workflow",
    "text": "Define workflow\nWorkflows bring together models and recipes so that they can be easily applied to both the training and test data.\n\nemail_wflow <- workflow() %>% \n  add_model(email_mod) %>% \n  add_recipe(email_rec)\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#fit-model-to-training-data",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#fit-model-to-training-data",
    "title": "Feature engineering",
    "section": "Fit model to training data",
    "text": "Fit model to training data\n\nemail_fit <- email_wflow %>% \n  fit(data = train_data)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#make-predictions-for-test-data",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#make-predictions-for-test-data",
    "title": "Feature engineering",
    "section": "Make predictions for test data",
    "text": "Make predictions for test data\n\nemail_pred <- predict(email_fit, test_data, type = \"prob\") %>% \n  bind_cols(test_data) \n\nWarning: There are new levels in a factor: NA\n\nemail_pred\n\n# A tibble: 785 x 23\n  .pred_0  .pred_1 spam  to_multiple from     cc sent_email\n    <dbl>    <dbl> <fct> <fct>       <fct> <int> <fct>     \n1   0.995 0.00451  0     1           1         0 1         \n2   0.999 0.00129  0     0           1         1 1         \n3   0.969 0.0306   0     0           1         0 0         \n4   0.999 0.000816 0     0           1         1 0         \n5   0.993 0.00680  0     0           1         4 0         \n6   0.852 0.148    0     0           1         0 0         \n# ... with 779 more rows, and 16 more variables: time <dttm>,\n#   image <dbl>, attach <dbl>, dollar <dbl>, winner <fct>,\n#   inherit <dbl>, viagra <dbl>, password <dbl>, num_char <dbl>,\n#   line_breaks <int>, format <fct>, re_subj <fct>,\n#   exclaim_subj <dbl>, urgent_subj <fct>, exclaim_mess <dbl>,\n#   number <fct>"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#evaluate-the-performance",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#evaluate-the-performance",
    "title": "Feature engineering",
    "section": "Evaluate the performance",
    "text": "Evaluate the performance\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#evaluate-the-performance-1",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#evaluate-the-performance-1",
    "title": "Feature engineering",
    "section": "Evaluate the performance",
    "text": "Evaluate the performance\n.pull-left[] .pull-right[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#cutoff-probability-0.5",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#cutoff-probability-0.5",
    "title": "Feature engineering",
    "section": "Cutoff probability: 0.5",
    "text": "Cutoff probability: 0.5\n.panelset[ .panel[.panel-name[Output]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#cutoff-probability-0.25",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#cutoff-probability-0.25",
    "title": "Feature engineering",
    "section": "Cutoff probability: 0.25",
    "text": "Cutoff probability: 0.25\n.panelset[ .panel[.panel-name[Output]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#cutoff-probability-0.75",
    "href": "slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#cutoff-probability-0.75",
    "title": "Feature engineering",
    "section": "Cutoff probability: 0.75",
    "text": "Cutoff probability: 0.75\n.panelset[ .panel[.panel-name[Output]] .panel[.panel-name[Code]]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html",
    "title": "Cross validation",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#data",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#data",
    "title": "Cross validation",
    "section": "Data",
    "text": "Data\n\noffice_ratings <- read_csv(\"data/office_ratings.csv\")\noffice_ratings\n\n# A tibble: 188 x 6\n  season episode title         imdb_rating total_votes air_date  \n   <dbl>   <dbl> <chr>               <dbl>       <dbl> <date>    \n1      1       1 Pilot                 7.6        3706 2005-03-24\n2      1       2 Diversity Day         8.3        3566 2005-03-29\n3      1       3 Health Care           7.9        2983 2005-04-05\n4      1       4 The Alliance          8.1        2886 2005-04-12\n5      1       5 Basketball            8.4        3179 2005-04-19\n6      1       6 Hot Girl              7.8        2852 2005-04-26\n# ... with 182 more rows\n\n\n.footnote[ .small[ Source: The data come from data.world, by way of TidyTuesday. ]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#imdb-ratings",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#imdb-ratings",
    "title": "Cross validation",
    "section": "IMDB ratings",
    "text": "IMDB ratings\n.panelset[]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#imdb-ratings-vs.-number-of-votes",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#imdb-ratings-vs.-number-of-votes",
    "title": "Cross validation",
    "section": "IMDB ratings vs. number of votes",
    "text": "IMDB ratings vs. number of votes\n.panelset[]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#outliers",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#outliers",
    "title": "Cross validation",
    "section": "Outliers",
    "text": "Outliers\n.panelset[]\n.footnote[ .small[ If you like the Dinner Party episode, I highly recommend this “oral history” of the episode published on Rolling Stone magazine.]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#imdb-ratings-vs.-seasons",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#imdb-ratings-vs.-seasons",
    "title": "Cross validation",
    "section": "IMDB ratings vs. seasons",
    "text": "IMDB ratings vs. seasons\n.panelset[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#train-test",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#train-test",
    "title": "Cross validation",
    "section": "Train / test",
    "text": "Train / test\n\nCreate an initial split\n\n\nset.seed(1122)\noffice_split <- initial_split(office_ratings) # prop = 3/4 by default\n\n\n\n\n\n\n\n.pull-left[ - Save training data]\n\n\n\n\n.pull-right[ - Save testing data\n\n\n::: {.cell layout-align=“center”}\n\n\n{.r .cell-code} office_test  <- testing(office_split) dim(office_test)\n\n\n::: {.cell-output .cell-output-stdout}\n\n\n]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#specify-model",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#specify-model",
    "title": "Cross validation",
    "section": "Specify model",
    "text": "Specify model\n\noffice_mod <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_mod\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#build-recipe",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#build-recipe",
    "title": "Cross validation",
    "section": "Build recipe",
    "text": "Build recipe\n.panelset[ .panel[.panel-name[Code]] .panel[.panel-name[Output] .small[]]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#build-workflow",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#build-workflow",
    "title": "Cross validation",
    "section": "Build workflow",
    "text": "Build workflow\n.panelset[ .panel[.panel-name[Code]] .panel[.panel-name[Output] .small[]]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#fit-model",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#fit-model",
    "title": "Cross validation",
    "section": "Fit model",
    "text": "Fit model\n.panelset[ .panel[.panel-name[Code]] .panel[.panel-name[Output] .small[]]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#make-predictions-for-training-data",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#make-predictions-for-training-data",
    "title": "Cross validation",
    "section": "Make predictions for training data",
    "text": "Make predictions for training data\n\noffice_train_pred <- predict(office_fit, office_train) %>%\n  bind_cols(office_train %>% select(imdb_rating, title))\n\noffice_train_pred\n\n# A tibble: 141 x 3\n  .pred imdb_rating title            \n  <dbl>       <dbl> <chr>            \n1  7.90         8.1 Garden Party     \n2  8.43         7.9 The Chump        \n3  7.81         7.1 Here Comes Treble\n4  7.94         6.7 Get the Girl     \n5  7.92         7.9 Tallahassee      \n6  8.29         7.7 The Inner Circle \n# ... with 135 more rows"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#r-squared",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#r-squared",
    "title": "Cross validation",
    "section": "R-squared",
    "text": "R-squared\nPercentage of variability in the IMDB ratings explained by the model\n\nrsq(office_train_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.500\n\n\n–\n.question[ Are models with high or low \\(R^2\\) more preferable?]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#rmse",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#rmse",
    "title": "Cross validation",
    "section": "RMSE",
    "text": "RMSE\nAn alternative model performance statistic: root mean square error\n\\[ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}} \\]\n–\n\nrmse(office_train_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.373\n\n\n–\n.question[ Are models with high or low RMSE are more preferable?]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#interpreting-rmse",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#interpreting-rmse",
    "title": "Cross validation",
    "section": "Interpreting RMSE",
    "text": "Interpreting RMSE\n.question[ Is this RMSE considered low or high?]\n\nrmse(office_train_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.373\n\n\n–\n\noffice_train %>%\n  summarise(min = min(imdb_rating), max = max(imdb_rating))\n\n# A tibble: 1 x 2\n    min   max\n  <dbl> <dbl>\n1   6.7   9.7\n\n\n\nclass: middle\n.hand[ .light-blue[ but, really, who cares about predictions on .pink[training] data?]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#make-predictions-for-testing-data",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#make-predictions-for-testing-data",
    "title": "Cross validation",
    "section": "Make predictions for testing data",
    "text": "Make predictions for testing data\n\noffice_test_pred <- predict(office_fit, office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, title))\n\noffice_test_pred\n\n# A tibble: 47 x 3\n  .pred imdb_rating title          \n  <dbl>       <dbl> <chr>          \n1  8.52         8.4 Office Olympics\n2  8.54         8.6 The Client     \n3  8.90         8.8 Christmas Party\n4  8.71         9   The Injury     \n5  8.50         8.2 Boys and Girls \n6  8.46         8.4 Dwight's Speech\n# ... with 41 more rows"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#evaluate-performance-on-testing-data",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#evaluate-performance-on-testing-data",
    "title": "Cross validation",
    "section": "Evaluate performance on testing data",
    "text": "Evaluate performance on testing data\n\nRMSE of model fit to testing data\n\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.386\n\n\n\n\\(R^2\\) of model fit to testing data\n\n\nrsq(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.556"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#training-vs.-testing",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#training-vs.-testing",
    "title": "Cross validation",
    "section": "Training vs. testing",
    "text": "Training vs. testing\n\n\n\n\n\n\nmetric\ntrain\ntest\ncomparison\n\n\n\n\nRMSE\n0.373\n0.386\nRMSE lower for training\n\n\nR-squared\n0.500\n0.556\nR-squared higher for training"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#evaluating-performance-on-training-data",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#evaluating-performance-on-training-data",
    "title": "Cross validation",
    "section": "Evaluating performance on training data",
    "text": "Evaluating performance on training data\n\nThe training set does not have the capacity to be a good arbiter of performance.\n\n\n\n\n- It is not an independent piece of information; predicting the training set can only reflect what the model already knows.\n\n\n\n\n- Suppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\n\n\n.footnote[ .small[ Source: tidymodels.org]]\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#cross-validation-1",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#cross-validation-1",
    "title": "Cross validation",
    "section": "Cross validation",
    "text": "Cross validation\nMore specifically, v-fold cross validation:\n\nShuffle your data v partitions\nUse 1 partition for validation, and the remaining v-1 partitions for training\nRepeat v times\n\n.footnote[ .small[ You might also heard of this referred to as k-fold cross validation.]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#cross-validation-2",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#cross-validation-2",
    "title": "Cross validation",
    "section": "Cross validation",
    "text": "Cross validation"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#split-data-into-folds",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#split-data-into-folds",
    "title": "Cross validation",
    "section": "Split data into folds",
    "text": "Split data into folds\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#fit-resamples",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#fit-resamples",
    "title": "Cross validation",
    "section": "Fit resamples",
    "text": "Fit resamples\n.pull-left[] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#collect-cv-metrics",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#collect-cv-metrics",
    "title": "Cross validation",
    "section": "Collect CV metrics",
    "text": "Collect CV metrics\n\ncollect_metrics(office_fit_rs)\n\n# A tibble: 2 x 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.403     5  0.0336 Preprocessor1_Model1\n2 rsq     standard   0.413     5  0.0727 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#deeper-look-into-cv-metrics",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#deeper-look-into-cv-metrics",
    "title": "Cross validation",
    "section": "Deeper look into CV metrics",
    "text": "Deeper look into CV metrics\n.panelset[ .panel[.panel-name[Raw]] .panel[.panel-name[Tidy]]]"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#how-does-rmse-compare-to-y",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#how-does-rmse-compare-to-y",
    "title": "Cross validation",
    "section": "How does RMSE compare to y?",
    "text": "How does RMSE compare to y?\n\nCross validation RMSE stats\n\n\n\n# A tibble: 1 x 6\n    min   max  mean   med     sd    IQR\n  <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1 0.289 0.475 0.403 0.430 0.0751 0.0841\n\n\n\nTraining data IMDB score stats\n\n\n\n# A tibble: 1 x 6\n    min   max  mean   med    sd   IQR\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1   6.7   9.7  8.24   8.2 0.530 0.600"
  },
  {
    "objectID": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#whats-next",
    "href": "slides/u4-d09-cross-validation/u4-d09-cross-validation.html#whats-next",
    "title": "Cross validation",
    "section": "What’s next?",
    "text": "What’s next?"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#data",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#data",
    "title": "Quantifying uncertainty",
    "section": "Data",
    "text": "Data\n\nFamily income and gift aid data from a random sample of fifty students in the freshman class of Elmhurst College in Illinois, USA\nGift aid is financial aid that does not need to be paid back, as opposed to a loan\n\n\n\n\n\n\n\n\n\n\n.footnote[ .small[ The data come from the openintro package: elmhurst.]]"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#linear-model",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#linear-model",
    "title": "Quantifying uncertainty",
    "section": "Linear model",
    "text": "Linear model\n.pull-left[ .small[]] .pull-right[]"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#interpreting-the-slope",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#interpreting-the-slope",
    "title": "Quantifying uncertainty",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n.pull-left-wide[] .pull-right-narrow[]\n–\nFor each additional $1,000 of family income, we would expect students to receive a net difference of 1,000 * (-0.0431) = -$43.10 in aid on average, i.e. $43.10 less in gift aid, on average.\n\nclass: middle\n.hand[ .light-blue[ exactly $43.10 for all students at this school?!]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#statistical-inference",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#statistical-inference",
    "title": "Quantifying uncertainty",
    "section": "Statistical inference",
    "text": "Statistical inference\n… is the process of using sample data to make conclusions about the underlying population the sample came from"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#estimation",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#estimation",
    "title": "Quantifying uncertainty",
    "section": "Estimation",
    "text": "Estimation\nSo far we have done lots of estimation (mean, median, slope, etc.), i.e. - used data from samples to calculate sample statistics - which can then be used as estimates for population parameters\n\n.question[ If you want to catch a fish, do you prefer a spear or a net?]\n\n.pull-left[] .pull-right[]\n\n.question[ If you want to estimate a population parameter, do you prefer to report a range of values the parameter might be in, or a single value?]\n\n–\n\nIf we report a point estimate, we probably won’t hit the exact population parameter\nIf we report a range of plausible values we have a good shot at capturing the parameter\n\n\n.center[ \n]\n.footnote[ .midi[ Source: Gallup. Britons’ Approval of U.S. Leadership at New Low, 5 Nov 2020.]]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#confidence-intervals-1",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#confidence-intervals-1",
    "title": "Quantifying uncertainty",
    "section": "Confidence intervals",
    "text": "Confidence intervals\nA plausible range of values for the population parameter is a confidence interval.\n\n\n\n\n\n\n- In order to construct a confidence interval we need to quantify the variability of our sample statistic\n\n\n\n\n- For example, if we want to construct a confidence interval for a population slope, we need to come up with a plausible range of values around our observed sample slope\n\n\n\n\nThis range will depend on how precise and how accurate our sample mean is as an estimate of the population mean\n\n\n\n\n\n\n\n- Quantifying this requires a measurement of how much we would expect the sample population to vary from sample to sample\n\n\n\n.question[ Suppose we split the class in half down the middle of the classroom and ask each student their heights. Then, we calculate the mean height of students on each side of the classroom. Would you expect these two means to be exactly equal, close but not equal, or wildly different?]\n–\n\n.question[ Suppose you randomly sample 50 students and 5 of them are left handed. If you were to take another random sample of 50 students, how many would you expect to be left handed? Would you be surprised if only 3 of them were left handed? Would you be surprised if 40 of them were left handed?]"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#quantifying-the-variability-of-slopes",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#quantifying-the-variability-of-slopes",
    "title": "Quantifying uncertainty",
    "section": "Quantifying the variability of slopes",
    "text": "Quantifying the variability of slopes\nWe can quantify the variability of sample statistics using\n\nsimulation: via bootstrapping (now)\n\nor\n\ntheory: via Central Limit Theorem (future stat courses!)\n\n\n\n# A tibble: 2 x 5\n  term          estimate std.error statistic  p.value\n  <chr>            <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrapping-1",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrapping-1",
    "title": "Quantifying uncertainty",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n.pull-left-wide[ - “pulling oneself up by one’s bootstraps”: accomplishing an impossible task without any outside help - Impossible task: estimating a population parameter using data from only the given sample - Note: Notion of saying something about a population parameter using only information from an observed sample is the crux of statistical inference] .pull-right-narrow[ .huge[ 🥾]]"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#observed-sample",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#observed-sample",
    "title": "Quantifying uncertainty",
    "section": "Observed sample",
    "text": "Observed sample"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-population",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-population",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap population",
    "text": "Bootstrap population\nGenerated assuming there are more students like the ones in the observed sample…"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrapping-scheme",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrapping-scheme",
    "title": "Quantifying uncertainty",
    "section": "Bootstrapping scheme",
    "text": "Bootstrapping scheme\n\nTake a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample\n\n\n\n\n\n\n\n2. Calculate the bootstrap statistic - a statistic such as mean, median, proportion, slope, etc. computed on the bootstrap samples\n\n\n\n\n3. Repeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics\n\n\n\n\nCalculate the bounds of the XX% confidence interval as the middle XX% of the bootstrap distribution"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-1",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-1",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1\n\nelmhurtst_boot_1 <- elmhurst %>%\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-2",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-2",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2\n\nelmhurtst_boot_2 <- elmhurst %>%\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-3",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-3",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3\n\nelmhurtst_boot_3 <- elmhurst %>%\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-4",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-sample-4",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4\n\nelmhurtst_boot_4 <- elmhurst %>%\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-samples-1---4",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#bootstrap-samples-1---4",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap samples 1 - 4",
    "text": "Bootstrap samples 1 - 4\n\n\n\n\n\n\n\n\n\n\nclass: middle\n.hand[ .light-blue[ we could keep going…]]"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#many-many-samples",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#many-many-samples",
    "title": "Quantifying uncertainty",
    "section": "Many many samples…",
    "text": "Many many samples…"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#slopes-of-bootstrap-samples",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#slopes-of-bootstrap-samples",
    "title": "Quantifying uncertainty",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#confidence-interval",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#confidence-interval",
    "title": "Quantifying uncertainty",
    "section": "95% confidence interval",
    "text": "95% confidence interval"
  },
  {
    "objectID": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#interpreting-the-slope-take-two",
    "href": "slides/u4-d10-quantify-uncertainty/u4-d10-quantify-uncertainty.html#interpreting-the-slope-take-two",
    "title": "Quantifying uncertainty",
    "section": "Interpreting the slope, take two",
    "text": "Interpreting the slope, take two\n\n\n# A tibble: 1 x 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1  -0.0695  -0.0232\n\n\nWe are 95% confident that for each additional $1,000 of family income, we would expect students to receive $69.5 to $23.24 less in gift aid, on average."
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html",
    "title": "Bootstrapping",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#rent-in-edinburgh-1",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#rent-in-edinburgh-1",
    "title": "Bootstrapping",
    "section": "Rent in Edinburgh",
    "text": "Rent in Edinburgh\n.question[ Take a guess! How much does a typical 3 BR flat in Edinburgh rents for?]"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#sample",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#sample",
    "title": "Bootstrapping",
    "section": "Sample",
    "text": "Sample\nFifteen 3 BR flats in Edinburgh were randomly selected on rightmove.co.uk.\n\nlibrary(tidyverse)\nedi_3br <- read_csv2(\"data/edi-3br.csv\") # ; separated\n\n.small[]"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#observed-sample",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#observed-sample",
    "title": "Bootstrapping",
    "section": "Observed sample",
    "text": "Observed sample"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#observed-sample-1",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#observed-sample-1",
    "title": "Bootstrapping",
    "section": "Observed sample",
    "text": "Observed sample\nSample mean ≈ £1895 😱"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#bootstrap-population",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#bootstrap-population",
    "title": "Bootstrapping",
    "section": "Bootstrap population",
    "text": "Bootstrap population\nGenerated assuming there are more flats like the ones in the observed sample… Population mean = ❓"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#bootstrapping-scheme",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#bootstrapping-scheme",
    "title": "Bootstrapping",
    "section": "Bootstrapping scheme",
    "text": "Bootstrapping scheme\n\nTake a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample\nCalculate the bootstrap statistic - a statistic such as mean, median, proportion, slope, etc. computed on the bootstrap samples\nRepeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics\nCalculate the bounds of the XX% confidence interval as the middle XX% of the bootstrap distribution\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means",
    "title": "Bootstrapping",
    "section": "Generate bootstrap means",
    "text": "Generate bootstrap means\n\nedi_3br %>%\n  # specify the variable of interest\n  specify(response = rent)"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means-1",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means-1",
    "title": "Bootstrapping",
    "section": "Generate bootstrap means",
    "text": "Generate bootstrap means\n\nedi_3br %>%\n  # specify the variable of interest\n  specify(response = rent)\n  # generate 15000 bootstrap samples\n  generate(reps = 15000, type = \"bootstrap\")"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means-2",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means-2",
    "title": "Bootstrapping",
    "section": "Generate bootstrap means",
    "text": "Generate bootstrap means\n\nedi_3br %>%\n  # specify the variable of interest\n  specify(response = rent)\n  # generate 15000 bootstrap samples\n  generate(reps = 15000, type = \"bootstrap\")\n  # calculate the mean of each bootstrap sample\n  calculate(stat = \"mean\")"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means-3",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#generate-bootstrap-means-3",
    "title": "Bootstrapping",
    "section": "Generate bootstrap means",
    "text": "Generate bootstrap means\n\n# save resulting bootstrap distribution\nboot_df <- edi_3br %>%\n  # specify the variable of interest\n  specify(response = rent) %>% \n  # generate 15000 bootstrap samples\n  generate(reps = 15000, type = \"bootstrap\") %>% \n  # calculate the mean of each bootstrap sample\n  calculate(stat = \"mean\")"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#the-bootstrap-sample",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#the-bootstrap-sample",
    "title": "Bootstrapping",
    "section": "The bootstrap sample",
    "text": "The bootstrap sample\n.question[ How many observations are there in boot_df? What does each observation represent?]\n\nboot_df\n\nResponse: rent (numeric)\n# A tibble: 15,000 x 2\n  replicate  stat\n      <int> <dbl>\n1         1 1793.\n2         2 1938.\n3         3 2175 \n4         4 2159.\n5         5 2084 \n6         6 1761 \n# ... with 14,994 more rows"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#visualize-the-bootstrap-distribution",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#visualize-the-bootstrap-distribution",
    "title": "Bootstrapping",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nggplot(data = boot_df, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 100) +\n  labs(title = \"Bootstrap distribution of means\")"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#calculate-the-confidence-interval",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#calculate-the-confidence-interval",
    "title": "Bootstrapping",
    "section": "Calculate the confidence interval",
    "text": "Calculate the confidence interval\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution.\n\nboot_df %>%\n  summarize(lower = quantile(stat, 0.025),\n            upper = quantile(stat, 0.975))\n\n# A tibble: 1 x 2\n  lower upper\n  <dbl> <dbl>\n1 1603. 2213."
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#visualize-the-confidence-interval",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#visualize-the-confidence-interval",
    "title": "Bootstrapping",
    "section": "Visualize the confidence interval",
    "text": "Visualize the confidence interval"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#interpret-the-confidence-interval",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#interpret-the-confidence-interval",
    "title": "Bootstrapping",
    "section": "Interpret the confidence interval",
    "text": "Interpret the confidence interval\n.question[ The 95% confidence interval for the mean rent of three bedroom flats in Edinburgh was calculated as (1603, 2213). Which of the following is the correct interpretation of this interval?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#confidence-level",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#confidence-level",
    "title": "Bootstrapping",
    "section": "Confidence level",
    "text": "Confidence level\nWe are 95% confident that …\n\nSuppose we took many samples from the original population and built a 95% confidence interval based on each sample.\nThen about 95% of those intervals would contain the true population parameter."
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#commonly-used-confidence-levels",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#commonly-used-confidence-levels",
    "title": "Bootstrapping",
    "section": "Commonly used confidence levels",
    "text": "Commonly used confidence levels\n.question[ Which line (orange dash/dot, blue dash, green dot) represents which confidence level?]"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#precision-vs.-accuracy",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#precision-vs.-accuracy",
    "title": "Bootstrapping",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n.question[ If we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?]\n–\n\n\n\n\n\n\n\n\n\n–\n.question[ How can we get best of both worlds – high precision and high accuracy?]"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#changing-confidence-level",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#changing-confidence-level",
    "title": "Bootstrapping",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n.question[ How would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?]\n\nedi_3br %>%\n  specify(response = rent) %>% \n  generate(reps = 15000, type = \"bootstrap\") %>% \n  calculate(stat = \"mean\") %>%\n  summarize(lower = quantile(stat, 0.025),\n            upper = quantile(stat, 0.975))"
  },
  {
    "objectID": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#recap",
    "href": "slides/u4-d11-bootstrap/u4-d11-bootstrap.html#recap",
    "title": "Bootstrapping",
    "section": "Recap",
    "text": "Recap\n\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability\nWe can do this for any sample statistic:\n\nFor a mean: calculate(stat = \"mean\")\nFor a median: calculate(stat = \"median\")\nLearn about calculating bootstrap intervals for other statistics in your homework"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html",
    "title": "Hypothesis testing",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#packages",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#packages",
    "title": "Hypothesis testing",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#organ-donors",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#organ-donors",
    "title": "Hypothesis testing",
    "section": "Organ donors",
    "text": "Organ donors\nPeople providing an organ for donation sometimes seek the help of a special “medical consultant”. These consultants assist the patient in all aspects of the surgery, with the goal of reducing the possibility of complications during the medical procedure and recovery. Patients might choose a consultant based in part on the historical complication rate of the consultant’s clients.\nOne consultant tried to attract patients by noting that the average complication rate for liver donor surgeries in the US is about 10%, but her clients have only had 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!)."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#data",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#data",
    "title": "Hypothesis testing",
    "section": "Data",
    "text": "Data\n\n\n\n\norgan_donor %>%\n  count(outcome)\n\n# A tibble: 2 x 2\n  outcome             n\n  <chr>           <int>\n1 complication        3\n2 no complication    59"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#parameter-vs.-statistic",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#parameter-vs.-statistic",
    "title": "Hypothesis testing",
    "section": "Parameter vs. statistic",
    "text": "Parameter vs. statistic\nA parameter for a hypothesis test is the “true” value of interest. We typically estimate the parameter using a sample statistic as a point estimate.\n\\(p~\\): true rate of complication\n\\(\\hat{p}~\\): rate of complication in the sample = \\(\\frac{3}{62}\\) = 0.048"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#correlation-vs.-causation",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#correlation-vs.-causation",
    "title": "Hypothesis testing",
    "section": "Correlation vs. causation",
    "text": "Correlation vs. causation\n.question[ Is it possible to assess the consultant’s claim using the data?]\n–\nNo. The claim is that there is a causal connection, but the data are observational. For example, maybe patients who can afford a medical consultant can afford better medical care, which can also lead to a lower complication rate.\nWhile it is not possible to assess the causal claim, it is still possible to test for an association using these data. For this question we ask, could the low complication rate of \\(\\hat{p}\\) = 0.048 be due to chance?"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#two-claims",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#two-claims",
    "title": "Hypothesis testing",
    "section": "Two claims",
    "text": "Two claims\n\nNull hypothesis: “There is nothing going on”\n\nComplication rate for this consultant is no different than the US average of 10%\n–\n\nAlternative hypothesis: “There is something going on”\n\nComplication rate for this consultant is lower than the US average of 10%"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#hypothesis-testing-as-a-court-trial",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\n–\n\nPresent the evidence: Collect data\n\n–\n\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#hypothesis-testing-framework",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#hypothesis-testing-framework",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#setting-the-hypotheses",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#setting-the-hypotheses",
    "title": "Hypothesis testing",
    "section": "Setting the hypotheses",
    "text": "Setting the hypotheses\n.question[ Which of the following is the correct set of hypotheses?]\n\n\\(H_0: p = 0.10\\); \\(H_A: p \\ne 0.10\\) \n\\(H_0: p = 0.10\\); \\(H_A: p > 0.10\\) \n\\(H_0: p = 0.10\\); \\(H_A: p < 0.10\\) \n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} \\ne 0.10\\) \n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} > 0.10\\) \n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} < 0.10\\)"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulating-the-null-distribution",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulating-the-null-distribution",
    "title": "Hypothesis testing",
    "section": "Simulating the null distribution",
    "text": "Simulating the null distribution\nSince \\(H_0: p = 0.10\\), we need to simulate a null distribution where the probability of success (complication) for each trial (patient) is 0.10.\n.question[ Describe how you would simulate the null distribution for this study using a bag of chips. How many chips? What colors? What do the colors indicate? How many draws? With replacement or without replacement?]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#what-do-we-expect",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#what-do-we-expect",
    "title": "Hypothesis testing",
    "section": "What do we expect?",
    "text": "What do we expect?\n.question[ When sampling from the null distribution, what is the expected proportion of success (complications)?]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-1",
    "title": "Hypothesis testing",
    "section": "Simulation #1",
    "text": "Simulation #1\n\n\nsim1\n   complication no complication \n              3              59 \n\n\n[1] 0.0483871"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-2",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-2",
    "title": "Hypothesis testing",
    "section": "Simulation #2",
    "text": "Simulation #2\n\n\nsim2\n   complication no complication \n              9              53 \n\n\n[1] 0.1451613"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-3",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-3",
    "title": "Hypothesis testing",
    "section": "Simulation #3",
    "text": "Simulation #3\n\n\nsim3\n   complication no complication \n              8              54 \n\n\n[1] 0.1290323"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#this-is-getting-boring",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#this-is-getting-boring",
    "title": "Hypothesis testing",
    "section": "This is getting boring…",
    "text": "This is getting boring…\nWe need a way to automate this process!"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#using-tidymodels-to-generate-the-null-distribution",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#using-tidymodels-to-generate-the-null-distribution",
    "title": "Hypothesis testing",
    "section": "Using tidymodels to generate the null distribution",
    "text": "Using tidymodels to generate the null distribution\n.small[]\n\n\nResponse: outcome (factor)\nNull Hypothesis: point\n# A tibble: 100 x 2\n  replicate  stat\n      <dbl> <dbl>\n1         1 0.161\n2         2 0.081\n3         3 0.161\n4         4 0.145\n5         5 0.097\n6         6 0.145\n# ... with 94 more rows"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#visualizing-the-null-distribution",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#visualizing-the-null-distribution",
    "title": "Hypothesis testing",
    "section": "Visualizing the null distribution",
    "text": "Visualizing the null distribution\n.question[ What would you expect the center of the null distribution to be?]\n–\n\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.01) +\n  labs(title = \"Null distribution\")"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-visually",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-visually",
    "title": "Hypothesis testing",
    "section": "Calculating the p-value, visually",
    "text": "Calculating the p-value, visually\n.question[ What is the p-value, i.e. in what % of the simulations was the simulated sample proportion at least as extreme as the observed sample proportion?]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-directly",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-directly",
    "title": "Hypothesis testing",
    "section": "Calculating the p-value, directly",
    "text": "Calculating the p-value, directly\n\nnull_dist %>%\n  filter(stat <= (3/62)) %>%\n  summarise(p_value = n()/nrow(null_dist))\n\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1    0.12"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#significance-level",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#significance-level",
    "title": "Hypothesis testing",
    "section": "Significance level",
    "text": "Significance level\nWe often use 5% as the cutoff for whether the p-value is low enough that the data are unlikely to have come from the null model. This cutoff value is called the significance level, \\(\\alpha\\).\n\nIf p-value < \\(\\alpha\\), reject \\(H_0\\) in favor of \\(H_A\\): The data provide convincing evidence for the alternative hypothesis.\nIf p-value > \\(\\alpha\\), fail to reject \\(H_0\\) in favor of \\(H_A\\): The data do not provide convincing evidence for the alternative hypothesis."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#conclusion",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#conclusion",
    "title": "Hypothesis testing",
    "section": "Conclusion",
    "text": "Conclusion\n.question[ What is the conclusion of the hypothesis test?]\n–\nSince the p-value is greater than the significance level, we fail to reject the null hypothesis. These data do not provide convincing evidence that this consultant incurs a lower complication rate than 10% (overall US complication rate)."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#lets-get-real",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#lets-get-real",
    "title": "Hypothesis testing",
    "section": "Let’s get real",
    "text": "Let’s get real\n\n100 simulations is not sufficient\nWe usually simulate around 15,000 times to get an accurate distribution, but we’ll do 1,000 here for efficiency."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#run-the-test",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#run-the-test",
    "title": "Hypothesis testing",
    "section": "Run the test",
    "text": "Run the test\n.small[]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#visualize-and-calculate",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#visualize-and-calculate",
    "title": "Hypothesis testing",
    "section": "Visualize and calculate",
    "text": "Visualize and calculate\n.small[]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#types-of-alternative-hypotheses",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#types-of-alternative-hypotheses",
    "title": "Hypothesis testing",
    "section": "Types of alternative hypotheses",
    "text": "Types of alternative hypotheses\n\nOne sided (one tailed) alternatives: The parameter is hypothesized to be less than or greater than the null value, < or >\n\n–\n\nTwo sided (two tailed) alternatives: The parameter is hypothesized to be not equal to the null value, \\(\\ne\\)\n\nCalculated as two times the tail area beyond the observed sample statistic\nMore objective, and hence more widely preferred\n\n\n–\n.question[ Average systolic blood pressure of people with Stage 1 Hypertension is 150 mm Hg. Suppose we want to use a hypothesis test to evaluate whether a new blood pressure medication has an effect on the average blood pressure of heart patients. What are the hypotheses?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#is-yawning-contagious",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#is-yawning-contagious",
    "title": "Hypothesis testing",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\n.question[ Do you think yawning is contagious?]\n.pull-left[ ] .pull-right[ ]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#is-yawning-contagious-1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#is-yawning-contagious-1",
    "title": "Hypothesis testing",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\nAn experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.\nhttps://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious-2"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#study-description",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#study-description",
    "title": "Hypothesis testing",
    "section": "Study description",
    "text": "Study description\nIn this study 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn’t see someone yawn (control).\nThe data are in the openintro package: yawn\n\nyawn %>%\n  count(group, result)\n\n# A tibble: 4 x 3\n  group result       n\n  <fct> <fct>    <int>\n1 ctrl  not yawn    12\n2 ctrl  yawn         4\n3 trmt  not yawn    24\n4 trmt  yawn        10"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#proportion-of-yawners",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#proportion-of-yawners",
    "title": "Hypothesis testing",
    "section": "Proportion of yawners",
    "text": "Proportion of yawners\n.small[]\n\nProportion of yawners in the treatment group: \\(\\frac{10}{34} = 0.2941\\)\nProportion of yawners in the control group: \\(\\frac{4}{16} = 0.25\\)\nDifference: \\(0.2941 - 0.25 = 0.0441\\)\nOur results match the ones calculated on the MythBusters episode."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#independence",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#independence",
    "title": "Hypothesis testing",
    "section": "Independence?",
    "text": "Independence?\n.question[ Based on the proportions we calculated, do you think yawning is really contagious, i.e. are seeing someone yawn and yawning dependent?]\n\n\n# A tibble: 4 x 4\n# Groups:   group [2]\n  group result       n p_hat\n  <fct> <fct>    <int> <dbl>\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#dependence-or-another-possible-explanation",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#dependence-or-another-possible-explanation",
    "title": "Hypothesis testing",
    "section": "Dependence, or another possible explanation?",
    "text": "Dependence, or another possible explanation?\n\nThe observed differences might suggest that yawning is contagious, i.e. seeing someone yawn and yawning are dependent.\nBut the differences are small enough that we might wonder if they might simple be due to chance.\nPerhaps if we were to repeat the experiment, we would see slightly different results.\nSo we will do just that - well, somewhat - and see what happens.\nInstead of actually conducting the experiment many times, we will simulate our results."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#two-competing-claims",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#two-competing-claims",
    "title": "Hypothesis testing",
    "section": "Two competing claims",
    "text": "Two competing claims\n\n“There is nothing going on.” Yawning and seeing someone yawn are independent, yawning is not contagious, observed difference in proportions is simply due to chance. \\(\\rightarrow\\) Null hypothesis\n“There is something going on.” Yawning and seeing someone yawn are dependent, yawning is contagious, observed difference in proportions is not due to chance. \\(\\rightarrow\\) Alternative hypothesis"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-setup",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-setup",
    "title": "Hypothesis testing",
    "section": "Simulation setup",
    "text": "Simulation setup\n\nA regular deck of cards is comprised of 52 cards: 4 aces, 4 of numbers 2-10, 4 jacks, 4 queens, and 4 kings.\nTake out two aces from the deck of cards and set them aside.\nThe remaining 50 playing cards to represent each participant in the study:\n\n14 face cards (including the 2 aces) represent the people who yawn.\n36 non-face cards represent the people who don’t yawn."
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#running-the-simulation",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#running-the-simulation",
    "title": "Hypothesis testing",
    "section": "Running the simulation",
    "text": "Running the simulation\n\nShuffle the 50 cards at least 7 times1 to ensure that the cards counted out are from a random process.\nCount out the top 16 cards and set them aside. These cards represent the people in the control group.\nOut of the remaining 34 cards (treatment group) count the (the number of people who yawned in the treatment group).\nCalculate the difference in proportions of yawners (treatment - control), and plot it on the board.\nMark the difference you find on the dot plot on the board.\n\n.footnote[ [1] http://www.dartmouth.edu/~chance/course/topics/winning_number.html]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-hand",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-hand",
    "title": "Hypothesis testing",
    "section": "Simulation by hand",
    "text": "Simulation by hand\n.question[ Do the simulation results suggest that yawning is contagious, i.e. does seeing someone yawn and yawning appear to be dependent?]\n\n\n\nyawn-sim-results"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation",
    "title": "Hypothesis testing",
    "section": "Simulation by computation",
    "text": "Simulation by computation\n\nnull_dist <- yawn %>%\n  specify(response = result, explanatory = group, \n          success = \"yawn\") %>%\n  hypothesize(null = \"independence\") %>%\n  generate(100, type = \"permute\") %>%\n  calculate(stat = \"diff in props\", \n            order = c(\"trmt\", \"ctrl\"))"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---1",
    "title": "Hypothesis testing",
    "section": "Simulation by computation - 1",
    "text": "Simulation by computation - 1\n.small[ - Start with the data frame - Specify the variables - Since the response variable is categorical, specify the level which should be considered as “success”]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---2",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---2",
    "title": "Hypothesis testing",
    "section": "Simulation by computation - 2",
    "text": "Simulation by computation - 2\n.small[ - Start with the data frame - Specify the variables - Since the response variable is categorical, specify the level which should be considered as “success” - State the null hypothesis (yawning and whether or not you see someone yawn are independent)]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---3",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---3",
    "title": "Hypothesis testing",
    "section": "Simulation by computation - 3",
    "text": "Simulation by computation - 3\n.small[ - Start with the data frame - Specify the variables - Since the response variable is categorical, specify the level which should be considered as “success” - State the null hypothesis (yawning and whether or not you see someone yawn are independent) - Generate simulated differences via permutation]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---4",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---4",
    "title": "Hypothesis testing",
    "section": "Simulation by computation - 4",
    "text": "Simulation by computation - 4\n.small[ - Start with the data frame - Specify the variables - Since the response variable is categorical, specify the level which should be considered as “success” - State the null hypothesis (yawning and whether or not you see someone yawn are independent) - Generate simulated differences via permutation - Calculate the sample statistic of interest (difference in propotions) - Since the explanatory variable is categorical, specify the order in which the subtraction should occur for the calculation of the sample statistic, \\((\\hat{p}_{treatment} - \\hat{p}_{control})\\).]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---0",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#simulation-by-computation---0",
    "title": "Hypothesis testing",
    "section": "Simulation by computation - 0",
    "text": "Simulation by computation - 0\n.small[ - Save the result - Start with the data frame - Specify the variables - Since the response variable is categorical, specify the level which should be considered as “success” - State the null hypothesis (yawning and whether or not you see someone yawn are independent) - Generate simulated differences via permutation - Calculate the sample statistic of interest (difference in propotions) - Since the explanatory variable is categorical, specify the order in which the subtraction should occur for the calculation of the sample statistic, \\((\\hat{p}_{treatment} - \\hat{p}_{control})\\).]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#visualizing-the-null-distribution-1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#visualizing-the-null-distribution-1",
    "title": "Hypothesis testing",
    "section": "Visualizing the null distribution",
    "text": "Visualizing the null distribution\n.question[ What would you expect the center of the null distribution to be?]\n–\n\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.05) +\n  labs(title = \"Null distribution\")"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-visually-1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-visually-1",
    "title": "Hypothesis testing",
    "section": "Calculating the p-value, visually",
    "text": "Calculating the p-value, visually\n.question[ What is the p-value, i.e. in what % of the simulations was the simulated difference in sample proportion at least as extreme as the observed difference in sample proportions?]"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-directly-1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#calculating-the-p-value-directly-1",
    "title": "Hypothesis testing",
    "section": "Calculating the p-value, directly",
    "text": "Calculating the p-value, directly\n\nnull_dist %>%\n  filter(stat >= 0.0441) %>%\n  summarise(p_value = n()/nrow(null_dist))\n\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1    0.53"
  },
  {
    "objectID": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#conclusion-1",
    "href": "slides/u4-d12-hypothesis-testing/u4-d12-hypothesis-testing.html#conclusion-1",
    "title": "Hypothesis testing",
    "section": "Conclusion",
    "text": "Conclusion\n.question[ What is the conclusion of the hypothesis test?]\n\n–\n.question[ Do you “buy” this conclusion?]"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html",
    "title": "Inference overview",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#what-do-you-want-to-do",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#what-do-you-want-to-do",
    "title": "Inference overview",
    "section": "What do you want to do?",
    "text": "What do you want to do?\n\nEstimation -> Confidence interval\nDecision -> Hypothesis test\nFirst step: Ask the following questions\n\nHow many variables?\nWhat types of variables?\nWhat is the research question?\n\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#confidence-intervals-1",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#confidence-intervals-1",
    "title": "Inference overview",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nBootstrap\nBounds: cutoff values for the middle XX% of the distribution\nInterpretation: We are XX% confident that the true population parameter is in the interval.\nDefinition of confidence level: XX% of random samples of size n are expected to produce confidence intervals that contain the true population parameter.\ninfer::generate(reps, type = \"bootstrap\")"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#confidence-intervals-exercises",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#confidence-intervals-exercises",
    "title": "Inference overview",
    "section": "Confidence intervals exercises",
    "text": "Confidence intervals exercises\n.question[ Describe the simulation process for estimating the parameter assigned to your team.]"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#accuracy-vs.-precision",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#accuracy-vs.-precision",
    "title": "Inference overview",
    "section": "Accuracy vs. precision",
    "text": "Accuracy vs. precision\n.question[ What happens to the width of the confidence interval as the confidence level increases? Why? Should we always prefer a confidence interval with a higher confidence level?]"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#sample-size-and-width-of-intervals",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#sample-size-and-width-of-intervals",
    "title": "Inference overview",
    "section": "Sample size and width of intervals",
    "text": "Sample size and width of intervals"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#sample-size-and-width-of-intervals-1",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#sample-size-and-width-of-intervals-1",
    "title": "Inference overview",
    "section": "Sample size and width of intervals",
    "text": "Sample size and width of intervals"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#sample-size-and-width-of-intervals-2",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#sample-size-and-width-of-intervals-2",
    "title": "Inference overview",
    "section": "Sample size and width of intervals",
    "text": "Sample size and width of intervals"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#equivalency-of-confidence-and-significance-levels",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#equivalency-of-confidence-and-significance-levels",
    "title": "Inference overview",
    "section": "Equivalency of confidence and significance levels",
    "text": "Equivalency of confidence and significance levels\n\nTwo sided alternative HT with \\(\\alpha\\) \\(\\rightarrow\\) \\(CL = 1 - \\alpha\\)\nOne sided alternative HT with \\(\\alpha\\) \\(\\rightarrow\\) \\(CL = 1 - (2 \\times \\alpha)\\)"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#interpretation-of-confidence-intervals",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#interpretation-of-confidence-intervals",
    "title": "Inference overview",
    "section": "Interpretation of confidence intervals",
    "text": "Interpretation of confidence intervals\n.question[ Which of the following is more informative: ]\n–\n.question[ What does your answer tell you about interpretation of confidence intervals for differences between two population parameters?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#hypothesis-testing",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#hypothesis-testing",
    "title": "Inference overview",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\n\nSet the hypotheses.\nCalculate the observed sample statistic.\nCalculate the p-value.\nMake a conclusion, about the hypotheses, in context of the data and the research question.\ninfer::hypothesize(null = \"point\") and infer::generate(reps, type = \"simulate\") or infer::generate(reps, type = \"bootstrap\")\ninfer::hypothesize(null = \"independence\") and infer::generate(reps, type = \"permute\")"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#hypothesis-testing-exercises",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#hypothesis-testing-exercises",
    "title": "Inference overview",
    "section": "Hypothesis testing exercises",
    "text": "Hypothesis testing exercises\n.question[ Describe the simulation process for tesing for the parameter assigned to your team.]"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#testing-errors",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#testing-errors",
    "title": "Inference overview",
    "section": "Testing errors",
    "text": "Testing errors\n\nType 1: Reject \\(H_0\\) when you shouldn’t have\n\nP(Type 1 error) = \\(\\alpha\\)\n\nType 2: Fail to reject \\(H_0\\) when you should have\n\nP(Type 2 error) is harder to calculate, but increases as \\(\\alpha\\) decreases\n\n\n–\n.question[ In a court of law]"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#probabilities-of-testing-errors",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#probabilities-of-testing-errors",
    "title": "Inference overview",
    "section": "Probabilities of testing errors",
    "text": "Probabilities of testing errors\n\nP(Type 1 error) = \\(\\alpha\\)\nP(Type 2 error) = 1 - Power\nPower = P(correctly rejecting the null hypothesis)\n\n–\n.question[ Fill in the blanks in terms of correctly/incorrectly rejecting/failing to reject the null hypothesis:]\n\nclass: middle"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#what-do-you-want-to-do-1",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#what-do-you-want-to-do-1",
    "title": "Inference overview",
    "section": "What do you want to do?",
    "text": "What do you want to do?\n\nEstimation -> Confidence interval\nDecision -> Hypothesis test\nFirst step: Ask the following questions\n\nHow many variables?\nWhat type(s) of variable(s)?\nWhat is the research question?"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#data-nc-births",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#data-nc-births",
    "title": "Inference overview",
    "section": "Data: NC births",
    "text": "Data: NC births\nThe dataset is in the openintro package.\n\nglimpse(ncbirths)\n\nRows: 1,000\nColumns: 13\n$ fage           <int> NA, NA, 19, 21, NA, NA, 18, 17, NA, 20, ~\n$ mage           <int> 13, 14, 15, 15, 15, 15, 15, 15, 16, 16, ~\n$ mature         <fct> younger mom, younger mom, younger mom, y~\n$ weeks          <int> 39, 42, 37, 41, 39, 38, 37, 35, 38, 37, ~\n$ premie         <fct> full term, full term, full term, full te~\n$ visits         <int> 10, 15, 11, 6, 9, 19, 12, 5, 9, 13, 9, 8~\n$ marital        <fct> not married, not married, not married, n~\n$ gained         <int> 38, 20, 38, 34, 27, 22, 76, 15, NA, 52, ~\n$ weight         <dbl> 7.63, 7.88, 6.63, 8.00, 6.38, 5.38, 8.44~\n$ lowbirthweight <fct> not low, not low, not low, not low, not ~\n$ gender         <fct> male, male, female, male, female, male, ~\n$ habit          <fct> nonsmoker, nonsmoker, nonsmoker, nonsmok~\n$ whitemom       <fct> not white, not white, white, white, not ~"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation",
    "title": "Inference overview",
    "section": "Length of gestation",
    "text": "Length of gestation\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 1 x 7\n    min  xbar   med     s    q1    q3   max\n  <int> <dbl> <dbl> <dbl> <dbl> <dbl> <int>\n1    20  38.3    39  2.93    37    40    45"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-1",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-1",
    "title": "Inference overview",
    "section": "Length of gestation",
    "text": "Length of gestation\n.question[ Assuming that this sample is representative of all births in NC, we are 95% confident that the average length of gestation for babies in NC is between —- and —- weeks.]\n–\n(1) How many variables?\n–\n1 variable: length of gestation, weeks\n–\n(2) What type(s) of variable(s)?\n–\nNumerical\n–\n(3) What is the research question?\n–\nEstimate the average length of gestation \\(\\rightarrow\\) confidence interval"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#simulation-for-ci-for-a-mean",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#simulation-for-ci-for-a-mean",
    "title": "Inference overview",
    "section": "Simulation for CI for a mean",
    "text": "Simulation for CI for a mean\nGoal: Use bootstrapping to estimate the sampling variability of the mean, i.e. the variability of means taken from the same population with the same sample size.\n–\n\nTake a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample.\nCalculate the mean of the bootstrap sample.\nRepeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap means.\nCalculate the bounds of the 95% confidence interval as the middle 95% of the bootstrap distribution."
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#set-a-seed-first",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#set-a-seed-first",
    "title": "Inference overview",
    "section": "Set a seed first",
    "text": "Set a seed first\nFrom the documentation of set.seed:\n\nset.seed uses a single integer argument to set as many seeds as are required. There is no guarantee that different values of seed will seed the RNG differently, although any exceptions would be extremely rare.\nInitially, there is no seed; a new one is created from the current time and the process ID when one is required. Hence different sessions will give different simulation results, by default.\n\n\nset.seed(20180326)"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#computation-for-ci-for-a-mean",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#computation-for-ci-for-a-mean",
    "title": "Inference overview",
    "section": "Computation for CI for a mean",
    "text": "Computation for CI for a mean\n\nboot_means <- ncbirths %>%\n  filter(!is.na(weeks)) %>% # remove NAs\n  specify(response = weeks) %>%\n  generate(reps = 1000, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\nggplot(data = boot_means, aes(x = stat)) +\n  geom_histogram(binwidth = 0.03)"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-2",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-2",
    "title": "Inference overview",
    "section": "Length of gestation",
    "text": "Length of gestation\n\nboot_means %>%\n  summarise(\n    lower = quantile(stat, 0.025),\n    upper = quantile(stat, 0.975)\n  )\n\n# A tibble: 1 x 2\n  lower upper\n  <dbl> <dbl>\n1  38.2  38.5\n\n\n–\nAssuming that this sample is representative of all births in NC, we are 95% confident that the average length of gestation for babies in NC is between 38.1 and 38.5 weeks."
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-revisited",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-revisited",
    "title": "Inference overview",
    "section": "Length of gestation, revisited",
    "text": "Length of gestation, revisited\n.question[ The average length of human gestation is 280 days, or 40 weeks, from the first day of the woman’s last menstrual period. Do these data provide convincing evidence that average length of gestation for women in NC is different than 40 weeks? Use a significance level of 5%.]\n–\n\\(H_0: \\mu = 40\\)\n\\(H_A: \\mu \\ne 40\\)\n–\n\nWe just said, “we are 95% confident that the average length of gestation for babies in NC is between 38.1 and 38.5 weeks”.\nSince the null value is outside the CI, we would reject the null hypothesis in favor of the alternative.\nBut an alternative, more direct, way of answering this question is using a hypothesis test."
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#simulation-for-ht-for-a-mean",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#simulation-for-ht-for-a-mean",
    "title": "Inference overview",
    "section": "Simulation for HT for a mean",
    "text": "Simulation for HT for a mean\nGoal: Use bootstrapping to generate a sampling distribution under the assumption of the null hypothesis being true. Then, calculate the p-value to make a decision on the hypotheses.\n–\n\nTake a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample.\nCalculate the mean of the bootstrap sample.\nRepeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap means.\nShift the bootstrap distribution to be centered at the null value by subtracting/adding the difference between the center of the bootstrap distribution and the null value to each bootstrap mean.\nCalculate the p-value as the proportion of simulations that yield a sample mean at least as extreme as the observed sample mean."
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#computation-for-ht-for-a-mean",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#computation-for-ht-for-a-mean",
    "title": "Inference overview",
    "section": "Computation for HT for a mean",
    "text": "Computation for HT for a mean\n\nboot_means_shifted <- ncbirths %>%\n  filter(!is.na(weeks)) %>% # remove NAs\n  specify(response = weeks) %>%\n  hypothesize(null = \"point\", mu = 40) %>% # hypothesize step\n  generate(reps = 1000, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\nggplot(data = boot_means_shifted, aes(x = stat)) +\n  geom_histogram(binwidth = 0.03) +\n  geom_vline(xintercept = 38.33, color = \"red\") +\n  geom_vline(xintercept = 40 + (40 - 38.33), color = \"red\")"
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-3",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#length-of-gestation-3",
    "title": "Inference overview",
    "section": "Length of gestation",
    "text": "Length of gestation\n\nboot_means_shifted %>%\n  filter(stat <= 38.33) %>%\n  summarise(p_value = 2 * (n() / 1000))\n\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1       0\n\n\n–\nSince p-value less than the significance level, we reject the null hypothesis. The data provide convincing evidence that the average length of gestation of births in NC is different than 40."
  },
  {
    "objectID": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#infer-structure",
    "href": "slides/u4-d13-inference-overview/u4-d13-inference-overview.html#infer-structure",
    "title": "Inference overview",
    "section": "infer structure",
    "text": "infer structure\n\ndf %>%\n  specify(response, explanatory) %>% # explanatory optional\n  generate(reps, type) %>% # type: bootstrap, simulate, or permute\n  calculate(stat)\n\n\nAlways start with data frame\nResult is always a data frame with a variable called stat\n\nSee the documentation for calculate to see which statistics can be calculated\n\nFor hypothesis testing add a hypothesize() step between specify() and generate()\n\nnull = \"point\", and then specify the null value\nnull = \"independence\""
  },
  {
    "objectID": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html",
    "href": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html",
    "title": "Text analysis",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#tidytext",
    "href": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#tidytext",
    "title": "Text analysis",
    "section": "Tidytext",
    "text": "Tidytext\n.pull-left[ - Using tidy data principles can make many text mining tasks easier, more effective, and consistent with tools already in wide use - Learn more at tidytextmining.com] .pull-right[]"
  },
  {
    "objectID": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#what-is-tidy-text",
    "href": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#what-is-tidy-text",
    "title": "Text analysis",
    "section": "What is tidy text?",
    "text": "What is tidy text?\n.pull-left-wide[ .small[]]"
  },
  {
    "objectID": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#what-is-tidy-text-1",
    "href": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#what-is-tidy-text-1",
    "title": "Text analysis",
    "section": "What is tidy text?",
    "text": "What is tidy text?\n\ntext_df <- tibble(line = 1:12, text = text)\n\ntext_df %>% print(n = 12)\n\n# A tibble: 12 x 2\n    line text                                   \n   <int> <chr>                                  \n 1     1 Oh! Get me away from here, I'm dying   \n 2     2 Play me a song to set me free          \n 3     3 Nobody writes them like they used to   \n 4     4 So it may as well be me                \n 5     5 Here on my own now after hours         \n 6     6 Here on my own now on a bus            \n 7     7 Think of it this way                   \n 8     8 You could either be successful or be us\n 9     9 With our winning smiles, and us        \n10    10 With our catchy tunes or worse         \n11    11 Now we're photogenic                   \n12    12 You know, we don't stand a chance"
  },
  {
    "objectID": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#what-is-tidy-text-2",
    "href": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#what-is-tidy-text-2",
    "title": "Text analysis",
    "section": "What is tidy text?",
    "text": "What is tidy text?\n\ntext_df %>%\n  unnest_tokens(word, text) %>%\n  print(n = 10)\n\n# A tibble: 80 x 2\n    line word \n   <int> <chr>\n 1     1 oh   \n 2     1 get  \n 3     1 me   \n 4     1 away \n 5     1 from \n 6     1 here \n 7     1 i'm  \n 8     1 dying\n 9     2 play \n10     2 me   \n# ... with 70 more rows"
  },
  {
    "objectID": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#case-study-fms-covid-19-speeches",
    "href": "slides/u5-d01-text-analysis/u5-d01-text-analysis.html#case-study-fms-covid-19-speeches",
    "title": "Text analysis",
    "section": "Case study: FM’s COVID-19 speeches",
    "text": "Case study: FM’s COVID-19 speeches\n\n.title-slide[ ### github.com/mine-cetinkaya-rundel/fm-speeches-covid19]"
  },
  {
    "objectID": "slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html",
    "href": "slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html",
    "title": "Comparing texts",
    "section": "",
    "text": "layout: true"
  },
  {
    "objectID": "slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html#what-is-a-document-about",
    "href": "slides/u5-d02-comparing-texts/u5-d02-comparing-texts.html#what-is-a-document-about",
    "title": "Comparing texts",
    "section": "What is a document about?",
    "text": "What is a document about?\n\nTerm frequency\nInverse document frequency\n\n\\[idf(\\text{term}) = \\ln{\\left(\\frac{n_{\\text{documents}}}{n_{\\text{documents containing term}}}\\right)}\\]\ntf-idf is about comparing documents within a collection"
  },
  {
    "objectID": "slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html",
    "href": "slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html",
    "title": "Interactive web apps",
    "section": "",
    "text": "layout: true"
  },
  {
    "objectID": "slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#shiny",
    "href": "slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#shiny",
    "title": "Interactive web apps",
    "section": "Shiny",
    "text": "Shiny\n.pull-left[ - Shiny is an R package that makes it easy to build interactive web apps straight from R - You can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards - You can also extend your Shiny apps with CSS themes, htmlwidgets, and JavaScript actions - Learn more at shiny.rstudio.com] .pull-right[]"
  },
  {
    "objectID": "slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#high-level-view",
    "href": "slides/u5-d03-interactive-web-app/u5-d03-interactive-web-app.html#high-level-view",
    "title": "Interactive web apps",
    "section": "High level view",
    "text": "High level view\n\nEvery Shiny app has a webpage that the user visits, and behind this webpage there is a computer that serves this webpage by running R\nWhen running your app locally, the computer serving your app is your computer\nWhen your app is deployed, the computer serving your app is a web server\n\n\n.center[ minecr.shinyapps.io/fm-speeches-covid19-simple]\n.center[ \n]"
  },
  {
    "objectID": "slides/u5-d04-machine-learning/u5-d04-machine-learning.html",
    "href": "slides/u5-d04-machine-learning/u5-d04-machine-learning.html",
    "title": "Machine learning",
    "section": "",
    "text": "layout: true"
  },
  {
    "objectID": "slides/u5-d04-machine-learning/u5-d04-machine-learning.html#machine-learning-models-for-text-data",
    "href": "slides/u5-d04-machine-learning/u5-d04-machine-learning.html#machine-learning-models-for-text-data",
    "title": "Machine learning",
    "section": "Machine learning models for text data",
    "text": "Machine learning models for text data"
  },
  {
    "objectID": "slides/u5-d04-machine-learning/u5-d04-machine-learning.html#overview",
    "href": "slides/u5-d04-machine-learning/u5-d04-machine-learning.html#overview",
    "title": "Machine learning",
    "section": "Overview",
    "text": "Overview\n\nFit a classification model\nCross validate\nSee if we can do better with hyperparameter tuning\nPredict!\nDiscuss shortcomings of our implementation"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html",
    "title": "Bayesian inference",
    "section": "",
    "text": "layout: true\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#free-spam",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#free-spam",
    "title": "Bayesian inference",
    "section": "Free spam",
    "text": "Free spam\n.question[ You have 100 emails in your inbox: 60 are spam, 40 are not. Of the 60 spam emails, 35 contain the word “free”. Of the rest, 3 contain the word “free”. If an email contains the word “free”, what is the probability that it is spam?]\n\n\n\n\n\n\n\n\n\n\\[P(spam~|~free) = \\frac{\\#~spam~\\&~free}{\\#~free} = \\frac{35}{35+3} = 0.92\\]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#bayes-theorem-1",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#bayes-theorem-1",
    "title": "Bayesian inference",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\n\\[P(A~|~B) = \\frac{P(A~and~B)}{P(B)}\\]\n–\n\nThen, \\(P(A~and~B) = P(A~|~B) \\times P(B)\\)\n\n–\n\nIf A and B are independent, then knowing B doesn’t tell us anything about A, i.e. \\(P(A~|~B) = P(A)\\). Then,\n\n\\[P(A~and~B) = P(A~|~B) \\times P(B)\\]\n\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#dice-game",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#dice-game",
    "title": "Bayesian inference",
    "section": "Dice game",
    "text": "Dice game\n.question[ What’s the chance of winning? What is the probability of getting an outcome greater than or equal to 4 when rolling a 6-sided die? What is the probability when rolling a 12-sided die?]\n\n–\n.question[ Pick the “good” die. You’re playing a game where you win if the die roll is greater than or equal to 4. If you could get your pick, which die would you prefer to play this game with, 6 or 12-sided?]\n\nclass: small"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#set-up",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#set-up",
    "title": "Bayesian inference",
    "section": "Set up",
    "text": "Set up\n\nI have two dice: one 6-sided, the other 12-sided.\n\n–\n\nWe’re going to play a game: I keep one die on the left side (die L) and one die on the right (die R), and you won’t know which is the 6-sided die and which is the 12-sided. When I say left, I mean YOUR left.\n\n–\n\nYou pick die (L or R), I roll it, and I tell you if you win or not, where winning is getting a number greater than or equal to 4. If you win, you get candy on Wednesday. If you lose, no candy for you.\n\n–\n\nWe’ll play this multiple times with different contestants.\n\n–\n\nI will not swap the sides the dice are on at any point.\n\n–\n\nWe’ll record which die each contestant picks and whether they won or lost.\n\n–\n\nThe ultimate goal is to come to a class consensus about whether the die on the left or the die on the right is the “good die”.\n\n–\n\nYou get to pick how long you want play, but remember, each time you get <4, you lose a piece of candy (so there is a cost associated with too many tries). If you make the wrong decision, you lose all the candy."
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#hypotheses-and-decisions",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#hypotheses-and-decisions",
    "title": "Bayesian inference",
    "section": "Hypotheses and decisions",
    "text": "Hypotheses and decisions\n\n\n\nDecision\nTruth: R good, L bad\nTruth: R bad, L good\n\n\n\n\nPick R\nYou get the candy!\nYou lose the candy :(\n\n\nPick L\nYou lose the candy :(\nYou get the candy!\n\n\n\n\n–\n\nAt each trial you risk losing pieces of candy if you lose (the die comes up \\(<\\) 4). Too many trials means you won’t have much candy left.\nAnd if you take too long you’ll be stuck here for a while.\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#initial-guess",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#initial-guess",
    "title": "Bayesian inference",
    "section": "Initial guess",
    "text": "Initial guess\n.question[ You have no idea if I have chosen the die on the left (L) to be the good die (12-sided) or bad die (6-sided). Then, before we collect any data, what are the probabilities associated with the following hypotheses?]\n\\(H_1\\): R good, L bad\n\\(H_2\\): R bad, L good"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#prior-propbabilities",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#prior-propbabilities",
    "title": "Bayesian inference",
    "section": "Prior propbabilities",
    "text": "Prior propbabilities\n\nThese are your prior probabilities for the two competing claims (hypotheses):\n\n\\(H_1\\): R good, L bad\n\\(H_2\\): R bad, L good\n\nThat is, these probabilities represent what you believe before seeing any data.\nYou could have conceivably made up these probabilities, but instead you have chosen to make an educated guess.\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#data-collection-and-making-a-decision",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#data-collection-and-making-a-decision",
    "title": "Bayesian inference",
    "section": "Data collection and making a decision",
    "text": "Data collection and making a decision\n\n\n\n\nChoice (L or R)\nResult (W or L)\n\n\n\n\nRoll 1\n\n\n\n\nRoll 2\n\n\n\n\nRoll 3\n\n\n\n\n…\n…\n…\n\n\n\n\n.question[ What is your decision? How did you make this decision?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#roll-1",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#roll-1",
    "title": "Bayesian inference",
    "section": "Roll 1",
    "text": "Roll 1\n.question[ What is the probability, based on the outcome of the first roll, that R is the good die (and L is the bad die)?]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#posterior-probability-1",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#posterior-probability-1",
    "title": "Bayesian inference",
    "section": "Posterior probability",
    "text": "Posterior probability\n\nThe probability we just calculated P(R is good | Win) is also called the posterior probability.\nPosterior probability is generally defined as P(hypothesis | data). It tells us the probability of a hypothesis we set forth, given the data we just observed. It depends on both the prior probability we set and the observed data.\nThis is different than p-values – the probability of observed or more extreme data given the null hypothesis being true, i.e. P(data | hypothesis)."
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#updating-the-prior",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#updating-the-prior",
    "title": "Bayesian inference",
    "section": "Updating the prior",
    "text": "Updating the prior\n\nIn the Bayesian approach, we evaluate claims iteratively as we collect more data.\nIn the next iteration (roll) we get to take advantage of what we learned from the data.\nIn other words, we update our prior with our posterior probability from the previous iteration."
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#roll-2",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#roll-2",
    "title": "Bayesian inference",
    "section": "Roll 2",
    "text": "Roll 2\n.question[ What is the probability, based on the outcome of the first two rolls, that R is the good die (and L is the bad die)?]\n\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#recap-bayesian-inference",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#recap-bayesian-inference",
    "title": "Bayesian inference",
    "section": "Recap: Bayesian inference",
    "text": "Recap: Bayesian inference\n\nTake advantage of prior information, like a previously published study or a physical model.\n\n–\n\nNaturally integrate data as you collect it, and update your priors.\n\n–\n\nAvoid the counter-intuitive Frequentist definition of a p-value as the P(observed or more extreme outcome | \\(H_0\\) is true). Instead base decisions on the posterior probability, P(hypothesis is true | observed data).\n\n–\n\nWatch out! A good prior helps, a bad prior hurts, but the prior matters less the more data you have.\n\n–\n\nMore advanced Bayesian techniques offer flexibility not present in Frequentist models.\n\n\nclass: middle"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#breast-cancer-screening-1",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#breast-cancer-screening-1",
    "title": "Bayesian inference",
    "section": "Breast cancer screening",
    "text": "Breast cancer screening\n\nAmerican Cancer Society estimates that about 1.7% of women have breast cancer.\n\nhttp://www.cancer.org/cancer/cancerbasics/cancer-prevalence\n\nSusan G. Komen For The Cure Foundation states that mammography correctly identifies about 78% of women who truly have breast cancer.\n\nhttp://ww5.komen.org/BreastCancer/AccuracyofMammograms.html\n\nAn article published in 2003 suggests that up to 10% of all mammograms are false positive.\n\nhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC1360940\nNote: These percentages are approximate, and very difficult to estimate."
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#determining-the-prior",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#determining-the-prior",
    "title": "Bayesian inference",
    "section": "Determining the prior",
    "text": "Determining the prior\n.question[ Prior to any testing and any information exchange between the patient and the doctor, what probability should a doctor assign to a female patient having breast cancer?]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#calculating-the-posterior",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#calculating-the-posterior",
    "title": "Bayesian inference",
    "section": "Calculating the posterior",
    "text": "Calculating the posterior\n.question[ When a patient goes through breast cancer screening there are two competing claims: patient had cancer and patient doesn’t have cancer. If a mammogram yields a positive result, what is the probability that patient has cancer, i.e. what is the posterior probability of having cancer if mammogram yield a positive result?]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#updating-the-prior-when-retesting",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#updating-the-prior-when-retesting",
    "title": "Bayesian inference",
    "section": "Updating the prior when retesting",
    "text": "Updating the prior when retesting\n.question[ Suppose this patient who got a positive result in the first test wants to get tested again. What should the new prior probability that this patient has cancer? Is this probability smaller, larger, or equal to the prior probability in the first test? Why?]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#thinking-ahead",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#thinking-ahead",
    "title": "Bayesian inference",
    "section": "Thinking ahead",
    "text": "Thinking ahead\n.question[ If this patient tests positive in the second test as well, will the posterior probability of her having cancer be higher or lower (or equal to) the earlier posterior probability we calculated?]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#re-calculating-the-posterior-when-retesting",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#re-calculating-the-posterior-when-retesting",
    "title": "Bayesian inference",
    "section": "Re-calculating the posterior when retesting",
    "text": "Re-calculating the posterior when retesting\n.question[ What is the posterior probability of having cancer if this second mammogram also yielded a positive result?]"
  },
  {
    "objectID": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#role-of-computation",
    "href": "slides/u5-d07-bayes-inf/u5-d07-bayes-inf.html#role-of-computation",
    "title": "Bayesian inference",
    "section": "Role of computation",
    "text": "Role of computation\n.question[ We have done a bunch of hand calculations so far. How can we use computation in this paradigm?]"
  },
  {
    "objectID": "starters/hw/hw-01-pet-names/hw-01.html",
    "href": "starters/hw/hw-01-pet-names/hw-01.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "href": "starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "title": "HW 01 - Pet names",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nThere are ___ pets in the dataset.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\nseattlepets %>%\n  count(animal_name, sort = TRUE)\n\n# A tibble: 13,930 x 2\n   animal_name     n\n   <chr>       <int>\n 1 <NA>          483\n 2 Lucy          439\n 3 Charlie       387\n 4 Luna          355\n 5 Bella         331\n 6 Max           270\n 7 Daisy         261\n 8 Molly         240\n 9 Jack          232\n10 Lily          232\n# ... with 13,920 more rows\n\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here."
  },
  {
    "objectID": "starters/hw/hw-02-airbnb-edi/hw-02.html",
    "href": "starters/hw/hw-02-airbnb-edi/hw-02.html",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "href": "starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# remove this comment and add the code for Exercise 5 here"
  },
  {
    "objectID": "starters/hw/hw-03-bike-crash/hw-03.html",
    "href": "starters/hw/hw-03-bike-crash/hw-03.html",
    "title": "HW 02 - Road traffic accidents",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "starters/hw/hw-03-bike-crash/hw-03.html#exercises",
    "href": "starters/hw/hw-03-bike-crash/hw-03.html#exercises",
    "title": "HW 02 - Road traffic accidents",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here"
  },
  {
    "objectID": "starters/hw/hw-04-college-majors/hw-04.html",
    "href": "starters/hw/hw-04-college-majors/hw-04.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "href": "starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "title": "HW 04 - What should I major in?",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…"
  },
  {
    "objectID": "starters/hw/hw-05-legos/hw-05.html",
    "href": "starters/hw/hw-05-legos/hw-05.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "starters/hw/hw-05-legos/hw-05.html#exercises",
    "href": "starters/hw/hw-05-legos/hw-05.html#exercises",
    "title": "HW 05 - Legos",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…"
  },
  {
    "objectID": "starters/hw/hw-06-money-in-politics/hw-06.html",
    "href": "starters/hw/hw-06-money-in-politics/hw-06.html",
    "title": "HW 06 - Money in politics",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "href": "starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "title": "HW 06 - Money in politics",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…"
  },
  {
    "objectID": "starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "href": "starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "href": "starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…\n\n\nExercise 13\n…\n\n\nExercise 14\n…\n\n\nExercise 15\n…"
  },
  {
    "objectID": "starters/hw/hw-08-exploring-gss/hw-08.html",
    "href": "starters/hw/hw-08-exploring-gss/hw-08.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "href": "starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "title": "HW 08 - Exploring the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…"
  },
  {
    "objectID": "starters/hw/hw-09-modeling-gss/hw-09.html",
    "href": "starters/hw/hw-09-modeling-gss/hw-09.html",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "starters/hw/hw-09-modeling-gss/hw-09.html#exercises",
    "href": "starters/hw/hw-09-modeling-gss/hw-09.html#exercises",
    "title": "HW 09 - Modeling the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…\n\n\nExercise 13\n…\n\n\nExercise 14\n…\n\n\nExercise 15\n…"
  },
  {
    "objectID": "starters/hw/hw-10-wrap-up/hw-10.html",
    "href": "starters/hw/hw-10-wrap-up/hw-10.html",
    "title": "HW 10 - Wrap up",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "href": "starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "title": "HW 10 - Wrap up",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels."
  },
  {
    "objectID": "starters/lab/lab-01-hello-r/lab-01.html",
    "href": "starters/lab/lab-01-hello-r/lab-01.html",
    "title": "Lab 01 - Hello R",
    "section": "",
    "text": "library(tidyverse) \nlibrary(datasauRus)\nlibrary(usethis)"
  },
  {
    "objectID": "starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "href": "starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "title": "Lab 01 - Hello R",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nThe answers for this Exercise are given for you below. But you should clean up some of the narrative so that it only includes what you want to turn in.\nFirst let’s plot the data in the dino dataset:\n\ndino_data <- datasaurus_dozen %>%\n  filter(dataset == \"dino\")\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\nAnd next calculate the correlation between x and y in this dataset:\n\ndino_data %>%\n  summarize(r = cor(x, y))\n\n# A tibble: 1 x 1\n        r\n    <dbl>\n1 -0.0645\n\n\n\n\nExercise 3\nAdd code and narrative as needed. Note that the R chunks are labelled with plot-star and cor-star to provide spaces to place the code for plotting and calculating the correlation coefficient. To finish, clean up the narrative by removing these instructions.\nBlah blah blah…\n\n\n\nI’m some text, you should replace me with more meaningful text…\n\n\n\n\n\nExercise 4\nAdd code and narrative as needed. Note that two R chunks are given but they are not labeled. Use the convention from above to name them appropriately.\n\n\n\n\n\n\n\n\nExercise 5\nAdd code and narrative as needed. To add R chunks either type out the backticks, curly braces, and the letter r or use the Insert chunk button above, green C+."
  },
  {
    "objectID": "starters/lab/lab-02-plastic-waste/lab-02.html",
    "href": "starters/lab/lab-02-plastic-waste/lab-02.html",
    "title": "Lab 02 - Plastic waste",
    "section": "",
    "text": "library(tidyverse) \n\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")"
  },
  {
    "objectID": "starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "href": "starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "title": "Lab 02 - Plastic waste",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n# insert code here\n\n\n\nExercise 2\n\n# insert code here\n\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# insert code here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# insert code here\n\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here.\n\n# insert code here\n\n\n\nExercise 7\nRemove this text, and add your answer for Exercise 7 here.\n\n# insert code here\n\n\n# insert code here\n\n\n\nExercise 8\nRemove this text, and add your answer for Exercise 8 here.\n\n# insert code here"
  },
  {
    "objectID": "starters/lab/lab-03-nobel-laureates/lab-03.html",
    "href": "starters/lab/lab-03-nobel-laureates/lab-03.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "library(tidyverse) \n\n\nnobel <- read_csv(\"data/nobel.csv\")"
  },
  {
    "objectID": "starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "href": "starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "title": "Lab 03 - Nobel laureates",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…"
  },
  {
    "objectID": "starters/lab/lab-04-viz-sp-data/lab-04.html",
    "href": "starters/lab/lab-04-viz-sp-data/lab-04.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "href": "starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-06-sad-plots/lab-06.html",
    "href": "starters/lab/lab-06-sad-plots/lab-06.html",
    "title": "Lab 06 - Sad plots",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-07-simpsons-paradox/lab-07.html",
    "href": "starters/lab/lab-07-simpsons-paradox/lab-07.html",
    "title": "Lab 07 - Simpson’s paradox",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-08-uoe-art/lab-08.html",
    "href": "starters/lab/lab-08-uoe-art/lab-08.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "Exercise 9\n\nuoe_art <- uoe_art %>%\n  separate(title, into = c(\"title\", \"date\"), sep = \"\\\\(\") %>%\n  mutate(year = str_remove(date, \"\\\\)\") %>% as.numeric()) %>%\n  select(title, artist, year, ___)\n\nError: <text>:4:31: unexpected input\n3:   mutate(year = str_remove(date, \"\\\\)\") %>% as.numeric()) %>%\n4:   select(title, artist, year, _\n                                 ^\n\n\n\n\nExercise 10\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 11\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-09-better-viz/lab-09.html",
    "href": "starters/lab/lab-09-better-viz/lab-09.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-10-slr-course-evals/lab-10.html",
    "href": "starters/lab/lab-10-slr-course-evals/lab-10.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "href": "starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/lab/lab-12-inference-smoking/lab-12.html",
    "href": "starters/lab/lab-12-inference-smoking/lab-12.html",
    "title": "Lab 12 - Smoking during pregnancy",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "starters/project/presentation/presentation.html",
    "href": "starters/project/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "starters/project/presentation/presentation.html#plot-and-text",
    "href": "starters/project/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[]"
  },
  {
    "objectID": "starters/project/proposal/proposal.html",
    "href": "starters/project/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "starters/project/proposal/proposal.html#introduction",
    "href": "starters/project/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "starters/project/proposal/proposal.html#data",
    "href": "starters/project/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "starters/project/proposal/proposal.html#data-analysis-plan",
    "href": "starters/project/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "weeks_depr/week-1.html",
    "href": "weeks_depr/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Important\n\n\n\nClasses are virtual this week. Find Zoom links here."
  },
  {
    "objectID": "weeks_depr/week-1.html#prepare",
    "href": "weeks_depr/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks_depr/week-1.html#participate",
    "href": "weeks_depr/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Lab 0 -Meet+ greet\n🖥️ Lecture 1 - Welcome to STA 210"
  },
  {
    "objectID": "weeks_depr/week-1.html#practice",
    "href": "weeks_depr/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\n📋 AE 0 - Movies"
  },
  {
    "objectID": "weeks_depr/week-1.html#perform",
    "href": "weeks_depr/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n⌨️ Lab 0 - Meet + greet\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-10.html",
    "href": "weeks_depr/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Important\n\n\n\nDue date: Project proposal due Fri, Mar 18 at 5:00 pm."
  },
  {
    "objectID": "weeks_depr/week-10.html#prepare",
    "href": "weeks_depr/week-10.html#prepare",
    "title": "Week 10",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Introduction to Modern Statistics, Chp 9: Logistic regression"
  },
  {
    "objectID": "weeks_depr/week-10.html#participate",
    "href": "weeks_depr/week-10.html#participate",
    "title": "Week 10",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 18 - Logistic regression\n🖥️ Lecture 19 - Probabilities, odds, odds ratios"
  },
  {
    "objectID": "weeks_depr/week-10.html#practice",
    "href": "weeks_depr/week-10.html#practice",
    "title": "Week 10",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 9 - Odds"
  },
  {
    "objectID": "weeks_depr/week-10.html#perform",
    "href": "weeks_depr/week-10.html#perform",
    "title": "Week 10",
    "section": "Perform",
    "text": "Perform\n✍️ HW 3 - Logistic regression and log transformation\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-11.html",
    "href": "weeks_depr/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 5 - Friday, Mar 25\nHW 3 - Friday, Mar 25"
  },
  {
    "objectID": "weeks_depr/week-11.html#prepare",
    "href": "weeks_depr/week-11.html#prepare",
    "title": "Week 11",
    "section": "Prepare",
    "text": "Prepare\nNo additional readings this week. Catch up with previously assigned readings if you’ve fallen behind."
  },
  {
    "objectID": "weeks_depr/week-11.html#participate",
    "href": "weeks_depr/week-11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 20 - LR: Prediction / classification\n🖥️ Lecture 21 - LR: Model validation"
  },
  {
    "objectID": "weeks_depr/week-11.html#practice",
    "href": "weeks_depr/week-11.html#practice",
    "title": "Week 11",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 10 - Flight delays"
  },
  {
    "objectID": "weeks_depr/week-11.html#perform",
    "href": "weeks_depr/week-11.html#perform",
    "title": "Week 11",
    "section": "Perform",
    "text": "Perform\n✍️ HW 3 - Logistic regression and log transformation\n⌨️ Lab 5 - General Social Survey\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-12.html",
    "href": "weeks_depr/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Important\n\n\n\nDue dates: None."
  },
  {
    "objectID": "weeks_depr/week-12.html#prepare",
    "href": "weeks_depr/week-12.html#prepare",
    "title": "Week 12",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Introduction to Modern Statistics, Chp 26: Inference for logistic regression"
  },
  {
    "objectID": "weeks_depr/week-12.html#participate",
    "href": "weeks_depr/week-12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 22 - LR: Inference + conditions\n🖥️ Lecture 23 - Multinomial logistic regression (MultiLR)"
  },
  {
    "objectID": "weeks_depr/week-12.html#practice",
    "href": "weeks_depr/week-12.html#practice",
    "title": "Week 12",
    "section": "Practice",
    "text": "Practice\nNo application exercises this week."
  },
  {
    "objectID": "weeks_depr/week-12.html#perform",
    "href": "weeks_depr/week-12.html#perform",
    "title": "Week 12",
    "section": "Perform",
    "text": "Perform\n✍️ HW 4 - Multinomial logistic regression\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-13.html",
    "href": "weeks_depr/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 6 - Friday, April 8\nProject drafts - Sunday, April 10"
  },
  {
    "objectID": "weeks_depr/week-13.html#participate",
    "href": "weeks_depr/week-13.html#participate",
    "title": "Week 13",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 24 - MultiLR: Prediction + inferential models\n🖥️ Lecture 25 - MultiLR: Predictive models"
  },
  {
    "objectID": "weeks_depr/week-13.html#practice",
    "href": "weeks_depr/week-13.html#practice",
    "title": "Week 13",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 11 - Volcanoes"
  },
  {
    "objectID": "weeks_depr/week-13.html#perform",
    "href": "weeks_depr/week-13.html#perform",
    "title": "Week 13",
    "section": "Perform",
    "text": "Perform\n✍️ HW 4 - Multinomial logistic regression\n💻 Lab 6 - Why Many Americans Don’t Vote\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-14.html",
    "href": "weeks_depr/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Friday, April 15 - Project peer review of drafts"
  },
  {
    "objectID": "weeks_depr/week-14.html#participate",
    "href": "weeks_depr/week-14.html#participate",
    "title": "Week 14",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 26 - MultiLR: Predictive models (cont.)\n🖥️ Lecture 27 - Exam 3 Review"
  },
  {
    "objectID": "weeks_depr/week-14.html#practice",
    "href": "weeks_depr/week-14.html#practice",
    "title": "Week 14",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 12 - Exam 3 Review"
  },
  {
    "objectID": "weeks_depr/week-14.html#perform",
    "href": "weeks_depr/week-14.html#perform",
    "title": "Week 14",
    "section": "Perform",
    "text": "Perform\n✍️ Project - Peer review of drafts\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-15.html",
    "href": "weeks_depr/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Tue, Apr 19 - HW 5"
  },
  {
    "objectID": "weeks_depr/week-15.html#participate",
    "href": "weeks_depr/week-15.html#participate",
    "title": "Week 15",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 28 - Wrap up"
  },
  {
    "objectID": "weeks_depr/week-15.html#practice",
    "href": "weeks_depr/week-15.html#practice",
    "title": "Week 15",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 13 - A Tale of Two Creeks"
  },
  {
    "objectID": "weeks_depr/week-15.html#perform",
    "href": "weeks_depr/week-15.html#perform",
    "title": "Week 15",
    "section": "Perform",
    "text": "Perform\n✍️ HW 5 - Statistics experience\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-2.html",
    "href": "weeks_depr/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important\n\n\n\n\nClasses are virtual this week. Find Zoom links here.\nDue dates:\n\nLab 1: Fri, Jan 14, 5pm ET\nAE 1: Sun, Jan 16, 11:59pm ET"
  },
  {
    "objectID": "weeks_depr/week-2.html#prepare",
    "href": "weeks_depr/week-2.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Introduction to Modern Statistics, Chp 7: Linear regression with a single predictor"
  },
  {
    "objectID": "weeks_depr/week-2.html#participate",
    "href": "weeks_depr/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Lab 1 - Meet the toolkit\n🖥️ Lecture 2 - Simple linear regression\n🖥️ Lecture 3 - Model fitting in R with tidymodels"
  },
  {
    "objectID": "weeks_depr/week-2.html#practice",
    "href": "weeks_depr/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 1 - Bike rentals in DC (Post-class note: complete only Part 1 - Daily counts and temperature)"
  },
  {
    "objectID": "weeks_depr/week-2.html#perform",
    "href": "weeks_depr/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n⌨️ Lab 1 - Meet the toolkit\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-3.html",
    "href": "weeks_depr/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\n\nWe’re back to in person classes this week! See here for class locations. And don’t forget to wear your mask! 😷\nDue dates:\n\nAE 2: Fri, Jan 21, 11:59pm ET"
  },
  {
    "objectID": "weeks_depr/week-3.html#prepare",
    "href": "weeks_depr/week-3.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Introduction to Modern Statistics, Sec 24.1: Case study: Sandwich store\n📖 Read Introduction to Modern Statistics, Sec 24.2: Randomization test for the slope\n📖 Read Introduction to Modern Statistics, Sec 24.3: Bootstrap confidence interval for the slope"
  },
  {
    "objectID": "weeks_depr/week-3.html#participate",
    "href": "weeks_depr/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 4 - SLR: Prediction + model evaluation\n🖥️ Lecture 5 - SLR: Simulation-based inference"
  },
  {
    "objectID": "weeks_depr/week-3.html#practice",
    "href": "weeks_depr/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 2 - Bike rentals in DC"
  },
  {
    "objectID": "weeks_depr/week-3.html#perform",
    "href": "weeks_depr/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\nNone.\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-4.html",
    "href": "weeks_depr/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\n\nIf you can’t be in class for the lectures, you can watch the live stream or watch the recording later on Panopto.\nDue dates:\n\nHW 1: Fri, Jan 28, 5pm ET\nLab 1: Fri, Jan 28, 5pm ET"
  },
  {
    "objectID": "weeks_depr/week-4.html#prepare",
    "href": "weeks_depr/week-4.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Introduction to Modern Statistics, Sec 24.4: Mathematical model for testing the slope\n📖 Read Introduction to Modern Statistics, Sec 24.5: Mathematical model, interval for the slope\n📖 Read Introduction to Modern Statistics, Sec 24.6: Checking model conditions\n📖 Read Introduction to Modern Statistics, Sec 24.7: Chapter review"
  },
  {
    "objectID": "weeks_depr/week-4.html#participate",
    "href": "weeks_depr/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Lab 2 - College scorecard\n🖥️ Lecture 6 - SLR: Mathematical models for inference\n🖥️ Lecture 7 - SLR: Model diagnostics"
  },
  {
    "objectID": "weeks_depr/week-4.html#practice",
    "href": "weeks_depr/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 3 - Checking model conditions"
  },
  {
    "objectID": "weeks_depr/week-4.html#perform",
    "href": "weeks_depr/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n⌨️ Lab 2 - College scorecard\n✍️ HW 1 - In-person voting trends\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-5.html",
    "href": "weeks_depr/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Important\n\n\n\n\nDue date: Lab 2 - Fri, Feb 4, 5pm ET\nExam 1 released on Fri, Feb 4, due Mon, Feb 7 at 11:59pm"
  },
  {
    "objectID": "weeks_depr/week-5.html#prepare",
    "href": "weeks_depr/week-5.html#prepare",
    "title": "Week 5",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Introduction to Modern Statistics, Sec 8.1: Indicator and categorical predictors\n📖 Read Introduction to Modern Statistics, Sec 8.2: Many predictors in a model\n📖 Read Introduction to Modern Statistics, Sec 8.3: Adjusted R-squared"
  },
  {
    "objectID": "weeks_depr/week-5.html#participate",
    "href": "weeks_depr/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\n🖥️ Lab 3 - Coffee ratings\n🖥️ Lecture 8 - Multiple linear regression (MLR)\n🖥️ Lecture 9 - Exam 1 review"
  },
  {
    "objectID": "weeks_depr/week-5.html#practice",
    "href": "weeks_depr/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 4 - Exam 1 Review"
  },
  {
    "objectID": "weeks_depr/week-5.html#perform",
    "href": "weeks_depr/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n⌨️ Lab 3 - Coffee ratings\n✅ Exam 1\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-6.html",
    "href": "weeks_depr/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Exam 1 - Mon, Feb 7 at 11:59pm"
  },
  {
    "objectID": "weeks_depr/week-6.html#prepare",
    "href": "weeks_depr/week-6.html#prepare",
    "title": "Week 6",
    "section": "Prepare",
    "text": "Prepare\nNo reading (take a break after the exam! 😴)"
  },
  {
    "objectID": "weeks_depr/week-6.html#participate",
    "href": "weeks_depr/week-6.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 10 - MLR: Types of predictors\n🖥️ Lecture 11 - MLR: Model comparison"
  },
  {
    "objectID": "weeks_depr/week-6.html#practice",
    "href": "weeks_depr/week-6.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\nNo application exercises"
  },
  {
    "objectID": "weeks_depr/week-6.html#perform",
    "href": "weeks_depr/week-6.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\nNo lab\n✅ Exam 1\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-7.html",
    "href": "weeks_depr/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nHW 2 - Friday, Feb 18\nProject ideas - Friday, Feb 18"
  },
  {
    "objectID": "weeks_depr/week-7.html#prepare",
    "href": "weeks_depr/week-7.html#prepare",
    "title": "Week 7",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Tidy Modeling in R Chp 8: Feature engineering with recipes"
  },
  {
    "objectID": "weeks_depr/week-7.html#participate",
    "href": "weeks_depr/week-7.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 12 - MLR: Feature engineering\n🖥️ Lecture 13 - MLR: Feature engineering (cont.)"
  },
  {
    "objectID": "weeks_depr/week-7.html#practice",
    "href": "weeks_depr/week-7.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 5 - The Office"
  },
  {
    "objectID": "weeks_depr/week-7.html#perform",
    "href": "weeks_depr/week-7.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n✍️ HW 2 - Multiple linear regression\n📂 Project - Topic ideas\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-8.html",
    "href": "weeks_depr/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "Important\n\n\n\nDue date: Lab 4 - Friday, Feb 25"
  },
  {
    "objectID": "weeks_depr/week-8.html#prepare",
    "href": "weeks_depr/week-8.html#prepare",
    "title": "Week 8",
    "section": "Prepare",
    "text": "Prepare\n📖 Read Tidy Modeling in R Chp 10: Resampling for evaluating performance"
  },
  {
    "objectID": "weeks_depr/week-8.html#participate",
    "href": "weeks_depr/week-8.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 14 - MLR: Cross validation\n🖥️ Lecture 15 - Exam 2 review"
  },
  {
    "objectID": "weeks_depr/week-8.html#practice",
    "href": "weeks_depr/week-8.html#practice",
    "title": "Week 8",
    "section": "Practice",
    "text": "Practice\nApplication Exercise 6 - The office - CV\nApplication Exercise 7 - Exam 2 Review"
  },
  {
    "objectID": "weeks_depr/week-8.html#perform",
    "href": "weeks_depr/week-8.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n⌨️ Lab 4 - The Office, another look\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks_depr/week-9.html",
    "href": "weeks_depr/week-9.html",
    "title": "Week 9",
    "section": "",
    "text": "Important\n\n\n\nDue date: Exam 1 released on Fri, Feb 35, due Mon, Feb 28 at 11:59pm"
  },
  {
    "objectID": "weeks_depr/week-9.html#prepare",
    "href": "weeks_depr/week-9.html#prepare",
    "title": "Week 9",
    "section": "Prepare",
    "text": "Prepare\nNo readings this week."
  },
  {
    "objectID": "weeks_depr/week-9.html#participate",
    "href": "weeks_depr/week-9.html#participate",
    "title": "Week 9",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 16 - MLR: Inference\n🖥️ Lecture 17 - MLR: Inference conditions + multicollinearity"
  },
  {
    "objectID": "weeks_depr/week-9.html#practice",
    "href": "weeks_depr/week-9.html#practice",
    "title": "Week 9",
    "section": "Practice",
    "text": "Practice\n📋 Application Exercise 8 - Rail Trail"
  },
  {
    "objectID": "weeks_depr/week-9.html#perform",
    "href": "weeks_depr/week-9.html#perform",
    "title": "Week 9",
    "section": "Perform",
    "text": "Perform\n✅ Exam 2\n\n\nBack to course schedule ⏎"
  }
]