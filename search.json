[
  {
    "objectID": "course-faq_in_dev.html",
    "href": "course-faq_in_dev.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder)."
  },
  {
    "objectID": "course-faq_in_dev.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq_in_dev.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq_in_dev.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq_in_dev.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.1.2: https://cran.r-project.org/\nDownload and install a daily build of RStudio: https://dailies.rstudio.com/\nInstall Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Showcase your inner data scientist",
    "section": "",
    "text": "Pick a dataset, any dataset…\n…and do something with it. That is your final project in a nutshell. More details below."
  },
  {
    "objectID": "project-description.html#data",
    "href": "project-description.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nOn the useful links part of the website you will find a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them."
  },
  {
    "objectID": "project-description.html#deliverables-and-due-dates",
    "href": "project-description.html#deliverables-and-due-dates",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables and Due Dates",
    "text": "Deliverables and Due Dates\n\nProposal - due 9/30/2022 at meeting.\nUpdate - due 10/7/2022 at meeting.\nPaper - due 10/14/2022 at meeting.\nPresentation - due 10/18/2022 in class.\nExecutive summary - due 10/18/2022 11:59pm.\n\n\nInitial Meeting\nThis includes a research question and one paragraph describing your intended project. Place your writing in an RMarkdown document in your proposal folder in your project repository. Your group will also present the data you have found. Together, as a group, we will review your idea and discuss your ideas. Every group member must contribute to this conversation. This also gives me an opportunity to help you decide if the data you have chosen will work for your questions of interest. I will be cloning you a repository to work on your project with. You do not need to copy and paste from this document.\nThe grading scheme for the project proposal is as follows.\n\n\n\n\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n4 pts\n\n\nProposal\n4 pts\n\n\nTeamwork\n2 pt\n\n\n\n\n\nUpdate\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset. Place your writing in an RMarkdown document in your update folder in your project repository.\n\nSection 1 - Introduction: The introduction should introduce your general research question and your data (where it came from, how it was collected,what are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nThe outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery exploratory data analysis, including some summary statistics and visualizations, along with explanation on how they help you learn more about your data.\nThe method(s) that you believe will be useful in answering your question(s).\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows.\n\n\n\n\n\n\n\nTotal\n20 pts\n\n\n\n\nCleaned Data\n2 pts\n\n\nPreliminary Paper\n10 pts\n\n\nWorkflow, organization, code quality\n3 pts\n\n\nTeamwork\n5 pts\n\n\n\n\n\nPaper\nThis is should include a complete group presentation, paper, and documentation of your analysis.\n\n1. Title\nGive an informative title to your project.\nAssessment: Does the title give an accurate preview of what the paper is about? Is it informative, specific and precise?\n\n\n2. Abstract\nThe abstract provides a brief summary of the entire paper (background, methods, results and conclusions). The suggested length is no more than 150 words. This allows you approximately 1 sentence (and likely no more than two sentences) summarizing each of the following sections. Typically, abstracts are the last thing you write.\nAssessment: Are the main points of the paper described clearly and succinctly?\n\n\n3. Background and significance\nIn this section you are providing the background of the research area and arguing why it is interesting and significant. This section relies heavily on literature review (prior research done in this area and facts that argue why the research is important). This whole section should provide the necessary background leading up to a presentation (in the last few sentences of this section) of the research hypotheses that you will be testing in your study. Well-accepted facts and/or referenced statements should serve as the majority of content of this section. Typically, the background and significance section starts very broad and moves towards the specific area/hypotheses you are testing.\nAssessment: - Does the background and significance have a logical organization? Does it move from the general to the specific? - Has sufficient background been provided to understand the paper? How does this work relate to other work in the scientific literature? - Has a reasonable explanation been given for why the research was done? Why is the work important? Why is it relevant? - Does this section end with statements about the hypothesis/goals of the paper?\n\n\n4. Methods\n\nData collection. Explain how the data was collected/experiment was conducted. Additionally, you should provide information on the individuals who participated to assess representativeness. Non-response rates and other relevant data collection details should be mentioned here if they are an issue. However, you should not discuss the impact of these issues here—save that for the limitations section.\nVariable creation. Detail the variables in your analysis and how they are defined (if necessary). For example, if you created a combined (frequency times quantity) drinking variable you should describe how. If you are talking about gender no further explanation is really needed.\nAnalytic Methods. Explain the statistical procedures that will be used to analyze your data. E.g. Boxplots are used to illustrate differences in GPA across gender and class standing. Correlations are used to assess the impacts of gender and class standing on GPA.\n\nAssessment: Could the study be repeated based on the information given here? Is the material organized into logical categories (like the one’s above)?\n\n\n5. Results\nTypically, results sections start with descriptive statistics, e.g. what percent of the sample is male/female, what is the mean GPA overall, in the different groups, etc. Figures can be nice to illustrate these differences! However, information presented must be relevant in helping to answer the research question(s) of interest. Typically, inferential (i.e. hypothesis tests) statistics come next. Tables can often be helpful for results from multiple regression. Do not give computer output here! This should look like a peer-reviewed journal article results section. Tables and figures should be labeled, embedded in the text, and referenced appropriately. The results section typically makes for fairly dry reading. It does not explain the impact of findings, it merely highlights and reports statistical information.\nAssessment: - Is the content appropriate for a results section? Is there a clear description of the results? - Are the results/data analyzed well? Given the data in each figure/table is the interpretation accurate and logical? Is the analysis of the data thorough (anything ignored?) - Are the figures/tables appropriate for the data being discussed? Are the figure legends and titles clear and concise?\n\n\n6. Discussion/Conclusions\nRestate your objective and draw connections between your analyses and objective. In other words, how did (or didn’t) you answer/address your objective. Place these all in the larger scope of previous research on your topic (i.e. what you found from the literature review), that is, how do your findings help the field move forward? Talk about the limitations of your findings and possible areas for future research to better investigate your research question. End with a concluding sentence or two that summarizes your key findings and impact on the field.\nAssessment: - Does the author clearly state whether the results answer the question (support or disprove the hypothesis)? - Were specific data cited from the results to support each interpretation? Does the author clearly articulate the basis for supporting or rejecting each hypothesis? - Does the author adequately relate the results of the current work to previous research?\n\n\n7. References\nAssessment: Are the references appropriate and of adequate quality? Are the references citied properly (both in the text and at the end of the paper)?\nSome additional general criteria that will be used to evaluate: - Description of the data source - Accuracy of data analysis - Accuracy of conclusions and discussion - Overall clarity and presentation - Originality and significance of the study - Writing quality and organization of the paper\nCredit: The Undergraduate Statistics Project Competition\n\n\n\n\n\n\n\nTotal\n75 pts\n\n\n\n\nCleaned Data\n5 pts\n\n\nPaper\n20 pts\n\n\nWorkflow, organization, code quality\n10 pt\n\n\nTeamwork and Presentation\n5 pt\n\n\n\n\n\n\nPresentation or Poster\n3 minutes, per person, maximum, and each team member should say something substantial. You can either present live during class with either a poster, virtual poster, or presentation or pre-record and submit your video to be played during class.\n\nSlide Option\nPrepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (3 minutes, per person, total). Each team member should get a chance to speak during the presentation.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\n\n\nVirtual Poster\nSee website supplementary documents for a template.\n\n\nPoster (you need to get this printed)\nSee website supplementary documents for a template.\nWhichever form you choose, your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nPresentations will take place during the last day of class.\nDuring class you will watch presentations from other teams in class and provide feedback in the form of peer evaluations. See website supplementary documents. The presentation line-up will be in group number order (since that was random).\nThe professors grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n45 pts\n\n\n\n\nTime management: Did the team divide the time well among themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use impact visualizations and/or appropriate statistical procedures, and interpret the results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n8 pts\n\n\nAre the slides/poster well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n7 pts\n\n\n\n\n\n\nExecutive summary\nAlong with your visual presentation, your team should provide a brief summary of your project in the README of your repository.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.Place your writing in an RMarkdown document in your executive_summary folder in your project repository.\nThe executive summary and repo organization is worth 30 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nRepo organization\nThe following folders and files in your project repository:\n\nREADME.Rmd + README.md: Will contain your executive summary and links to your other content.\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n/update: Your first major update files\n/paper: Your paper\n/extra: Extra files you may use\n/presentation+ presentation.Rmd + presentation.html: Your presentation slides\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "project-description.html#tips",
    "href": "project-description.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou’re working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that’s fine Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (I will be reviewing commits from different team members).\nSet aside time to work together and apart.\nWhen you’re done, review the documents on GitHub to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion."
  },
  {
    "objectID": "project-description.html#marking",
    "href": "project-description.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\n\n\n\n\nTotal\n200 pts\n\n\n\n\nProposal\n10 pts\n\n\nUpdate\n20 pts\n\n\nPaper\n75 pts\n\n\nExecutive summary\n30 pts\n\n\nPresentation\n45 pts\n\n\nReproducibility and organization\n10 pts\n\n\nClassmates’ presentation evaluation\n10 pts\n\n\n\n\nCriteria/Rubric\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged, by their teammates, to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works. GitHub shows who submits changes and can also be used to see who participated. You will be asked to fill out a survey where you report a contribution percentage for each team member. If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations."
  },
  {
    "objectID": "course-instructor.html",
    "href": "course-instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Dr. Tyler George (he/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics at Central Michigan University. During his PhD he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Friday 3:05 pm - 4:05pm\nWest 311\n\n\nOther Times by Appointment\nWest\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor!"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nYou are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first few days of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of your professors office hours here."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\n\nQuantitative Reasoning Studio (QRS)\nThere are times you may need help outside of class or office hours. Or, maybe you need something explained in a different way. In those instances, I encourage you to visit the Quantitative Reasoning Studio in Cole Library room 322. The Quantitative Reasoning Studio (QRS) offers free tutoring to all students at Cornell College. There will be at least 1 peer tutor that has taken this course and will be able to help you, if you arrive at a time they are working. Feel free to email Jessica Johanningmeier at QRS@cornellcollege.edu to ask when the tutor for this class will be available. They often will have a schedule posted on the wall in the studio.\n\n\nQRS Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n3 p.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\n\n\n\nDungy Writing Studio\nFor help with your writing, visit the Dungy Writing Studio. You can make online appointments individual or groups to get help with items such as your group project. If you have any questions about the studio, email Dungy Writing Studio Director and Director of Fellowships and Scholarships, Laura Farmer, at lfarmer@cornellcollege.edu.\n\n\nWriting Studio Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n1 p.m. - 5 p.m."
  },
  {
    "objectID": "course-support.html#student-success-center",
    "href": "course-support.html#student-success-center",
    "title": "Course support",
    "section": "Student Success Center",
    "text": "Student Success Center\nThe Student Success Center is a resource for all students. Their staff serves as student success coaches for all students and welcome students to visit us to talk about academic concerns, study plans, finding their place at Cornell, or any questions you have and aren’t sure where to start! You can walk in to chat or contact a staff member directly to set up an appointment! See the website for more information."
  },
  {
    "objectID": "course-support.html#professor-email",
    "href": "course-support.html#professor-email",
    "title": "Course support",
    "section": "Professor Email",
    "text": "Professor Email\nIf you are not available during office hours times or have a questions later in the evening or other times outside of class, email your professor at tgeorge@cornellcollege.edu. If your question involves code - it is very likely you will need to meet with him to get help. Please reach out with any concerns you have during the course!"
  },
  {
    "objectID": "course-support.html#ebersole-health-and-wellbeing-center",
    "href": "course-support.html#ebersole-health-and-wellbeing-center",
    "title": "Course support",
    "section": "Ebersole Health and Wellbeing Center",
    "text": "Ebersole Health and Wellbeing Center\nThe mission of Cornell College Student Health Services complements the mission of the college by promoting the optimal well-being of students. We do this by:\n\nproviding and coordinating quality health care services\nadvocating for students in their pursuit of health and wellness\npreparing students to be their own health advocates and informed consumers of appropriate health care services\nproviding health education to promote the development of healthy lifestyles\n\nThe Student Health Center is located in the Ebersole Building, directly south of the Thomas Commons. Appointments are preferred. You can schedule an appointment online or by phone at 319-895-4292. Walk-ins will be accommodated as time permits. Appointments with the nurse are free."
  },
  {
    "objectID": "course-support.html#technology-support",
    "href": "course-support.html#technology-support",
    "title": "Course support",
    "section": "Technology Support",
    "text": "Technology Support\nIf you have issues with your computer during the block, IT may be able to help. Please submit a ticket."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSC 223: Introduction to Data Science",
    "section": "",
    "text": "Day\nDate\nTopic\nSlides\nAE\nLab\nHW\nExam\nProject\n\n\n\n\n1\nMon, Sep 26\nWelcome and Toolkit  Data Viz\n🖥️🖥️🖥️\n📋📋📋\n💻\n📖 Chp 2 R4ds  📖 Sec 1.1,1.2 IMS  📖 Chp 3 R4ds  Read CARVE  Start HW 01 ✍️\n\n\n\n\n2\nTue, Sep 27\nTidy Data  Data wrangling  Data Frame\n🖥️🖥️🖥️🖥️\n📋\n💻\nFinish HW 01✍️  📖 Chp 4 IMS  📖 Chp 5 IMS  📖 The Ethical Data Scientist\n\n\n\n\n3\nWed, Sep 28\n📋 Ethical DS Ethics Discussion.  Practice Tuesday content.  No afternoon class.\nNone\n\n💻\n📖Tidy data  📖 Chp 13 R4ds  📖 Chp 12 R4ds  📖 Gelman  📖ASA Guidelines✍️Complete HW 02\n\n\n\n\n4\nThu, Sep 29\nTidy data, wrangling, and data frames\n🖥️🖥️🖥️\n📋\n\n📖Chp 15 R4ds ✍️ Complete HW 03\n\n📂Project Group Meeting\n\n\n5\nFri, Sep 30\nData frames, Data type and clasess.\n🖥️🖥️🖥️🖥️\n📋\n\n📖 Chp 11 R4ds  ✍️ Work on HW 04\n\n📂 Proposal Meetings. Afternoon class.\n\n\n6\nMon, Oct 3\nImporting and recording data.  Ethics Discussion on Gelman and ASA\n🖥️🖥️\n📋 AE 06\n💻\n✍️Finish HW 04📖Read Article📖Chp 16.1-16.3 R4ds📖Chp 6 IMS\n\n\n\n\n7\nTue, Oct 4\nArticle Discussion.Effective Data Viz\n🖥️\n📋 AE 07\n💻\n📖 Chp 7 R4ds📖 Chp 2 IMS✍️ Start HW 05 Install Google Chrome and Selector Gadget (will need in class)\n\n\n\n\n8\nWed, Oct 5\nConfounding, Simpsons paradox, and doing data science.\n🖥️🖥️🖥️\n\n💻\n✍️ Finish HW 05\n\n\n\n\n9\nThu, Oct 6\nWeb scraping\n🖥️🖥️🖥️\n📋 AE 08\n💻\nStudy\n\n\n\n\n10\nFri, Oct 7\nExam and Project\n\n\n\n✍️Start HW 06 HW 05 Solution\n✅\n📂Project Update Meeting\n\n\n11\nMon, Oct 10\n\n\n\n\n\n\n\n\n\n12\nTues, Oct 11\n\n\n\n\n\n\n\n\n\n13\nWed, Oct 12\n\n\n\n\n\n\n\n\n\n14\nThu, Oct 13\n\n\n\n\n\n\n\n\n\n15\nFri, Oct 14\n\n\n\n\n\n\n📂\n\n\n16\nMon, Oct 17\n\n\n\n\n\n\n\n\n\n17\nTue, Oct 18\n\n\n\n\n\n\n📂\n\n\n18\nWed, Oct 19\nFinal Exam\n\n\n\n\n✅"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\n🔗 on Cornell College Cluster\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nGradebook\n🔗 on Moodle"
  },
  {
    "objectID": "course-links.html#other-useful-links",
    "href": "course-links.html#other-useful-links",
    "title": "Useful links",
    "section": "Other Useful Links",
    "text": "Other Useful Links\n\nRStudio Cheatsheets\nIntroduction to dplyr\nR Date Examples\nNY Times Cornell College Sign-up"
  },
  {
    "objectID": "course-links.html#data-links",
    "href": "course-links.html#data-links",
    "title": "Useful links",
    "section": "Data Links",
    "text": "Data Links\n\nTidyTuesday\nAmazon Registry of Open Data\nOpen data StackExchange\nMicrosoft R Application Window\nData.gov\nUS Census\nNew York City data\nGeorge Mason University Data Link List\nToward Data Science list of Data Sources\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland’s official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we’ll add here…"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "Your account will be pre-created before the class begins and will use your Cornell College username. The default password will be shared in class and you will need to change it."
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(palmerpenguins)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.1     ✔ rsample      1.1.0\n✔ dials        1.0.0     ✔ tune         1.0.0\n✔ infer        1.0.3     ✔ workflows    1.0.0\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.1     ✔ yardstick    1.1.0\n✔ recipes      1.0.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(knitr)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\nFormat model output as table:\n\ntidy(penguins_fit) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5780.831\n305.815\n-18.903\n0\n\n\nflipper_length_mm\n49.686\n1.518\n32.722\n0\n\n\n\n\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n# A tibble: 342 × 9\n   .rownames body_mass_g flippe…¹ .fitted  .resid    .hat .sigma .cooksd .std.…²\n   <chr>           <int>    <int>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>   <dbl>\n 1 1                3750      181   3212.  538.   0.00881   394. 8.34e-3  1.37  \n 2 2                3800      186   3461.  339.   0.00622   394. 2.33e-3  0.863 \n 3 3                3250      195   3908. -658.   0.00344   393. 4.83e-3 -1.67  \n 4 5                3450      193   3808. -358.   0.00385   394. 1.60e-3 -0.911 \n 5 6                3650      190   3659.   -9.43 0.00469   395. 1.35e-6 -0.0240\n 6 7                3625      181   3212.  413.   0.00881   394. 4.91e-3  1.05  \n 7 8                4675      195   3908.  767.   0.00344   393. 6.56e-3  1.95  \n 8 9                3475      193   3808. -333.   0.00385   394. 1.39e-3 -0.847 \n 9 10               4250      190   3659.  591.   0.00469   394. 5.31e-3  1.50  \n10 11               3300      186   3461. -161.   0.00622   395. 5.23e-4 -0.409 \n# … with 332 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#   ²​.std.resid\n\n\n\n\nStatistical inference"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "DSC 223: Introduction to Data Science",
    "section": "",
    "text": "At the end of this course I would like you to be to use software’s including RStudio and GitHub to respect, explore, understand, and utilize data in a way that is replicable. This course supports the Educational Priorities and Outcomes of Cornell College with emphasis on knowledge, inquiry, reasoning, and communication, ethical behavior, citizenship, and vocation. Your emphasis on knowledge is in the skills you will learn and apply in various interdisciplinary fields. You will inquire when investigating data – seeing patters or trends and exploring them to. Your reasoning skills are built and tested when making decisions based on the data and your own programmed visualizations and numerical summaries. Your group work in class and group project presentations will help you practice your communication of statistical analysis. When you make decisions about what data to work with, how to treat the data, and how to talk about your results in an ethical way you practice good ethical behavior. Some of our analysis’ will be with data from institutions such as governments or organizations that have an influence on the public – these types of analysis’ can inform public policies and are our way, as data scientists, to practice citizenship. Lastly, you will learn about the field of data science and the types of knowledge and training that would be required to support your vocation as a data scientist."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "DSC 223 - Fall 2022 - Block 2 ",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the FULL syllabus."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nData Science in a Box by Mine Çetinkaya-Rundel\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "Ethics Materials",
    "section": "",
    "text": "CARVE moral dilemmas from Ethics in Action A Case-Based Approach by Connolly, Cox-White, Keller, and Leever.\n\n\n\nThe Ethical Data Scientist by Cathy O’ Neil. Class discussion questions.\nHonesty and Transparency Are Not Enoughby Andrew Gelman and ASA’s 2022 Ethical Guidelines for Statistical Practice. Class discussion questions.\nMultiple article and repeated class discussion questions."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "",
    "text": "Given below are two data visualizations that violate many data visualization best practices. Improve these visualizations using R and the tips for effective visualizations that we introduced in class. You should produce one visualization per dataset. Your visualization should be accompanied by a brief paragraph describing the choices you made in your improvement, specifically discussing what you didn’t like in the original plots and why, and how you addressed them in the visualization you created.\nYour group will give a brief presentation describing one of your improved visualizations and the reasoning for the choices you made."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#warm-up",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#warm-up",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#packages",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#packages",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#data",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#data",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Data",
    "text": "Data\nThe datasets we’ll use are called instructors and fisheries from the dsbox package. Since the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?instructors and ?fisheries in the Console or using the Help menu in RStudio to search for instructors or fisheries. You can also find this information here and here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Instructional staff employment trends",
    "text": "Instructional staff employment trends\nThe American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.\n\n\n\n\n\nLet’s start by loading the data used to create this plot.\n\nstaff <- read_csv(\"data/instructional-staff.csv\")\n\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n\n\n# A tibble: 5 × 12\n  facult…¹ `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Full-Ti…   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8\n2 Full-Ti…   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6\n3 Full-Ti…   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1\n4 Part-Ti…   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1\n5 Graduat…   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4\n# … with 1 more variable: `2011` <dbl>, and abbreviated variable name\n#   ¹​faculty_type\n\n\nIn order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year. In other words, we will convert the data from wide format to long format.\nBut before we do so, a thought exercise: How many rows will the long-format data have? It will have a row for each combination of year and faculty type. If there are 5 faculty types and 11 years of data, how many rows will we have?\nWe do the wide to long conversion using a new function: pivot_longer(). The animation below show how this function works, as well as its counterpart pivot_wider().\n\n\n\n\n\nThe function has the following arguments:\n\npivot_longer(data, cols, names_to = \"name\")\n\n\nThe first argument is data as usual.\nThe second argument, cols, is where you specify which columns to pivot into longer format – in this case all columns except for the faculty_type\nThe third argument, names_to, is a string specifying the name of the column to create from the data stored in the column names of data – in this case year\n\n\nstaff_long <- staff %>%\n  pivot_longer(cols = -faculty_type, names_to = \"year\") %>%\n  mutate(year = as.numeric(year))\n\nLet’s take a look at what the new longer data frame looks like.\n\nstaff_long\n\n# A tibble: 55 × 3\n   faculty_type               year value\n   <chr>                     <dbl> <dbl>\n 1 Full-Time Tenured Faculty  1975  29  \n 2 Full-Time Tenured Faculty  1989  27.6\n 3 Full-Time Tenured Faculty  1993  25  \n 4 Full-Time Tenured Faculty  1995  24.8\n 5 Full-Time Tenured Faculty  1999  21.8\n 6 Full-Time Tenured Faculty  2001  20.3\n 7 Full-Time Tenured Faculty  2003  19.3\n 8 Full-Time Tenured Faculty  2005  17.8\n 9 Full-Time Tenured Faculty  2007  17.2\n10 Full-Time Tenured Faculty  2009  16.8\n# … with 45 more rows\n\n\nAnd now let’s plot is as a line plot. A possible approach for creating a line plot where we color the lines by faculty type is the following:\n\nstaff_long %>%\n  ggplot(aes(x = year, y = value, color = faculty_type)) +\n  geom_line()\n\n\n\n\nBut note that this results in a message as well as an unexpected plot. The message is saying that there is only one observation for each faculty type year combination. We can fix this using the group aesthetic following.\n\nstaff_long %>%\n  ggplot(aes(x = year, y = value, group = faculty_type, color = faculty_type)) +\n  geom_line()\n\n\n\n\n\nInclude the line plot you made above in your report and make sure the figure width is large enough to make it legible. Also fix the title, axis labels, and legend label.\nSuppose the objective of this plot was to show that the proportion of part-time faculty have gone up over time compared to other instructional staff types. What changes would you propose making to this plot to tell this story and why.\nImplement the changes you proposed in the previous exercise.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#fisheries",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#fisheries",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Fisheries",
    "text": "Fisheries\nFisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries. This Wikipedia page lists fishery production of countries for 2016. For each country tonnage from capture and aquaculture are listed. Note that countries whose total harvest was less than 100,000 tons are not included in the visualization.\nA researcher shared with you the following visualization they created based on these data. 😳\n\n\n\n\n\n\nCan you help them make improve it? First, brainstorm how you would improve it. Then create the improved visualization and write up the changes/decisions you made as bullet points. It’s ok if some of your improvements are aspirational, i.e. you don’t know how to implement it, but you think it’s a good idea.\n\nLoad the data.\n\nfisheries <- read_csv(\"data/fisheries.csv\")\n\n\nCreate a new data visualisation for these data that implements the improvements you proposed in the previous exercise (or many of them as you can).\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "",
    "text": "Have you ever taken a road trip in the US and thought to yourself “I wonder what La Quinta means”. Well, the late comedian Mitch Hedberg thinks it’s Spanish for next to Denny’s.\nIf you’re not familiar with these two establishments, Denny’s is a casual diner chain that is open 24 hours and La Quinta Inn and Suites is a hotel chain.\nThese two establishments tend to be clustered together, or at least this observation is a joke made famous by Mitch Hedberg. In this lab we explore the validity of this joke and along the way learn some more data wrangling and tips for visualizing spatial data.\nThe inspiration for this lab comes from a blog post by John Reiser on his new jersey geographer blog. You can read that analysis here. Reiser’s blog post focuses on scraping data from Denny’s and La Quinta Inn and Suites websites using Python. In this lab we focus on visualization and analysis of these data. However note that the data scraping was also done in R, and we we will discuss web scraping using R later in the course. But for now we focus on the data that has already been scraped and tidied for you."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#warm-up",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#warm-up",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#packages",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#packages",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#data",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#data",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Data",
    "text": "Data\nThe datasets we’ll use are called dennys and laquinta from the dsbox package. Note that these data were scraped from here and here, respectively.\nSince the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here.\nTo help with our analysis we will also use a dataset on US states, which is located in your repository’s data folder.\n\nstates <- read_csv(\"data/states.csv\")\n\nEach observation in this dataset represents a state, including DC. Along with the name of the state we have the two-letter abbreviation and we have the geographic area of the state (in square miles)."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "In this lab our goal is to reconstruct and improve a data visualization on COVID and mask wearing."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#warm-up",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#warm-up",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#packages",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#packages",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#data",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#data",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Data",
    "text": "Data\nIn this lab you’ll construct the dataset!"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html",
    "title": "Lab 01 - Hello R!",
    "section": "",
    "text": "R is the name of the programming language itself and RStudio is a convenient interface.\nThe main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\ngit is a version control system (like “Track Changes” features from Microsoft Word on steroids) and GitHub is the home for your Git-based projects on the internet (like DropBox but much, much better).\nAn additional goal is to introduce you to Git and GitHub, which is the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nAnd to make versioning simpler, this is a solo lab. Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel. In future labs you’ll learn about collaborating on GitHub and produce a single lab report for your team."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#warm-up",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#warm-up",
    "title": "Lab 01 - Hello R!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nYAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.\n\n\n\n\n\n\n\nCommitting changes\nGo to the Git pane in your RStudio (top right) and click on Commit. This will bring up a new menu.\n\n\n\n\n\nIf you have made changes to your Rmd file (which you just changed your name), you should see it list on of the left. Diff shows you the difference between the last committed state of the document and its current state that includes your changes. Look over the files in the box that say they have been change. If agree with these changes, you will need to check the box to the left of each changed file, and in this case, write “Update author name” in the Commit message box. Then click Commit. It is important that you always describe what changes were made since your last commit in that box. This is how people in your team know what you changed without having to review thousands of lines of code.\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the block progresses we will let you make these decisions. Committing does not save your progress to the web.\n\n\nPushing changes\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean whoever you are working with.\nIn order to push your changes to GitHub, click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password, then your PAT. This might feel cumbersome. Bear with me… We will teach you how to save your password so you don’t have to enter it every time. But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#packages",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#packages",
    "title": "Lab 01 - Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with two more packages: datasauRus which contains the dataset we’ll be using and tidyverse which is a collection of packages for doing data analysis in a “tidy” way. These packages are already installed for you. You can load the packages by running the following in the Console.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\nNote that the packages are also loaded with the same commands in your R Markdown document."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#data",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#data",
    "title": "Lab 01 - Hello R!",
    "section": "Data",
    "text": "Data\nIf it’s confusing that the data frame is called datasaurus_dozen when it contains 13 datasets, you’re not alone! Have you heard of a baker’s dozen?\nThe data frame we will be working with today is called datasaurus_dozen and it’s in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable.\nTo find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, “Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity” (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings. (Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. http://www.sciencedirect.com/science/article/pii/S0272775704001165.)\nIn this lab you will analyze the data from this study in order to learn what goes into a positive professor evaluation.\nThe data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors’ physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#warm-up",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#warm-up",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#packages",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#packages",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#data",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#data",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called evals. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nVisualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.\nVisualize and describe the relationship between score and bty_avg.\n\nHint: See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.\n\nRecreate the scatterplot from Exercise 2, but this time use\ngeom_jitter()? What does “jitter” mean? What was misleading about the initial scatterplot?\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a numerical predictor",
    "text": "Linear regression with a numerical predictor\nLinear model is in the form \\(\\hat{y} = b_0 + b_1 x\\).\n\nLet’s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called score_bty_fit to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.\nRecreate the scatterplot from Exercise 2, and add the regression line to this plot in orange colour, with shading for the uncertainty of the line turned off.\nInterpret the slope of the linear model in context of the data.\nInterpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.\nDetermine the \\(R^2\\) of the model and interpret it in context of the data.\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a categorical predictor",
    "text": "Linear regression with a categorical predictor\n\nFit a new linear model called score_gender_fit to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.\nWhat is the equation of the line corresponding to male professors? What is it for female professors?\nFit a new linear model called score_rank_fit to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.\nCreate a new variable called rank_relevel where \"tenure track\" is the baseline level.\nFit a new linear model called score_rank_relevel_fit to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 12. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\nCreate another new variable called tenure_eligible that labels \"teaching\" faculty as \"no\" and labels \"tenure track\" and \"tenured\" faculty as \"yes\".\nFit a new linear model called score_tenure_eligible_fit to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in the previous exercise. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the professor evaluations data we modeled in the previous lab. In the last lab we modeled evaluation scores using a single predictor at a time. This time we will use multiple predictors to model evaluation scores.\nFor context, review the previous lab’s introduction before continuing on to the exercises."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#packages",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#packages",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#data",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#data",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called evals. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nFit a linear model (one you have fit before): score_bty_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nFit a linear model (one you have fit before): score_bty_gen_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\nInterpret the slopes and intercept of score_bty_gen_fit in context of the data.\nWhat percent of the variability in score is explained by the model score_bty_gen_fit.\nWhat is the equation of the line corresponding to just male professors?\nFor two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?\nHow does the relationship between beauty and evaluation score vary between male and female professors?\nHow do the adjusted \\(R^2\\) values of score_bty_gen_fit and score_bty_fit compare? What does this tell us about how useful gender is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.\nCompare the slopes of bty_avg under the two models (score_bty_fit and score_bty_gen_fit). Has the addition of gender to the model changed the parameter estimate (slope) for bty_avg?\nCreate a new model called score_bty_rank_fit with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html",
    "title": "Lab 02 - Global plastic waste",
    "section": "",
    "text": "Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health. Our World in Data has a lot of great data at various levels including globally, per country, and over time. For this lab we focus on data from 2010.\nAdditionally, National Geographic ran a data visualization communication contest on plastic waste as seen here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#packages",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#packages",
    "title": "Lab 02 - Global plastic waste",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for this analysis. Run the following code in the Console to load this package.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#data",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#data",
    "title": "Lab 02 - Global plastic waste",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following.\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "",
    "text": "This class you’ll continue working on your projects. The first half of the lab is structured, and you can use the second half to make progress on your projects."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Opening an issue",
    "text": "Opening an issue\n\nGo to your project repo and open a new issue titled “Practice issue”.\nAdd the following text to the issue:\n\n\nThis is not a real issue. This is just some placeholder text.\n\nAnd the following is a bulleted to-do list:\n- [ ] Do this\n- [ ] Then that\n- [ ] And finally this\n\nHit preview to make sure the issue looks like the following:\n\n\n\n\n\n\n\nSubmit the issue.\nThen, assign the issue to one or few members of the team."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Working on the issue",
    "text": "Working on the issue\nAs you work on the issue you can check the boxes.\n\n\n\n\n\nNote that this will also show progress on the issue on the issue dashboard.\n\n\n\n\n\n\nCheck some of the boxes on your practice issue and confirm that you can see the progress result on the issue dashboard."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Closing the issue",
    "text": "Closing the issue\nOnce you’re done with an issue, you should close it. You can do this in one of two ways: on GitHub by clicking on Close issue or via a commit that directly addresses the issue. We’ll practice the second one. If you preface your commits with “Fixes”, “Fixed”, “Fix”, “Closes”, “Closed”, or “Close”, the issue will be closed when you push the changes to your repo.\n\nTake a note of the issue number, which will show up next to the issue title.\n\n\n\n\n\n\n\nGo to your project on RStudio and make a change. This can be something silly like adding a new line to the issue README. Then commit this change. In your commit message, use one of the special words listed above and reference the issue. For example, if the change I made was to add a new line to the README I would say something like the following:\n\n\nAdd a new line to the README, closes #2\n\n\n\n\n\n\nPush your changes and observe that the issue is now closed on GitHub. Click on the referenced commit to confirm that it was your last commit that closed the issue."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article on why Nobel laureates show immigration is so important for American science. You can read the article here. In the article they show that while most living Nobel laureates in the sciences are based in the US, many of them were born in other countries. This is one reason why scientific leaders say that immigration is vital for progress. In this lab we will work with the data from this article to recreate some of their visualizations as well as explore new questions."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "title": "Lab 03 - Nobel laureates",
    "section": "Merges and merge conflicts",
    "text": "Merges and merge conflicts\nThis is the second week you’re working in teams, so we’re going to make things a little more interesting and let all of you make changes and push those changes to your team repository. Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts. So our first task today is to walk you through a merge conflict!\n\nPushing to a repo replaces the code on GitHub with the code you have on your computer.\nIf a collaborator has made a change to your repo on GitHub that you haven’t incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator’s work!\nSo you need to explicitly “merge” your collaborator’s work before you can push.\nIf your and your collaborator’s changes are in different files or in different parts of the same file, git merges the work for you automatically when you *pull*.\nIf you both changed the same part of a file, git will produce a **merge conflict** because it doesn’t know how which change you want to keep and which change you want to overwrite.\n\nGit will put conflict markers in your code that look like:\n<<<<<<< HEAD \n\nSee also: [dplyr documentation](https://dplyr.tidyverse.org/)   \n\n======= \n\nSee also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  \n\n>>>>>>> some1alpha2numeric3string4\nThe ===s separate your changes (top) from their changes (bottom).\nNote that on top you see the word HEAD, which indicates that these are your changes.\nAnd at the bottom you see some1alpha2numeric3string4 (well, it probably looks more like 28e7b2ceb39972085a0860892062810fb812a08f).\nThis is the hash (a unique identifier) of the commit your collaborator made with the conflicting change.\nYour job is to reconcile the changes: edit the file so that it incorporates the best of both versions and delete the <<<, ===, and >>> lines. Then you can stage and commit the result."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#setup",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#setup",
    "title": "Lab 03 - Nobel laureates",
    "section": "Setup",
    "text": "Setup\n\nClone the repo and open the .Rmd file.\nAssign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "title": "Lab 03 - Nobel laureates",
    "section": "Let’s cause a merge conflict!",
    "text": "Let’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: everyone should have the repo cloned and know which role number(s) they are.\nRole 1:\n\nChange the team name to your actual team name.\nKnit, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange the team name to some other word.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nKnit.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nChange the a label of the first code chunk\nKnit, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nChange the label of the first code chunk to something other than previous role did.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Commit, and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "title": "Lab 03 - Nobel laureates",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (commit and push) before continuing your work. Never do new work while resolving a merge conflict.\nKnit, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#warm-up",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#warm-up",
    "title": "Lab 03 - Nobel laureates",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#packages",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#packages",
    "title": "Lab 03 - Nobel laureates",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#data",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSv (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nThe variable descriptions are as follows:\n\nid: ID number\nfirstname: First name of laureate\nsurname: Surname\nyear: Year prize won\ncategory: Category of prize\naffiliation: Affiliation of laureate\ncity: City of laureate in prize year\ncountry: Country of laureate in prize year\nborn_date: Birth date of laureate\ndied_date: Death date of laureate\ngender: Gender of laureate\nborn_city: City where laureate was born\nborn_country: Country where laureate was born\nborn_country_code: Code of country where laureate was born\ndied_city: City where laureate died\ndied_country: Country where laureate died\ndied_country_code: Code of country where laureate died\noverall_motivation: Overall motivation for recognition\nshare: Number of other winners award is shared with\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix `_original`.\n\nborn_country_original: Original country where laureate was born\nborn_city_original: Original city where laureate was born\ndied_country_original: Original country where laureate died\ndied_city_original: Original city where laureate died\ncity_original: Original city where laureate lived at the time of winning the award\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\n\n\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code.\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 03 - Nobel laureates",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nNote that we can achieve the same result using the `fct_other()` function we've seen before (i.e. with `country_us = fct_other(country, \"USA\")`). We decided to use the `if_else()` here to show you one example of an if statement in R.\n\n\nnobel_living <- nobel_living %>%\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science <- nobel_living %>%\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the next exercise work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your R Markdown document, even though the next exercise doesn’t explicitly ask you to do so.\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.d"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 03 - Nobel laureates",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\n**Hint:** You should be able to ~~cheat~~ borrow from code you used earlier to create the `country_us` variable.\n\n\nCreate a new variable called born_country_us that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Based on your visualization, do the data appear to support Buzzfeed’s claim? Explain your reasoning in 1-2 sentences.\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be a bar for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "title": "Lab 03 - Nobel laureates",
    "section": "Here’s where those immigrant Nobelists were born",
    "text": "Here’s where those immigrant Nobelists were born\n\nNote that your bar plot won't exactly match the one from the Buzzfeed article. This is likely because the data has been updated since the article was published.\n\n\nIn a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work.\nNow go back through your write up to make sure you’ve answered all questions and all of your R chunks are properly labelled. Once you decide as a team that you’re done with this lab, all members of the team should pull the changes and knit the R Markdown document to confirm that they can reproduce the report."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the Denny’s and La Quinta Inn and Suites data we visualized in the previous lab."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#packages",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#packages",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#data",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#data",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Data",
    "text": "Data\nRemember that the datasets we’ll use are called dennys and laquinta from the dsbox package. Since the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "The University of Edinburgh Art Collection “supports the world-leading research and teaching that happens within the University. Comprised of an astonishing range of objects and ideas spanning two millennia and a multitude of artistic forms, the collection reflects not only the long and rich trajectory of the University, but also major national and international shifts in art history.”1.\nSee the sidebar here and note that there are 2970 pieces in the art collection we’re collecting data on. Note that more pieces may have been added or some pieces may have been removed between when this lab was written and when you’re working on it.\nIn this lab we’ll scrape data on all art pieces in the Edinburgh College of Art collection."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "R scripts vs. R Markdown documents",
    "text": "R scripts vs. R Markdown documents\nToday we will be using both R scripts and R Markdown documents:\n\n.R: R scripts are plain text files containing only code and brief comments,\n\nWe’ll use R scripts in the web scraping stage and ultimately save the scraped data as a csv.\n\n.Rmd: R Markdown documents are plain text files containing.\n\nWe’ll use an R Markdown document in the web analysis stage, where we start off by reading in the csv file we wrote out in the scraping stage.\n\n\nHere is the organization of your repo, and the corresponding section in the lab that each file will be used for:"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#warm-up",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#warm-up",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#packages",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#packages",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we’re allowed to scrape the data, the rvest package for data scraping. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(robotstxt)\nlibrary(rvest)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#data",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#data",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you’ll be scraping the data! But before doing so, let’s check that a bot has permissions to access pages on this domain.\n\npaths_allowed(\"https://collections.ed.ac.uk/art)\")\n\n\n collections.ed.ac.uk                      \n\n\n[1] TRUE"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Scraping a single page",
    "text": "Scraping a single page\nTip: To run the code you can highlight or put your cursor next to the lines of code you want to run and hit Command+Enter.\n\nWork in scripts/01-scrape-page-one.R.\n\nWe will start off by scraping data on the first 10 pieces in the collection from here.\nFirst, we define a new object called first_url, which is the link above. Then, we read the page at this url with the read_html() function from the rvest package. The code for this is already provided in 01-scrape-page-one.R.\n\n# set url\nfirst_url <- \"https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0\"\n\n# read html page\npage <- read_html(first_url)\n\nFor the ten pieces on this page we will extract title, artist, and link information, and put these three variables in a data frame.\n\nTitles\nLet’s start with titles. We make use of the SelectorGadget to identify the tags for the relevant nodes. Note that there is some guessing and checking with this. In this case, not only pay attention to what is shown in the box as the tag but also the tags shown when hovering over items.\n\n\n\n\n\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\")\n\n{xml_nodeset (10)}\n [1] <a href=\"./record/99523?highlight=*:*\">Rock R Coast, Hethleen Russell, B ...\n [2] <a href=\"./record/99519?highlight=*:*\">Untitled                          ...\n [3] <a href=\"./record/21767?highlight=*:*\">Untitled                          ...\n [4] <a href=\"./record/20969?highlight=*:*\">Standing Female Nude              ...\n [5] <a href=\"./record/50385?highlight=*:*\">Hill Fence                        ...\n [6] <a href=\"./record/22511?highlight=*:*\">Abstract Composition with Fabric  ...\n [7] <a href=\"./record/21413?highlight=*:*\">Landscape                         ...\n [8] <a href=\"./record/21351?highlight=*:*\">Portrait of a Man                 ...\n [9] <a href=\"./record/53663?highlight=*:*\">Saucer                            ...\n[10] <a href=\"./record/99483?highlight=*:*\">Untitled - City Scene at Night    ...\n\n\nThen we extract the text with html_text():\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text()\n\n [1] \"Rock R Coast, Hethleen Russell, Bournemouth                                                                            (1966)\"\n [2] \"Untitled                                                                            (1960)\"                                   \n [3] \"Untitled                                                                            (1962)\"                                   \n [4] \"Standing Female Nude                                                                            (1957)\"                       \n [5] \"Hill Fence                                                                            (1976)\"                                 \n [6] \"Abstract Composition with Fabric Collage                                    \"                                                 \n [7] \"Landscape                                                                            (Circa 1953)\"                            \n [8] \"Portrait of a Man                                                                            (Circa 1952)\"                    \n [9] \"Saucer                                    \"                                                                                   \n[10] \"Untitled - City Scene at Night                                                                            (1964-1965)\"        \n\n\nAnd get rid of all the spurious white space in the text with str_squish(), which reduces repeated whitespace inside a string.\nTake a look at the help for str_squish() to find out more about how it works and how it’s different from str_trim().\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text() %>%\n  str_squish()\n\n [1] \"Rock R Coast, Hethleen Russell, Bournemouth (1966)\"\n [2] \"Untitled (1960)\"                                   \n [3] \"Untitled (1962)\"                                   \n [4] \"Standing Female Nude (1957)\"                       \n [5] \"Hill Fence (1976)\"                                 \n [6] \"Abstract Composition with Fabric Collage\"          \n [7] \"Landscape (Circa 1953)\"                            \n [8] \"Portrait of a Man (Circa 1952)\"                    \n [9] \"Saucer\"                                            \n[10] \"Untitled - City Scene at Night (1964-1965)\"        \n\n\nAnd finally save the resulting data as a vector of length 10:\n\ntitles <- page %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text() %>%\n  str_squish()\n\n\n\nLinks\nThe same nodes that contain the text for the titles also contains information on the links to individual art piece pages for each title. We can extract this information using a new function from the rvest package, html_attr(), which extracts attributes.\nA mini HTML lesson! The following is how we define hyperlinked text in HTML:\n<a href=\"https://www.google.com\">Seach on Google</a>\nAnd this is how the text would look like on a webpage: Seach on Google.\nHere the text is Seach on Google and the href attribute contains the url of the website you’d go to if you click on the hyperlinked text: https://www.google.com.\nThe moral of the story is: the link is stored in the href attribute.\n\npage %>%\n  html_nodes(\".iteminfo\") %>%   # same nodes\n  html_node(\"h3 a\") %>%         # as before\n  html_attr(\"href\")             # but get href attribute instead of text\n\n [1] \"./record/99523?highlight=*:*\" \"./record/99519?highlight=*:*\"\n [3] \"./record/21767?highlight=*:*\" \"./record/20969?highlight=*:*\"\n [5] \"./record/50385?highlight=*:*\" \"./record/22511?highlight=*:*\"\n [7] \"./record/21413?highlight=*:*\" \"./record/21351?highlight=*:*\"\n [9] \"./record/53663?highlight=*:*\" \"./record/99483?highlight=*:*\"\n\n\nThese don’t really look like URLs as we know then though. They’re relative links.\nSee the help for str_replace() to find out how it works. Remember that the first argument is passed in from the pipeline, so you just need to define the pattern and replacement arguments.\n\nClick on one of art piece titles in your browser and take note of the url of the webpage it takes you to. Think about how that url compares to what we scraped above? How is it different? Using str_replace(), fix the URLs. You’ll note something special happening in the pattern to replace. We want to replace the ., but we have it as \\\\.. This is because the period . is a special character and so we need to escape it first with backslashes, \\\\s.\n\n\n\nArtists\n\nFill in the blanks to scrape artist names.\n\n\n\nPut it altogether\n\nFill in the blanks to organize everything in a tibble.\n\n\n\nScrape the next page\n\nClick on the next page, and grab its url. Fill in the blank in to define a new object: second_url. Copy-paste code from top of the R script to scrape the new set of art pieces, and save the resulting data frame as second_ten.\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#functions",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#functions",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Functions",
    "text": "Functions\n\nWork in scripts/02-scrape-page-function.R.\n\nYou’ve been using R functions, now it’s time to write your own!\nLet’s start simple. Here is a function that takes in an argument x, and adds 2 to it.\n\nadd_two <- function(x){\n  x + 2\n}\n\nLet’s test it:\n\nadd_two(3)\n\n[1] 5\n\nadd_two(10)\n\n[1] 12\n\n\nThe skeleton for defining functions in R is as follows:\n\nfunction_name <- function(input){\n  # do something with the input(s)\n  # return something\n}\n\nThen, a function for scraping a page should look something like:\n\n**Reminder:** Function names should be short but evocative verbs.\n\n\nfunction_name <- function(url){\n  # read page at url\n  # extract title, link, artist info for n pieces on page\n  # return a n x 3 tibble\n}\n\n\nFill in the blanks using code you already developed in the previous exercises. Name the function scrape_page.\n\nTest out your new function by running the following in the console. Does the output look right? Discuss with teammates whether you’re getting the same results as before.\n\nscrape_page(first_url)\nscrape_page(second_url)\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#iteration",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#iteration",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Iteration",
    "text": "Iteration\n\nWork in scripts/03-scrape-page-many.R.\n\nWe went from manually scraping individual pages to writing a function to do the same. Next, we will work on making our workflow a little more efficient by using R to iterate over all pages that contain information on the art collection.\n\n**Reminder:** The collection has 2970 pieces in total.\n\nThat means we give develop a list of URLs (of pages that each have 10 art pieces), and write some code that applies the scrape_page() function to each page, and combines the resulting data frames from each page into a single data frame with 2970 rows and 3 columns.\n\nList of URLs\nClick through the first few of the pages in the art collection and observe their URLs to confirm the following pattern:\n[sometext]offset=0     # Pieces 1-10\n[sometext]offset=10    # Pieces 11-20\n[sometext]offset=20    # Pieces 21-30\n[sometext]offset=30    # Pieces 31-40\n...\n[sometext]offset=2960  # Pieces 2961-2970\nWe can construct these URLs in R by pasting together two pieces: (1) a common (root) text for the beginning of the URL, and (2) numbers starting at 0, increasing by 10, all the way up to 2970. Two new functions are helpful for accomplishing this: glue() for pasting two pieces of text and seq() for generating a sequence of numbers.\n\nFill in the blanks to construct the list of URLs.\n\n\n\nMapping\nFinally, we’re ready to iterate over the list of URLs we constructed. We will do this by mapping the function we developed over the list of URLs. There are a series of mapping functions in R (which we’ll learn about in more detail tomorrow), and they each take the following form:\nmap([x], [function to apply to each element of x])\nIn our case x is the list of URLs we constructed and the function to apply to each element of x is the function we developed earlier, scrape_page. And as a result we want a data frame, so we use map_dfr function:\n\nmap_dfr(urls, scrape_page)\n\n\nFill in the blanks to scrape all pages, and to create a new data frame called uoe_art.\n\n\n\nWrite out data\n\nFinally write out the data frame you constructed into the data folder so that you can use it in the analysis section.\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#analysis",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#analysis",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Analysis",
    "text": "Analysis\n\nWork in lab-08.Rmd for the rest of the lab. RMD - you are saving the script file and moving to another file.\n\nNow that we have a tidy dataset that we can analyze, let’s do that!\nWe’ll start with some data cleaning, to clean up the dates that appear at the end of some title text in parentheses. Some of these are years, others are more specific dates, some art pieces have no date information whatsoever, and others have some non-date information in parentheses. This should be interesting to clean up!\nFirst thing we’ll try is to separate the title column into two: one for the actual title and the other for the date if it exists. In human speak, we need to\n\n“separate the title column at the first occurrence of ( and put the contents on one side of the ( into a column called title and the contents on the other side into a column called date”\n\nLuckily, there’s a function that does just this: separate()!\nAnd once we have completed separating the single title column into title and date, we need to do further clean-up in the date column to get rid of extraneous )s with str_remove(), capture year information, and save the data as a numeric variable.\nHint: Remember escaping special characters from yesterday’s lecture? You’ll need to use that trick again.\n\nFill in the blanks in to implement the data wrangling we described above. Note that this will result in some warnings when you run the code, and that’s OK! Read the warnings, and explain what they mean, and why we are ok with leaving them in given that our objective is to just capture year where it’s convenient to do so.\nPrint out a summary of the data frame using the skim() function. How many pieces have artist info missing? How many have year info missing?\nMake a histogram of years. Use a reasonable binwidth. Do you see anything out of the ordinary?\n\n\n**Hint:** You'll want to use `mutate()` and `if_else()` or `case_when()` to implement the correction.\n\n\nFind which piece has the out of the ordinary year and go to its page on the art collection website to find the correct year for it. Can you tell why our code didn’t capture the correct year information? Correct the error in the data frame and visualize the data again.\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nWho is the most commonly featured artist in the collection? Do you know them? Any guess as to why the university has so many pieces from them?\n\nHint: str_subset() can be helful here. You should consider how you might capture titles where the word appears as “child” and “Child”.\n\nFinal question! How many art pieces have the word “child” in their title? Try to figure it out, and ask for help if you’re stuck.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.html",
    "href": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.html",
    "title": "Sales",
    "section": "",
    "text": "Read in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\n\n\n\n\n\n\n\n\nStretch goal: Manipulate the sales data such such that it looks like the following."
  },
  {
    "objectID": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "href": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "title": "Nobel winners",
    "section": "",
    "text": "Let’s first load the data:\n\nnobel <- ___(___)\n\nThen let’s split the data into two:\n\n# stem laureates\n___ <- nobel %>%\n  filter(___)\n\n# non-steam laureates\n___ <- nobel %>%\n  filter(___)\n\nAnd finally write out the data:\n\n# add code for writing out the two data frames here"
  },
  {
    "objectID": "course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html",
    "href": "course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html",
    "title": "Visualizing Starwars characters",
    "section": "",
    "text": "glimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       <chr> \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     <int> 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color <chr> \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color <chr> \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  <chr> \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        <chr> \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     <chr> \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  <chr> \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    <chr> \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      <list> <\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   <list> <\"Snowspeeder\", \"Imperial Speeder Bike\">, <>, <>, <>, \"Imp…\n$ starships  <list> <\"X-wing\", \"Imperial shuttle\">, <>, <>, \"TIE Advanced x1\",…\n\n\n\nModify the following plot to change the color of all points to \"pink\".\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"pink\")\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\nAdd labels for title, x and y axes, and size of points. Uncomment to see the effect.\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"#30509C\") +\n  labs(\n    #title = \"___\",\n    #x = \"___\", \n    #y = \"___\",\n    #___\n    )\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\nPick a single numerical variable and make a histogram of it. Select a reasonable binwidth for it.\n\n(A little bit of starter code is provided below, and the code chunk is set to not be evaluated with eval: false because the current code in there is not valid code and hence the document wouldn’t knit. Once you replace the code with valid code, set the chunk option to eval: true, or remove the eval option altogether since it’s set to true by default.)\n\nggplot(starwars, aes(___)) +\n  geom___\n\n\nPick a numerical variable and a categorical variable and make a visualization (you pick the type!) to visualization the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here…\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\n\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here…\n\nPick two numerical variables and two categorical variables and make a visualization that incorporates all of them and provide an interpretation with your answer.\n\n(This time no starter code is provided, you’re on your own!)\n\n\n\nInterpretation goes here…"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html",
    "title": "Cumulative deaths from COVID-19",
    "section": "",
    "text": "Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries.\nThe data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily.\nFor our analysis, in addition to the coronavirus package, we will use the following packages for data wrangling and visualization.\n\ntidyverse for data wrangling and visualization\nlubridate package for handling dates\nglue package for constructing text strings\nscales package for formatting axis labels\nggrepel package for pretty printing of country labels\n\nWe will make use of the DT package for interactive display of tabular output in the Appendix.\n\nlibrary(coronavirus) # devtools::install_github(\"RamiKrispin/coronavirus\")\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(DT)"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#data-prep",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#data-prep",
    "title": "Cumulative deaths from COVID-19",
    "section": "Data prep",
    "text": "Data prep\nThe data frame called coronavirus in the coronavirus package provides a daily summary of the Coronavirus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). A full list of the countries in the data frame is provided in the Appendix. Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. For this report, we will focus on the deaths.\nWe will start by making our selection for the countries we want to explore.\n\ncountries <- c(\n  \"China\",\n  \"France\",\n  \"United Kingdom\",\n  \"US\",\n  \"Turkey\"\n)\n\nIn the following code chunk we filter the data frame for deaths in the countries we specified above and calculate cumulative number of deaths. We will only visualize data since 10th confirmed death.\n\ncountry_data <- coronavirus %>%\n  # filter for deaths in countries of interest\n  filter(\n    type == \"death\",\n    country %in% countries\n  ) %>%\n  # fix county labels for pretty plotting\n  mutate(\n    country = case_when(\n      country == \"United Kingdom\" ~ \"UK\",\n      TRUE ~ country\n    )\n  ) %>%\n  # calculate number of total cases for each country and date\n  group_by(country, date) %>%\n  summarise(tot_cases = sum(cases)) %>%\n  # arrange by date in ascending order\n  arrange(date) %>%\n  # record daily cumulative cases as cumulative_cases\n  mutate(cumulative_cases = cumsum(tot_cases)) %>%\n  # only use days since the 10th confirmed death\n  filter(cumulative_cases > 9) %>%\n  # record days elapsed, end date, and end label\n  mutate(\n    days_elapsed = as.numeric(date - min(date)),\n    end_date     = if_else(date == max(date), TRUE, FALSE),\n    end_label    = if_else(end_date, country, NULL)\n  ) %>%\n  # ungroup\n  ungroup()\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\nWe also need to take a note of the “as of date” for the data so that we can properly label our visualization.\n\nas_of_date <- country_data %>% \n  summarise(max(date)) %>% \n  pull()\n\nas_of_date_formatted <- glue(\"{wday(as_of_date, label = TRUE)}, {month(as_of_date, label = TRUE)} {day(as_of_date)}, {year(as_of_date)}\")\n\nThese data are as of Thu, Jun 23, 2022."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#visualization",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#visualization",
    "title": "Cumulative deaths from COVID-19",
    "section": "Visualization",
    "text": "Visualization\nThe following visualization shows the number of cumulative cases vs. days elapsed since the 10th confirmed death in each country. The time span plotted for each country varies since some countries started seeing (and reporting) deaths from COVID-19 much later than others.\n\nggplot(data = country_data,\n       mapping = aes(x = days_elapsed, \n                     y = cumulative_cases, \n                     color = country, \n                     label = end_label)) +\n  # represent cumulative cases with lines\n  geom_line(size = 0.7, alpha = 0.8) +\n  # add points to line endings\n  geom_point(data = country_data %>% filter(end_date)) +\n  # add country labels, nudged above the lines\n  geom_label_repel(nudge_y = 1, direction = \"y\", hjust = 1) + \n  # turn off legend\n  guides(color = \"none\") +\n  # use pretty colors\n  scale_color_viridis_d() +\n  # better formatting for y-axis\n  scale_y_continuous(labels = label_comma()) +\n  # use minimal theme\n  theme_minimal() +\n  # customize labels\n  labs(\n    x = \"Days since 10th confirmed death\",\n    y = \"Cumulative number of deaths\",\n    title = \"Cumulative deaths from COVID-19, selected countries\",\n    subtitle = glue(\"Data as of\", as_of_date_formatted, .sep = \" \"),\n    caption = \"Source: github.com/RamiKrispin/coronavirus\"\n  )"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#appendix",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#appendix",
    "title": "Cumulative deaths from COVID-19",
    "section": "Appendix",
    "text": "Appendix\nA list of countries in the coronavirus data frame is provided below."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes <- un_votes %>%\n  inner_join(un_roll_calls, by = \"rcid\") %>%\n  inner_join(un_roll_call_issues, by = \"rcid\")"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualisation that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes %>%\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) %>%\n  mutate(year = year(date)) %>%\n  group_by(country, year, issue) %>%\n  summarize(percent_yes = mean(vote == \"yes\")) %>%\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#references",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nDavid Robinson (2017). unvotes: United Nations General Assembly Voting Data. R package version 0.2.0.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#appendix",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html",
    "title": "Bechdel",
    "section": "",
    "text": "In this mini analysis we work with the data used in the FiveThirtyEight story titled “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”. Your task is to fill in the blanks denoted by ___."
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "title": "Bechdel",
    "section": "Data and packages",
    "text": "Data and packages\nWe start with loading the packages we’ll use.\n\nlibrary(fivethirtyeight)\nlibrary(tidyverse)\n\nThe dataset contains information on 1794 movies released between 1970 and 2013. However we’ll focus our analysis on movies released between 1990 and 2013.\n\nbechdel90_13 <- bechdel %>% \n  filter(between(year, 1990, 2013))\n\nThere are ___ such movies.\nThe financial variables we’ll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars\ndomgross_2013: Domestic gross (US) in 2013 inflation adjusted dollars\nintgross_2013: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars\n\nAnd we’ll also use the binary and clean_test variables for grouping."
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "title": "Bechdel",
    "section": "Analysis",
    "text": "Analysis\nLet’s take a look at how median budget and gross vary by whether the movie passed the Bechdel test, which is stored in the binary variable.\n\nbechdel90_13 %>%\n  group_by(binary) %>%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 2 × 4\n  binary med_budget med_domgross med_intgross\n  <chr>       <dbl>        <dbl>        <dbl>\n1 FAIL    48385984.    57318606.    104475669\n2 PASS    31070724     45330446.     80124349\n\n\nNext, let’s take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result. This information is stored in the clean_test variable, which takes on the following values:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\n\nbechdel90_13 %>%\n  #group_by(___) %>%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 1 × 3\n  med_budget med_domgross med_intgross\n       <int>        <dbl>        <dbl>\n1   37878971     52270207     93523336\n\n\nIn order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we’ll first create a new variable called roi as the ratio of the gross to budget.\n\nbechdel90_13 <- bechdel90_13 %>%\n  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)\n\nLet’s see which movies have the highest return on investment.\n\nbechdel90_13 %>%\n  arrange(desc(roi)) %>% \n  select(title, roi, year)\n\n# A tibble: 1,615 × 3\n   title                     roi  year\n   <chr>                   <dbl> <int>\n 1 Paranormal Activity      671.  2007\n 2 The Blair Witch Project  648.  1999\n 3 El Mariachi              583.  1992\n 4 Clerks.                  258.  1994\n 5 In the Company of Men    231.  1997\n 6 Napoleon Dynamite        227.  2004\n 7 Once                     190.  2006\n 8 The Devil Inside         155.  2012\n 9 Primer                   142.  2004\n10 Fireproof                134.  2008\n# … with 1,605 more rows\n\n\nBelow is a visualization of the return on investment by test result, however it’s difficult to see the distributions due to a few extreme observations.\n\nggplot(data = bechdel90_13, \n       mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"___\",\n    color = \"Binary Bechdel result\"\n    )\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel90_13 %>%\n  filter(roi > 400) %>%\n  select(title, budget_2013, domgross_2013, year)\n\n# A tibble: 3 × 4\n  title                   budget_2013 domgross_2013  year\n  <chr>                         <int>         <dbl> <int>\n1 Paranormal Activity          505595     121251476  2007\n2 The Blair Witch Project      839077     196538593  1999\n3 El Mariachi                   11622       3388636  1992\n\n\nZooming in on the movies with roi < ___ provides a better view of how the medians across the categories compare:\n\nggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    subtitle = \"___\", # Something about zooming in to a certain level\n    x = \"Detailed Bechdel result\",\n    y = \"Return on investment\",\n    color = \"Binary Bechdel result\"\n    ) +\n  coord_cartesian(ylim = c(0, 15))"
  },
  {
    "objectID": "course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.html",
    "href": "course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.html",
    "title": "Brexit",
    "section": "",
    "text": "In September 2019, YouGov survey asked 1,639 GB adults the following question:\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon’t know\n\n\nThe data from the survey is in data/brexit.csv.\n\nbrexit <- read_csv(\"data/brexit.csv\")\n\nIn the notes saw the code for following visualization.\n\nbrexit <- brexit %>%\n  mutate(\n    region = fct_relevel(region, \"london\", \"rest_of_south\", \"midlands_wales\", \"north\", \"scot\"),\n    region = fct_recode(region, London = \"london\", `Rest of South` = \"rest_of_south\", `Midlands / Wales` = \"midlands_wales\", North = \"north\", Scotland = \"scot\")\n  )\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\nIn this application exercise we tell different stories with the same data.\n\nExercise 1 - Free scales\nAdd scales = \"free_x\" as an argument to the facet_wrap() function. How does the visualization change? How is the story this visualization telling different than the story the original plot tells?\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region,\n    nrow = 1, labeller = label_wrap_gen(width = 12),\n    # ___\n  ) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\n\n\nExercise 2 - Comparing proportions across facets\nFirst, calculate the proportion of wrong, right, and don’t know answers in each category and then plot these proportions (rather than the counts) and then improve axis labeling. How is the story this visualization telling different than the story the original plot tells? Hint: You’ll need the scales package to improve axis labeling, which means you’ll need to load it on top of the document as well.\n\n# code goes here\n\n\n\nExercise 3 - Comparing proportions across bars\nRecreate the same visualization from the previous exercise, this time dodging the bars for opinion proportions for each region, rather than faceting by region and then improve the legend. How is the story this visualization telling different than the story the previous plot tells?\n\n# code goes here"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "title": "Hotel bookings - data wrangling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "title": "Hotel bookings - data wrangling",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.\nWarm up! Take a look at an overview of the data with the skim() function.\nNote: I already gave you the answer to this exercise. You just need to knit the document and view the output. A definition of all variables is given in the Data dictionary section at the end, though you don’t need to familiarize yourself with all variables in order to work through these exercises.\n\nskim(hotels)\n\n\nData summary\n\n\nName\nhotels\n\n\nNumber of rows\n119390\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n1\n\n\nnumeric\n18\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n178\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n334\n0\n\n\ncompany\n0\n1\n1\n4\n0\n353\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nreservation_status\n0\n1\n7\n9\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\n\n\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\n\n\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\n\n\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\n\n\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\n\n\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nExercise 2.\nAre people traveling on a whim? Let’s see…\nFill in the blanks for filtering for hotel bookings where the guest is not from the US (country code \"USA\") and the lead_time is less than 1 day.\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %>%\n  filter(\n    country ____ \"USA\", \n    lead_time ____ ____\n    )\n\n\n\nExercise 3.\nHow many bookings involve at least 1 child or baby?\nIn the following chunk, replace\n\n[AT LEAST] with the logical operator for “at least” (in two places)\n[OR] with the logical operator for “or”\n\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %>%\n  filter(\n    children [AT LEAST] 1 [OR] babies [AT LEAST] 1\n    )\n\n\n\nExercise 4.\nDo you think it’s more likely to find bookings with children or babies in city hotels or resort hotels? Test your intuition. Using filter() determine the number of bookings in resort hotels that have more than 1 child or baby in the room? Then, do the same for city hotels, and compare the numbers of rows in the resulting filtered data frames.\n\n# add code here\n# pay attention to correctness and code style\n\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 5.\nCreate a frequency table of the number of adults in a booking. Display the results in descending order so the most common observation is on top. What is the most common number of adults in bookings in this dataset? Are there any surprising results?\nNote: Don’t forget to label your R chunk as well (where it says label-me-1). Your label should be short, informative, and shouldn’t include spaces. It also shouldn’t repeat a previous label, otherwise R Markdown will give you an error about repeated R chunk labels.\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 6.\nRepeat Exercise 5, once for canceled bookings (is_canceled coded as 1) and once for not canceled bookings (is_canceled coded as 0). What does this reveal about the surprising results you spotted in the previous exercise?\nNote: Don’t forget to label your R chunk as well (where it says label-me-2).\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 7.\nCalculate minimum, mean, median, and maximum average daily rate (adr) grouped by hotel type so that you can get these statistics separately for resort and city hotels. Which type of hotel is higher, on average?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 8.\nWe observe two unusual values in the summary statistics above – a negative minimum, and a very high maximum). What types of hotels are these? Locate these observations in the dataset and find out the arrival date (year and month) as well as how many people (adults, children, and babies) stayed in the room. You can investigate the data in the viewer to locate these values, but preferably you should identify them in a reproducible way with some code.\nHint: For example, you can filter for the given adr amounts and select the relevant columns.\n\n# add code here\n# pay attention to correctness and code style"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "title": "Hotel bookings - data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the full data dictionary. Note that it is long (there are lots of variables in the data), but we will be using a limited set of the variables for our analysis.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:  Undefined/SC – no meal package;BB – Bed & Breakfast;  HB – Half board (breakfast and one other meal – usually dinner);  FB – Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155–3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:No Deposit – no deposit was made;Non Refund – a deposit was made in the value of the total stay cost;Refundable – a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:Contract - when the booking has an allotment or other type of contract associated to it;Group – when the booking is associated to a group;Transient – when the booking is not part of a group or contract, and is not associated to other transient booking;Transient-party – when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g. twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:Canceled – booking was canceled by the customer;Check-Out – customer has checked in but already departed;No-Show – customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.html",
    "href": "course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.html",
    "title": "Type coercion",
    "section": "",
    "text": "c(1, 1L, \"C\")\n\n[1] \"1\" \"1\" \"C\"\n\n\n\n1\n\n[1] 1\n\n1L\n\n[1] 1\n\n\"C\"\n\n[1] \"C\"\n\n\n\n#typeof(c(1, 1L, \"C\"))\n\n\nc(1L / 0, \"A\")\n\n\nc(1L / 0, \"A\")\n\n[1] \"Inf\" \"A\"  \n\n\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L/0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n\n\n#typeof(c(1L / 0, \"A\"))\n\n\nc(1:3, 5)\n\n\nc(1:3, 5)\n\n[1] 1 2 3 5\n\n\n\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n\n\n#typeof(c(1:3, 5))\n\n\nc(3, \"3+\")\n\n\nc(3, \"3+\")\n\n[1] \"3\"  \"3+\"\n\n\n\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n\n\n#typeof(c(3, \"3+\"))\n\n\nc(NA, TRUE)\n\n\nc(NA, TRUE)\n\n[1]   NA TRUE\n\n\n\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n#typeof(c(NA, TRUE))"
  },
  {
    "objectID": "course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.html",
    "href": "course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.html",
    "title": "Hotel bookings - factors",
    "section": "",
    "text": "# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nFirst, knit the document and view the following visualization. How are the months ordered? What would be a better order? Then, reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\nhotels %>%\n  group_by(hotel, arrival_date_month) %>%   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr)) %>%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n    )\n\n`summarise()` has grouped output by 'hotel'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.html",
    "href": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.html",
    "title": "The Office - Solution",
    "section": "",
    "text": "Use theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",…\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis…\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky…\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha…\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How …\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How …\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6…\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,…\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-…\n\n\nFix air_date for later use.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don’t match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %>%\n  distinct(season, episode)\n\n# A tibble: 186 × 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# … with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\noffice_lines <- theoffice %>%\n  group_by(season, episode) %>%\n  mutate(\n    n_lines = n(),\n    lines_jim = sum(character == \"Jim\") / n_lines,\n    lines_pam = sum(character == \"Pam\") / n_lines,\n    lines_michael = sum(character == \"Michael\") / n_lines,\n    lines_dwight = sum(character == \"Dwight\") / n_lines,\n  ) %>%\n  ungroup() %>%\n  select(season, episode, episode_name, contains(\"lines_\")) %>%\n  distinct(season, episode, episode_name, .keep_all = TRUE)\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine’s Day, and Christmas.\n\ntheoffice <- theoffice %>%\n  mutate(text = tolower(text))\n\nhalloween_episodes <- theoffice %>%\n  filter(str_detect(text, \"halloween\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(halloween = 1) %>%\n  select(-n)\n\nvalentine_episodes <- theoffice %>%\n  filter(str_detect(text, \"valentine\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(valentine = 1) %>%\n  select(-n)\n\nchristmas_episodes <- theoffice %>%\n  filter(str_detect(text, \"christmas\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(christmas = 1) %>%\n  select(-n)\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you’ve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\noffice_df <- theoffice %>%\n  select(season, episode, episode_name, imdb_rating, total_votes, air_date) %>%\n  distinct(season, episode, .keep_all = TRUE) %>%\n  left_join(halloween_episodes, by = \"episode_name\") %>% \n  left_join(valentine_episodes, by = \"episode_name\") %>% \n  left_join(christmas_episodes, by = \"episode_name\") %>% \n  replace_na(list(halloween = 0, valentine = 0, christmas = 0)) %>%\n  mutate(michael = if_else(season > 7, 0, 1)) %>%\n  mutate(across(halloween:michael, as.factor)) %>%\n  left_join(office_lines, by = c(\"season\", \"episode\", \"episode_name\"))\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\noffice_split <- initial_split(office_df)\noffice_train <- training(office_split)\noffice_test <- testing(office_split)\n\n\n\nExercise 5 - Specify a linear regression model.\n\noffice_mod <- linear_reg() %>%\n  set_engine(\"lm\")\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, and removes all zero variance predictors.\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  update_role(episode_name, new_role = \"id\") %>%\n  step_rm(air_date) %>%\n  step_dummy(all_nominal(), -episode_name) %>%\n  step_zv(all_predictors())\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\noffice_wflow <- workflow() %>%\n  add_model(office_mod) %>%\n  add_recipe(office_rec)\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\noffice_fit <- office_wflow %>%\n  fit(data = office_train)\n\ntidy(office_fit)\n\n# A tibble: 12 × 5\n   term           estimate std.error statistic  p.value\n   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)    6.34     0.298       21.2    1.24e-43\n 2 season         0.0542   0.0224       2.42   1.68e- 2\n 3 episode        0.0125   0.00439      2.85   5.05e- 3\n 4 total_votes    0.000372 0.0000390    9.55   1.25e-16\n 5 lines_jim      0.653    0.679        0.962  3.38e- 1\n 6 lines_pam      0.0329   0.696        0.0473 9.62e- 1\n 7 lines_michael  0.111    0.544        0.204  8.39e- 1\n 8 lines_dwight   0.806    0.522        1.54   1.25e- 1\n 9 halloween_X1  -0.00340  0.181       -0.0188 9.85e- 1\n10 valentine_X1  -0.0573   0.180       -0.318  7.51e- 1\n11 christmas_X1   0.285    0.129        2.22   2.82e- 2\n12 michael_X1     0.585    0.141        4.15   6.01e- 5\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\nset.seed(345)\nfolds <- vfold_cv(office_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits           id   \n  <list>           <chr>\n1 <split [111/28]> Fold1\n2 <split [111/28]> Fold2\n3 <split [111/28]> Fold3\n4 <split [111/28]> Fold4\n5 <split [112/27]> Fold5\n\nset.seed(456)\noffice_fit_rs <- office_wflow %>%\n  fit_resamples(folds)\n\ncollect_metrics(office_fit_rs)\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.367     5  0.0512 Preprocessor1_Model1\n2 rsq     standard   0.543     5  0.0386 Preprocessor1_Model1\n\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\noffice_test_pred <- predict(office_fit, new_data = office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, episode_name))\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.401\n\n\n\n\nOld model\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n# A tibble: 12 × 5\n   term                estimate std.error statistic  p.value\n   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)         7.20     0.188        38.4   9.92e-72\n 2 season             -0.0501   0.0140       -3.57  5.04e- 4\n 3 episode             0.0449   0.00877       5.11  1.13e- 6\n 4 total_votes         0.000360 0.0000404     8.89  4.99e-15\n 5 air_date_month_Feb -0.145    0.139        -1.04  2.99e- 1\n 6 air_date_month_Mar -0.376    0.134        -2.81  5.69e- 3\n 7 air_date_month_Apr -0.309    0.131        -2.36  1.96e- 2\n 8 air_date_month_May -0.128    0.162        -0.791 4.30e- 1\n 9 air_date_month_Sep  0.512    0.178         2.88  4.63e- 3\n10 air_date_month_Oct  0.270    0.139         1.95  5.38e- 2\n11 air_date_month_Nov  0.116    0.126         0.924 3.57e- 1\n12 air_date_month_Dec  0.407    0.165         2.47  1.49e- 2\n\noffice_test_pred_old <- predict(office_fit_old, new_data = office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, episode_name))\n\nrmse(office_test_pred_old, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.403"
  },
  {
    "objectID": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.html",
    "href": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.html",
    "title": "The Office",
    "section": "",
    "text": "Use theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",…\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis…\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky…\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha…\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How …\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How …\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6…\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,…\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-…\n\n\nFix air_date for later use.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don’t match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %>%\n  distinct(season, episode)\n\n# A tibble: 186 × 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# … with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\n\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine’s Day, and Christmas.\n\n\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you’ve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\n\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\n\n\n\nExercise 5 - Specify a linear regression model.\n\n\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, uses season as a factor, and removes all zero variance predictors.\n\n\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\n\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\n#set.seed(345)\n#folds <- vfold_cv(___, v = ___)\n#folds\n#\n#set.seed(456)\n#office_fit_rs <- ___ %>%\n#  ___(___)\n#\n#___(office_fit_rs)\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\n\n\n\n\nOld model\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n___\n\nError: <text>:22:2: unexpected input\n21: \n22: __\n     ^"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#introduction",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data-analysis-plan",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html#plot-and-text",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[\n\n\n\n\n\n]"
  },
  {
    "objectID": "course-materials/project-instructions/project.html#data",
    "href": "course-materials/project-instructions/project.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nOn the useful links part of the website you will find a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#deliverables-and-due-dates",
    "href": "course-materials/project-instructions/project.html#deliverables-and-due-dates",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables and Due Dates",
    "text": "Deliverables and Due Dates\n\nProposal - due 9/30/2022 at meeting.\nUpdate - due 10/7/2022 at meeting.\nPaper - due 10/14/2022 at meeting.\nPresentation - due 10/18/2022 in class.\nExecutive summary - due 10/18/2022 11:59pm.\n\n\nInitial Meeting\nThis includes a research question and one paragraph describing your intended project. Place your writing in an RMarkdown document in your proposal folder in your project repository. Your group will also present the data you have found. Together, as a group, we will review your idea and discuss your ideas. Every group member must contribute to this conversation. This also gives me an opportunity to help you decide if the data you have chosen will work for your questions of interest. I will be cloning you a repository to work on your project with. You do not need to copy and paste from this document.\nThe grading scheme for the project proposal is as follows.\n\n\n\n\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n4 pts\n\n\nProposal\n4 pts\n\n\nTeamwork\n2 pt\n\n\n\n\n\nUpdate\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset. Place your writing in an RMarkdown document in your update folder in your project repository.\n\nSection 1 - Introduction: The introduction should introduce your general research question and your data (where it came from, how it was collected,what are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nThe outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery exploratory data analysis, including some summary statistics and visualizations, along with explanation on how they help you learn more about your data.\nThe method(s) that you believe will be useful in answering your question(s).\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows.\n\n\n\n\n\n\n\nTotal\n20 pts\n\n\n\n\nCleaned Data\n2 pts\n\n\nPreliminary Paper\n10 pts\n\n\nWorkflow, organization, code quality\n3 pt\n\n\nTeamwork\n5 pt\n\n\n\n\n\nPaper\nThis is should include a complete group presentation, paper, and documentation of your analysis.\n\n1. Title\nGive an informative title to your project.\nAssessment: Does the title give an accurate preview of what the paper is about? Is it informative, specific and precise?\n\n\n2. Abstract\nThe abstract provides a brief summary of the entire paper (background, methods, results and conclusions). The suggested length is no more than 150 words. This allows you approximately 1 sentence (and likely no more than two sentences) summarizing each of the following sections. Typically, abstracts are the last thing you write.\nAssessment: Are the main points of the paper described clearly and succinctly?\n\n\n3. Background and significance\nIn this section you are providing the background of the research area and arguing why it is interesting and significant. This section relies heavily on literature review (prior research done in this area and facts that argue why the research is important). This whole section should provide the necessary background leading up to a presentation (in the last few sentences of this section) of the research hypotheses that you will be testing in your study. Well-accepted facts and/or referenced statements should serve as the majority of content of this section. Typically, the background and significance section starts very broad and moves towards the specific area/hypotheses you are testing.\nAssessment: - Does the background and significance have a logical organization? Does it move from the general to the specific? - Has sufficient background been provided to understand the paper? How does this work relate to other work in the scientific literature? - Has a reasonable explanation been given for why the research was done? Why is the work important? Why is it relevant? - Does this section end with statements about the hypothesis/goals of the paper?\n\n\n4. Methods\n\nData collection. Explain how the data was collected/experiment was conducted. Additionally, you should provide information on the individuals who participated to assess representativeness. Non-response rates and other relevant data collection details should be mentioned here if they are an issue. However, you should not discuss the impact of these issues here—save that for the limitations section.\nVariable creation. Detail the variables in your analysis and how they are defined (if necessary). For example, if you created a combined (frequency times quantity) drinking variable you should describe how. If you are talking about gender no further explanation is really needed.\nAnalytic Methods. Explain the statistical procedures that will be used to analyze your data. E.g. Boxplots are used to illustrate differences in GPA across gender and class standing. Correlations are used to assess the impacts of gender and class standing on GPA.\n\nAssessment: Could the study be repeated based on the information given here? Is the material organized into logical categories (like the one’s above)?\n\n\n5. Results\nTypically, results sections start with descriptive statistics, e.g. what percent of the sample is male/female, what is the mean GPA overall, in the different groups, etc. Figures can be nice to illustrate these differences! However, information presented must be relevant in helping to answer the research question(s) of interest. Typically, inferential (i.e. hypothesis tests) statistics come next. Tables can often be helpful for results from multiple regression. Do not give computer output here! This should look like a peer-reviewed journal article results section. Tables and figures should be labeled, embedded in the text, and referenced appropriately. The results section typically makes for fairly dry reading. It does not explain the impact of findings, it merely highlights and reports statistical information.\nAssessment: - Is the content appropriate for a results section? Is there a clear description of the results? - Are the results/data analyzed well? Given the data in each figure/table is the interpretation accurate and logical? Is the analysis of the data thorough (anything ignored?) - Are the figures/tables appropriate for the data being discussed? Are the figure legends and titles clear and concise?\n\n\n6. Discussion/Conclusions\nRestate your objective and draw connections between your analyses and objective. In other words, how did (or didn’t) you answer/address your objective. Place these all in the larger scope of previous research on your topic (i.e. what you found from the literature review), that is, how do your findings help the field move forward? Talk about the limitations of your findings and possible areas for future research to better investigate your research question. End with a concluding sentence or two that summarizes your key findings and impact on the field.\nAssessment: - Does the author clearly state whether the results answer the question (support or disprove the hypothesis)? - Were specific data cited from the results to support each interpretation? Does the author clearly articulate the basis for supporting or rejecting each hypothesis? - Does the author adequately relate the results of the current work to previous research?\n\n\n7. References\nAssessment: Are the references appropriate and of adequate quality? Are the references citied properly (both in the text and at the end of the paper)?\nSome additional general criteria that will be used to evaluate: - Description of the data source - Accuracy of data analysis - Accuracy of conclusions and discussion - Overall clarity and presentation - Originality and significance of the study - Writing quality and organization of the paper\nCredit: The Undergraduate Statistics Project Competition\n\n\n\n\n\n\n\nTotal\n75 pts\n\n\n\n\nCleaned Data\n5 pts\n\n\nPaper\n20 pts\n\n\nWorkflow, organization, code quality\n10 pt\n\n\nTeamwork and Presentation\n5 pt\n\n\n\n\n\n\nPresentation or Poster\n3 minutes, per person, maximum, and each team member should say something substantial. You can either present live during class with either a poster, virtual poster, or presentation or pre-record and submit your video to be played during class.\n\nSlide Option\nPrepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (3 minutes, per person, total). Each team member should get a chance to speak during the presentation.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\n\n\nVirtual Poster\nSee website supplementary documents for a template.\n\n\nPoster (you need to get this printed)\nSee website supplementary documents for a template.\nWhichever form you choose, your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nPresentations will take place during the last day of class.\nDuring class you will watch presentations from other teams in class and provide feedback in the form of peer evaluations. See website supplementary documents. The presentation line-up will be in group number order (since that was random).\nThe professors grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\n\nTotal | 45 pts | ================================================================================================================================================================================================================+========+ Time management: Did the team divide the time well among themselves or got cut off going over time? | 4 pts |\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\n\nContent: Did the team use impact visualizations and/or appropriate statistical procedures, and interpret the results accurately? | 10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n8 pts |\n\n\nAre the slides/poster well organized, readable, not full of text, featuring figures with legible labels, legends, etc.? | 7 pts |\n\n\n\n\n\n\nExecutive summary\nAlong with your visual presentation, your team should provide a brief summary of your project in the README of your repository.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.Place your writing in an RMarkdown document in your executive_summary folder in your project repository.\nThe executive summary and repo organization is worth 30 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nRepo organization\nThe following folders and files in your project repository:\n\nREADME.Rmd + README.md: Will contain your executive summary and links to your other content.\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n/update: Your first major update files\n/paper: Your paper\n/extra: Extra files you may use\n/presentation+ presentation.Rmd + presentation.html: Your presentation slides\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#tips",
    "href": "course-materials/project-instructions/project.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou’re working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that’s fine Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (I will be reviewing commits from different team members).\nSet aside time to work together and apart.\nWhen you’re done, review the documents on GitHub to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#marking",
    "href": "course-materials/project-instructions/project.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\n\n\n\n\nTotal\n200 pts\n\n\n\n\nProposal\n10 pts\n\n\nUpdate\n20 pts\n\n\nPaper\n75 pts\n\n\nExecutive summary\n30 pts\n\n\nPresentation\n45 pts\n\n\nReproducibility and organization\n10 pts\n\n\nClassmates’ presentation evaluation\n10 pts\n\n\n\n\nCriteria/Rubric\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged, by their teammates, to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works. GitHub shows who submits changes and can also be used to see who participated. You will be asked to fill out a survey where you report a contribution percentage for each team member. If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations."
  },
  {
    "objectID": "course-materials/class-discussion/ethical_ds_discussion.html",
    "href": "course-materials/class-discussion/ethical_ds_discussion.html",
    "title": "Ethical Data Scientist Discussion",
    "section": "",
    "text": "You should have read The Ethical Data Scientist by Cathy O’Neil, published in Slate on Feb 4, 2016.\nReview the CARVE ethical principals. For each of the questions below, as part of your discussion, consider which of these principals are relevant to the the discussion question.\nDiscuss the following questions with your group.\n\nDiscuss with your group the author’s argument that it would not be ethical to use race as a predictor for the homelessness project she worked on.\nThink of a different context where a predictor variable might be available, but it might not be ethical to use it.\nThe author argues that data scientists are not paid to assess the effects of their algorithms. Choose one of the questions below, quoted from the article. List some positive and negative effects that an algorithm might have on people’s lives in that context. Consider CARVE for each one as well.\n\n“Do new-fangled social media algorithms encourage addictive gambling behavior?\n“Do the teacher assessments encourage good teachers to stay in education?\n“Does predictive policing improve long-term outcomes for the people targeted by their models?”"
  },
  {
    "objectID": "course-materials/class-discussion/gelman_asa_ethics_discussion.html",
    "href": "course-materials/class-discussion/gelman_asa_ethics_discussion.html",
    "title": "Ethics Discussion 2",
    "section": "",
    "text": "You should have read Data Ethics Reading Honesty and transparency are not enoughby Andrew Gelman, published in Chance in 2017 and ethical guidelines for statistical practicefrom the American Statistical Association, 2022.\nReview the CARVE ethical principals. For each of the questions below, as part of your discussion, consider which of these principals are relevant to the the discussion question.\nDiscuss the following questions with your group.\n\nRegarding Andrew Gelman’s article, “Honesty and transparency are not enough.” Gelman refers to an “Excel error” by Reinhart and Rogoff. Google, read, and explain the mistake made by those authors.\nList some specific actions researchers can take that Gelman would label “honesty and transparency.”\nWhat would Gelman like researchers to do in addition to acting in an honest and transparent way?\nOpen the American Statistical Association’s “Ethical guidelines for statistical practice.” Note that clicking on the blue bars labeled “The ethical statistical practitioner:” expands sets of specific guidelines. Identify at least two guidelines that Gelman would call “honesty and transparency” and at least one guideline that address his desire for researchers to go beyond honesty and transparency. Which of CARVE do those correspond to, or do they not?"
  },
  {
    "objectID": "course-materials/class-discussion/multiple_article_ethics_discussion.html",
    "href": "course-materials/class-discussion/multiple_article_ethics_discussion.html",
    "title": "Ethics Discussion 3 and Beyond",
    "section": "",
    "text": "Read Of oaths and checklists by Patil, Mason, and Loukides."
  },
  {
    "objectID": "course-materials/class-discussion/multiple_article_ethics_discussion.html#rounds-12-and-3",
    "href": "course-materials/class-discussion/multiple_article_ethics_discussion.html#rounds-12-and-3",
    "title": "Ethics Discussion 3 and Beyond",
    "section": "Rounds 1,2 and 3",
    "text": "Rounds 1,2 and 3\nThere will be 3 days where you will be asked to read an article. You are only reading 1 article per assignment. Use the table below to know what articles to read and use their links by clicking the article title. Your group number is based on the class group you are in at the time of the assignment. See our groups table in Moodle."
  },
  {
    "objectID": "course-materials/class-discussion/multiple_article_ethics_discussion.html#in-class-discussion-questions",
    "href": "course-materials/class-discussion/multiple_article_ethics_discussion.html#in-class-discussion-questions",
    "title": "Ethics Discussion 3 and Beyond",
    "section": "In Class Discussion Questions",
    "text": "In Class Discussion Questions\nRemember to follow the suggestions for healthy discourse in your groups on your group contract. If you have lost that document, see a blank copy with the discourse suggestions.\nYou will discuss your shared read article in class with your group. Choose at least one recorder to take notes during discussion and one speaker for the group during the full class discussion.\n1) Discuss which CARVE principals are relevant and way.\n1) Suggest and briefly discuss one or two check-list items that might have helped prevent the ethical problem described or that relate to the issues discussed in the article."
  },
  {
    "objectID": "course-materials/class-discussion/multiple_article_ethics_discussion.html#article-table",
    "href": "course-materials/class-discussion/multiple_article_ethics_discussion.html#article-table",
    "title": "Ethics Discussion 3 and Beyond",
    "section": "Article Table",
    "text": "Article Table\n\n\n\n\n\n\n\n\n\nArticles\nRound 1\nRound 2\nRound 3\n\n\n\n\nGuardian article on Cambridge Analytica\nGroup 1\n\n\n\n\nPropublica article on risk assessment in criminal sentencing\nGroup 2\n\n\n\n\nNYTimes: Gender discrimination by an approval algorithm for Apple’s credit card\nGroup 3\n\n\n\n\nNYTimes: Changes to the Census could make small towns disappear\nGroup 4\n\n\n\n\nNYTimes: Location tracking cell phones\nGroup 5\n\n\n\n\nNYTimes: Data protection\nGroup 6\n\n\n\n\nWashington Post article on racial bias in medical algorithms\n\nGroup 1\n\n\n\nNPR: IBM discontinues facial recognition products\n\nGroup 2\n\n\n\nEthics of digital contact tracing\n\nGroup 3\n\n\n\nNPR: Fired data scientist launches coronavirus dashboard\n\nGroup 4\n\n\n\nHarvard Business Review: Racial disparities in health care outcomes\n\nGroup 5\n\n\n\nReuters: Amazon’s recruiting tool that filtered out women’s colleges\n\nGroup 6\n\n\n\nNYTimes: Indigenous data sovereignty\n\n\nGroup 1\n\n\nNYTimes: Many trial volunteers got the placebo vaccine. Do they now deserve the real ones?\n\n\nGroup 2\n\n\nNYTimes: An algorithm that grants freedom, or takes it away\n\n\nGroup 3\n\n\nNYTimes: Using A.I. to find bias in A.I.\n\n\nGroup 4\n\n\nNYTimes: 2020 Census undercounted\n\n\nGroup 5\n\n\nNYTimes: What should happen to our data when we die?\n\n\nGroup 6"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html",
    "title": "HW 03 - Road traffic accidents",
    "section": "",
    "text": "Photo by Clark Van Der Beken on Unsplash\nIn this assignment we’ll look at traffic accidents in Edinburgh. The data are made available online by the UK Government. It covers all recorded accidents in Edinburgh in 2018 and some of the variables were modified for the purposes of this assignment."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#warm-up",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#warm-up",
    "title": "HW 03 - Road traffic accidents",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#packages",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#packages",
    "title": "HW 03 - Road traffic accidents",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#data",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#data",
    "title": "HW 03 - Road traffic accidents",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called accidents. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?accidents in the Console or using the Help menu in RStudio to search for accidents. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "Photo by Marleena Garris on Unsplash\nThe first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#warm-up",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#warm-up",
    "title": "HW 04 - What should I major in?",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#packages",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#packages",
    "title": "HW 04 - What should I major in?",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, the scales package for better formatting of labels on visualizations, and the data lives in the fivethirtyeight package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#data",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#data",
    "title": "HW 04 - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found in the fivethirtyeight package, and it’s called college_recent_grads. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?college_recent_grads in the Console or using the Help menu in RStudio to search for college_recent_grads. You can also find this information here.\nYou can also take a quick peek at your data frame and view its dimensions with the glimpse function.\n\nglimpse(college_recent_grads)\n\nThe college_recent_grads data frame is a trove of information. Let’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all we need to do is sort the data. We use the arrange function to do this, and sort it by the unemployment_rate variable. By default arrange sorts in ascending order, which is what we want here – we’re interested in the major with the lowest unemployment rate.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate)\n\nThis gives us what we wanted, but not in an ideal form. First, the name of the major barely fits on the page. Second, some of the variables are not that useful (e.g. major_code, major_category) and some we might want front and center are not easily viewed (e.g. unemployment_rate).\nWe can use the select function to choose which variables to display, and in which order:\nNote how easily we expanded our code with adding another step to our pipeline, with the pipe operator: %>%.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate) %>%\n  select(rank, major, unemployment_rate)\n\nOk, this is looking better, but do we really need to display all those decimal places in the unemployment variable? Not really!\nWe can use the percent() function to clean up the display a bit.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate) %>%\n  select(rank, major, unemployment_rate) %>%\n  mutate(unemployment_rate = percent(unemployment_rate))"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\nThe desc function specifies that we want unemployment_rate in descending order.\n\ncollege_recent_grads %>%\n  arrange(desc(unemployment_rate)) %>%\n  select(rank, major, unemployment_rate)\n\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding slice_max() at the end of the pipeline."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW 04 - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: Wikipedia\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nWe use the ggplot() function to do this. The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the aesthetic elements of the plot.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram()\n\nAlong with the plot, we get a message:\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nThis is telling us that we might want to reconsider the binwidth we chose for our histogram – or more accurately, the binwidth we didn’t specify. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\n\nWe can also calculate summary statistics for this distribution using the summarise function:\n\ncollege_recent_grads %>%\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.\n\n\ncollege_recent_grads %>%\n  group_by(major_category) %>%\n  summarise(___ = ___(median)) %>%\n  arrange(___)\n\n\nWhich major category is the least popular in this sample? To answer this question we use a new function called count, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.\n\n\ncollege_recent_grads %>%\n  count(major_category)\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "title": "HW 04 - What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads <- college_recent_grads %>%\n  mutate(major_type = ifelse(major_category %in% stem_categories, \"stem\", \"not stem\"))\n\nLet’s unpack this: with mutate we create a new variable called major_type, which is defined as \"stem\" if the major_category is in the vector called stem_categories we created earlier, and as \"not stem\" otherwise.\n%in% is a logical operator. Other logical operators that are commonly used are\n\n\n\nOperator\nOperation\n\n\n\n\nx < y\nless than\n\n\nx > y\ngreater than\n\n\nx <= y\nless than or equal to\n\n\nx >= y\ngreater than or equal to\n\n\nx != y\nnot equal to\n\n\nx == y\nequal to\n\n\nx %in% y\ncontains\n\n\nx | y\nor\n\n\nx & y\nand\n\n\n!x\nnot\n\n\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads %>%\n  filter(\n    major_type == \"stem\",\n    median < 36000\n  )\n\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW 04 - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#further-exploration",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#further-exploration",
    "title": "HW 04 - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s).\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "Photo by Madeleine Kohler on Unsplash\nOnce upon a time, people travelled all over the world, and some stayed in hotels and others chose to stay in other people’s houses that they booked through Airbnb. Recent developments in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed. Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighbourhood."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#warm-up",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#warm-up",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#packages",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#packages",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#data",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#data",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called edibnb. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package.\nYou can view the dataset as a spreadsheet using the View() function. Note that you should not put this function in your R Markdown document, but instead type it directly in the Console, as it pops open a new window (and the concept of popping open a window in a static document doesn’t really make sense…). When you run this in the console, you’ll see the following data viewer window pop up.\n\nView(edibnb)\n\nYou can find out more about the dataset by inspecting its documentation, which you can access by running ?edibnb in the Console or using the Help menu in RStudio to search for edibnb. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "Photo by Jovana Askrabic on Unsplash\nThe goal of this assignment is to introduce you to R, RStudio, Git, and GitHub, which you’ll be using throughout the course both to learn the data science concepts discussed in the course and to analyze real data and come to informed conclusions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#prerequisites",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#prerequisites",
    "title": "HW 01 - Pet names",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis assignment assumes that you have reviewed the lectures titled “Meet the toolkit: Programming” and “Meet the toolkit: version control and collaboration”. If you haven’t yet done so, please pause and complete the following before continuing."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#terminology",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#terminology",
    "title": "HW 01 - Pet names",
    "section": "Terminology",
    "text": "Terminology\nWe’ve already thrown around a few new terms, so let’s define them before we proceed.\n\nR: Name of the programming language we will be using throughout the course.\nRStudio: An integrated development environment for R. In other words, a convenient interface for writing and running R code.\nGit: A version control system.\nGitHub: A web platform for hosting version controlled files and facilitating collaboration among users.\nRepository: A Git repository contains all of your project’s files and stores each file’s revision history. It’s common to refer to a repository as a repo.\n\nIn this course, each assignment you work on will be contained in a Git repo.\nFor individual assignments, only you will have access to the repo. For team assignments, all team members will have access to a single repo where they work collaboratively.\nAll repos associated with this course are housed in the course GitHub organization. The organization is set up such that students can only see repos they have access to, but the course staff can see all of them."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#starting-slow",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#starting-slow",
    "title": "HW 01 - Pet names",
    "section": "Starting slow",
    "text": "Starting slow\nAs the course progresses, you are encouraged to explore beyond what the assignments dictate; a willingness to experiment will make you a much better programmer! Before we get to that stage, however, you need to build some basic fluency in R. First, we will explore the fundamental building blocks of all of these tools.\nBefore you can get started with the analysis, you need to make sure you:\n\nhave a GitHub account\nare a member of the course GitHub organization\ncan log into the on campus RStudio Server (link on course webpage)\n\nIf you failed to confirm any of these, it means you have not yet completed the prerequisites for this assignment. Please go back to Prerequisites and complete them before continuing the assignment."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "title": "HW 01 - Pet names",
    "section": "Step 1. Update the YAML",
    "text": "Step 1. Update the YAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-2-commit",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-2-commit",
    "title": "HW 01 - Pet names",
    "section": "Step 2: Commit",
    "text": "Step 2: Commit\nThen Go to the Git pane in your RStudio.\nYou should see that your Rmd (R Markdown) file and its output, your md file (Markdown), are listed there as recently changed files.\nNext, click on Diff. This will pop open a new window that shows you the difference between the last committed state of the document and its current state that includes your changes. If you’re happy with these changes, click on the checkboxes of all files in the list, and type “Update author name” in the Commit message box and hit Commit.\n\n\n\n\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-3.-push",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-3.-push",
    "title": "HW 01 - Pet names",
    "section": "Step 3. Push",
    "text": "Step 3. Push\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean your instructor or group. In order to push your changes to GitHub, click on Push.\n\n\n\n\n\nThis will prompt a dialogue box where you first need to enter your user name, and then your PAT. This might feel cumbersome.But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it.\nThought exercise: Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?1"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "Photo by Viktor Kern on Unsplash\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\nSource: UCI Machine Learning Repository - Bike Sharing Dataset"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#packages",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#packages",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called dcbikeshare. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?dcbikeshare in the Console or using the Help menu in RStudio to search for dcbikeshare. You can also find this information here.\nThe data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days. The original data sources are http://capitalbikeshare.com/system-data and http://www.freemeteo.com."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nRecode the season variable to be a factor with meaningful level names as outlined in the codebook, with spring as the baseline level.\nRecode the binary variables holiday and workingday to be factors with levels no (0) and yes (1), with no as the baseline level.\nRecode the yr variable to be a factor with levels 2011 and 2012, with 2011 as the baseline level.\nRecode the weathersit variable as 1 - clear, 2 - mist, 3 - light precipitation, and 4 - heavy precipitation, with clear as the baseline.\nCalculate raw temperature, feeling temperature, humidity, and windspeed as their values given in the dataset multiplied by the maximum raw values stated in the codebook for each variable. Instead of writing over the existing variables, create new ones with concise but informative names.\nCheck that the sum of casual and registered adds up to cnt for each record. Hint: One way of doing this is to create a new column that takes on the value TRUE if they add up and FALSE if not, and then checking if all values in that column are TRUEs. But this is only one way, you might come up with another.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nRecreate the following visualization, and interpret it in context of the data. Hint: You will need to use one of the variables you created above. The temperature plotted is the feeling temperature.\n\n\n\n\n\n\n\nCreate a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Modelling",
    "text": "Modelling\n\nFit a linear model predicting total daily bike rentals from daily temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\). Note: We should check model conditions before using a model.\nFit another linear model predicting total daily bike rentals from daily feeling temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\). Is temperature or feeling temperature a better predictor of bike rentals? Explain your reasoning. Note: We should check model conditions before using a model.\nFit a model predicting total daily bike rentals from season, year, whether the day is holiday or not, whether the day is a workingday or not, the weather category, temperature, feeling temperature, humidity, and windspeed. Interpret the \\(R^2\\) of the model. Note: We should check model conditions before using a model.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "Photo by Daniel Cheung on Unsplash\nThis week we’ll do some data gymnastics to refresh and review what we learned over the past few weeks using (simulated) data from Lego sales in 2018 for a sample of customers who bought Legos in the US."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#warm-up",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#warm-up",
    "title": "HW 05 - Legos",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#packages",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#packages",
    "title": "HW 05 - Legos",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#data",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#data",
    "title": "HW 05 - Legos",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called lego_sales. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?lego_sales in the Console or using the Help menu in RStudio to search for lego_sales. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html",
    "title": "HW 10 - Wrap up!",
    "section": "",
    "text": "Photo by Kari Shea on Unsplash\nIt’s almost time to wrap up the course! In this three part assignment you get to practice what we learned this week, try something new, and get creative!"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#warm-up",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#warm-up",
    "title": "HW 10 - Wrap up!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#packages",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#packages",
    "title": "HW 10 - Wrap up!",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for the first part of this assignment. For the second part you get to choose which package to use.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "title": "HW 10 - Wrap up!",
    "section": "Part 1 - Mirror, mirror on the wall, who’s the ugliest of them all?",
    "text": "Part 1 - Mirror, mirror on the wall, who’s the ugliest of them all?\nHere is a simple plot using the mpg dataset, which contains information on fuel economy of cars. We’re plotting highway miles per gallon vs. city miles per gallon, coloured by whether the car is front-wheel drive, rear wheel drive, or four-wheel drive.\n\nggplot(data = mpg, aes(x = cty, y = hwy, color = drv)) +\n  geom_point()\n\nI realize that “ugly” is subjective, so we’re mostly looking to see if you can figure out how to change the look of a plot using help files of functions you haven’t learned before.\n\nMake this plot as ugly as possible by changing colours, background color, fonts, or anything else you can think of. You will probably want to play around with theme options, but you can do more. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "title": "HW 10 - Wrap up!",
    "section": "Part 2 - You gotta pick a package or two",
    "text": "Part 2 - You gotta pick a package or two\nBut really, one is enough. Pick a package from the list below, and use it to do something. If you want to use a package not on this list, that’s also ok, but it needs to be a package we haven’t used in class. If you start with a package and are struggling to get it to work, ask for help on Piazza or just move to another one.\nRemember: You install the package in the Console, not in the R Markdown document since you don’t want to keep reinstalling it every time you knit the document.\nYour task is to install the package you pick. Depending on where the package comes from, how you install the package differs:\n\nIf the package is on CRAN (Comprehensive R Archive Network), you can install it with install.packages.\nIf the package is only on Github (most likely because it is still under development), you need to use the install_github function.\n\nThen, load the package. Regardless of how you installed the package you can load it with the library function.\nFinally, do something with the package. It doesn’t have to be complicated. In fact, keep it simple. The goal is for you to read and understand the package documentation to carry out a simple task.\nNote: For the output generated by some of these packages to show up properly, you might need to change the output of your R Markdown document from github_document to html_document in the YAML of your R Markdown document.\n\nWhich package are you using? State the name of the package, whether it was on CRAN or GitHub, and include the code for loading it. Also include a one sentence description of what the package does.Then, do something with the package and provide a brief narrative including code and output. Also comment on difficulties you had, if any, figuring out how to use the package.\n\n\nPackages on CRAN\nThese packages can be installed with:\n\ninstall.packages(\"PACKAGENAME\")\n\n\n\n\nPackage\nDescription\n\n\n\n\ncowsay\nAllows printing of character strings as messages/warnings/etc. with ASCII animals, including cats, cows, frogs, chickens, ghosts, and more\n\n\nbabynames\nUS Baby Names 1880-2015\n\n\ndragracer\nThese are data sets for the hit TV show, RuPaul’s Drag Race. Data right now include episode-level data, contestant-level data, and episode-contestant-level data\n\n\ndatapasta\nRStudio addins and R functions that make copy-pasting vectors and tables to text painless\n\n\nDiagrammeR\nGraph/Network Visualization\n\n\njaneaustenr\nFull texts for Jane Austen’s 6 completed novels, ready for text analysis. These novels are “Sense and Sensibility”, “Pride and Prejudice”, “Mansfield Park”, “Emma”, “Northanger Abbey”, and “Persuasion”\n\n\nggimage\nSupports image files and graphic objects to be visualized in ‘ggplot2’ graphic system\n\n\ngganimate\nCreate easy animations with ggplot2\n\n\ngt\nEasily Create Presentation-Ready Display Tables\n\n\nleaflet\nCreate Interactive Web Maps with the JavaScript ‘Leaflet’ Library\n\n\npraise\nBuild friendly R packages that praise their users if they have done something good, or they just need it to feel better\n\n\nplotly\nCreate interactive web graphics from ggplot2 graphs and/or a custom interface to the JavaScript library plotly.js inspired by the grammar of graphics\n\n\nsuncalc\nR interface to suncalc.js library, part of the SunCalc.net project, for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), moon position and lunar phase for the given location and time\n\n\nschrute\nThe complete scripts from the American version of the Office television show in tibble format\n\n\nstatebins\nThe cartogram heatmaps generated by the included methods are an alternative to choropleth maps for the United States and are based on work by the Washington Post graphics department in their report on “The states most threatened by trade”\n\n\nttbbeer\nAn R data package of beer statistics from U.S. Department of the Treasury, Alcohol and Tobacco Tax and Trade Bureau (TTB)\n\n\nukbabynames\nFull listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994\n\n\n\n\n\nPackages on GitHub only\nThese packages can be installed with:\n\nlibrary(devtools)\ninstall_github(\"USERNAME/PACKAGENAME\")\n\nUSERNAME refers to the user name of the developer of the package. For example, for the first package listed below, USERNAME is hadley and PACKAGENAME is emo.\n\n\n\nPackage\nDescription\n\n\n\n\nbingo\nGenerate Bingo cards\n\n\nBRRR\nBRRR extends the beepr package to include a number of rap adlibs\n\n\nCatterPlots\nPlots with Cats\n\n\ncooking\nChopping, peeling, frying, and cooking various ingredients, and combining them to a delicious ragout. Also includes buying them from a local supermarket\n\n\ndadjoke\nThe goal of dadjoke is to make you laugh in spite of yourself\n\n\nemo\nThe goal of emo(ji) is to make it very easy to insert emoji into RMarkdown documents\n\n\nemoGG\nUse Emoji in ggplot2\n\n\nemokid\nFor those times when you’re having trouble expressing how you feel about your broken code\n\n\nflametree\nThe goal of flametree is to make pretty pictures\n\n\nggbarf\nMake isotype bars using the vomit emoji\n\n\nggCyberPunk\nCreate Cyberpunk area and line plots\n\n\nggiraph\nCreate interactive ggplot2 graphics using htmlwidgets\n\n\nggkeyboard\nPlot a Keyboard Using ggplot2\n\n\njasmines\nMake generative art\n\n\nkandinsky\nTurn any dataset into a Kandinsky painting\n\n\nlego\nThis R data package contains information about every Lego set manufactured from 1970 to 2015, a total of 6172 sets\n\n\nlinkinpark\nData package that contains a few different datasets about the band\n\n\nprenoms\nFirst names given to babies in metropolitan France between 1900 and 2015\n\n\nraybonsai\nGenerate 3D procedural trees in R, rendered with rayrender! Procedural generation code based on the flametree package by Danielle Navarro.\n\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "Photo by Mauro Mora on Unsplash\nThe GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes. Hundreds of trends have been tracked since 1972. In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.\nThe GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.\nIn this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.1"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#warm-up",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#warm-up",
    "title": "HW 08 - Exploring the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#packages",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#packages",
    "title": "HW 08 - Exploring the GSS",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#data",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#data",
    "title": "HW 08 - Exploring the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 1: Harassment at work",
    "text": "Part 1: Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nWhat are the possible responses to this question and how many respondents chose each of these answers?\nWhat percent of the respondents for whom this question is applicable\n(i.e. excluding NAs and Does not applys) have been harassed by their superiors or co-workers at their job.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 2: Time spent on email",
    "text": "Part 2: Time spent on email\nThe 2016 GSS also asked respondents how many hours and minutes they spend on email weekly. The responses to these questions are recorded in the emailhr and emailmin variables. For example, if the response is 2.5 hrs, this would be recorded as emailhr = 2 and emailmin = 30.\n\nCreate a new variable called email that combines these two variables to reports the number of minutes the respondents spend on email weekly.\nVisualize the distribution of this new variable. Find the mean and the median number of minutes respondents spend on email weekly. Is the mean or the median a better measure of the typical among of time Americans spend on email weekly? Why?\nCreate another new variable, snap_insta that is coded as “Yes” if the respondent reported using any of Snapchat (snapchat) or Instagram (instagrm), and “No” if not. If the recorded value was NA for both of these questions, the value in your new variable should also be NA.\nCalculate the percentage of Yes’s for snap_insta among those who answered the question, i.e. excluding NAs.\nWhat are the possible responses to the question Last week were you working full time, part time, going to school, keeping house, or what? and how many respondents chose each of these answers? Note that this information is stored in the wrkstat variable.\nFit a model predicting email (number of minutes per week spent on email) from educ (number of years of education), wrkstat, and snap_insta. Interpret the slopes for each of these variables.\nCreate a predicted values vs. residuals plot for this model. Are there any issues with the model? If yes, describe them.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 3: Political views and science research",
    "text": "Part 3: Political views and science research\nThe 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (polviews) and whether they think science research is necessary and should be supported by the federal government (advfront).\n\nThe question on science research is worded as follows:\n\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nAnd possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don’t know, No answer, Not applicable.\n\nThe question on political views is worded as follows:\n\n\nWe hear a lot of talk these days about liberals and conservatives. I’m going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal–point 1–to extremely conservative–point 7. Where would you place yourself on this scale?\n\nNote: The levels of this variables are spelled inconsistently: “Extremely liberal” vs. “Extrmly conservative”. Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.\nAnd possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative. Responses that were originally Don’t know, No answer and Not applicable are already mapped to NAs upon data import.\n\nIn a new variable, recode advfront such that Strongly Agree and Agree are mapped to \"Yes\", and Disagree and Strongly disagree are mapped to \"No\". The remaining levels can be left as is. Don’t overwrite the existing advfront, instead pick a different, informative name for your new variable.\nIn a new variable, recode polviews such that Extremely liberal, Liberal, and Slightly liberal, are mapped to \"Liberal\", and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to \"Conservative\". The remaining levels can be left as is. Make sure that the levels are in a reasonable order. Don’t overwrite the existing polviews, instead pick a different, informative name for your new variable.\nCreate a visualization that displays the relationship between these two new variables and interpret it.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html",
    "title": "HW 06 - Money in US politics",
    "section": "",
    "text": "Photo by Sharon McCutcheon on Unsplash\nEvery election cycle brings its own brand of excitement – and lots of money. Political donations are of particular interest to political scientists and other researchers studying politics and voting patterns. They are also of interest to citizens who want to stay informed of how much money their candidates raise and where that money comes from.\nIn the United States, “only American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees.”1\nIn this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns. First, we will get data foreign connected PAC contributions in the 2022 election cycle. Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.\nIn order to complete this assignment you will need a Chrome browser with the Selector Gadget extension installed."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#warm-up",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#warm-up",
    "title": "HW 06 - Money in US politics",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#packages",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#packages",
    "title": "HW 06 - Money in US politics",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we’re allowed to scrape the data, the rvest package for data scraping, and the scales package for better formatting of labels on visualisations. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(robotstxt)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data",
    "title": "HW 06 - Money in US politics",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you’ll be scraping the data!"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "title": "HW 06 - Money in US politics",
    "section": "Data collection via web scraping",
    "text": "Data collection via web scraping\n\n\n\n\n\nThe data come from OpenSecrets.org, a “website tracking the influence of money on U.S. politics, and how that money affects policy and citizens’ lives”. This website is hosted by The Center for Responsive Politics, which is a nonpartisan, independent nonprofit that “tracks money in U.S. politics and its effect on elections and public policy.”2\nBefore getting started, let’s check that a bot has permissions to access pages on this domain.\n\nlibrary(robotstxt)\npaths_allowed(\"https://www.opensecrets.org\")\n\n[1] TRUE\n\n\nOur goal is to scrape data for contributions in all election years Open Secrets has data for. Since that means repeating a task many times, let’s first write a function that works on the first page. Confirm it works on a few others. Then iterate it over pages for all years.\n\nComplete the following set of steps in the scrape-pac.R file in the scripts folder of your repository. This file already contains some starter code to help you out.\n\n\nWrite a function called scrape_pac() that scrapes information from the Open Secrets webpage for foreign-connected PAC contributions in a given year. This function should\n\nhave one input: the URL of the webpage and should return a data frame.\nrename variables scraped, using snake_case naming.\nclean up the Country of Origin/Parent Company variable with str_squish().\nadd a new column to the data frame for year. We will want this information when we ultimately have data from all years, so this is a good time to keep track of it. Our function doesn’t take a year argument, but the year is embedded in the URL, so we can extract it out of there, and add it as a new column. Use the str_sub() function to extract the last 4 characters from the URL. You will probably want to look at the help for this function to figure out how to specify “last 4 characters”.\n\nDefine the URLs for 2022, 2020, and 2000 contributions. Then, test your function using these URLs as inputs. Does the function seem to do what you expected it to do?\nConstruct a vector called urls that contains the URLs for each webpage that contains information on foreign-connected PAC contributions for a given year.\nMap the scrape_pac() function over urls in a way that will result in a data frame called pac_all.\nWrite the data frame to a csv file called pac-all.csv in the data folder.\n\n✅⬆️ If you haven’t yet done so, now is definitely a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. “Data scraping complete”). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nComplete the following set of steps in the hw-06.Rmd file in your repository.\n\n\nIn your R Markdown file, load pac-all.csv and report its number of observations and variables using inline code."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "title": "HW 06 - Money in US politics",
    "section": "Data cleaning",
    "text": "Data cleaning\nIn this section we clean the pac_all data frame to prepare it for analysis and visualization. We have two goals in data cleaning:\n\nSeparate the country_parent into two such that country and parent company appear in different columns for country-level analysis.\nConvert contribution amounts in total, dems, and repubs from character strings to numeric values.\n\nThe following exercises walk you through how to make these fixes to the data.\n\nUse the separate() function to separate country_parent into country and parent columns. Note that country and parent company names are separated by \\ (which will need to be specified in your function) and also note that there are some entries where the \\ sign appears twice and in these cases we want to only split the value at the first occurrence of \\. This can be accomplished by setting the extra argument in to \"merge\" so that the cell is split into only 2 segments, e.g. we want \"Denmark/Novo Nordisk A/S\" to be split into \"Denmark\" and \"Novo Nordisk A/S\". (See help for separate() for more on this.) End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you).\nRemove the character strings including $ and , signs in the total, dems,and repubs columns and convert these columns to numeric. End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you). A couple hints to help you out:\n\nThe $ character is a special character so it will need to be escaped.\nSome contribution amounts are in the millions (e.g. Anheuser-Busch contributed a total of $1,510,897 in 2008). In this case we need to remove all occurrences of ,, which we can do by using str_remove_all() instead of str_remove().\n\n\n🧶 ✅ ⬆️ Now is a good time to knit your document, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "title": "HW 06 - Money in US politics",
    "section": "Data visualization and interpretation",
    "text": "Data visualization and interpretation\n\nCreate a line plot of total contributions from all foreign-connected PACs in the Canada and Mexico over the years. Once you have made the plot, write a brief interpretation of what the graph reveals. Few hints to help you out:\n\nFilter for only Canada and Mexico.\nCalculate sum of total contributions from PACs for each year for each country by using a sequence of group_by() then summarise().\nMake a plot of total contributions (y-axis) by year (x-axis) where two lines identified by different colours represent each of Canada and Mexico.\n\n\nNote: The figure you create might look slightly different than this one if the data on the website has been updated recently.\n\nRecreate the following visualisation. Once you have made the plot, write a brief interpretation of what the graph reveals. Note that these are only UK contributions. You will need to make use of functions from the scales package for axis labels as well as from ggplot2.\n\n\n\n\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "href": "course-materials/starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "href": "course-materials/starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html",
    "href": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "library(tidyverse) \n\n\nnobel <- read_csv(\"data/nobel.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "href": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "title": "Lab 03 - Nobel laureates",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…"
  },
  {
    "objectID": "course-materials/starters/lab/lab-06-sad-plots/lab-06.html",
    "href": "course-materials/starters/lab/lab-06-sad-plots/lab-06.html",
    "title": "Lab 06 - Sad plots",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-10-slr-course-evals/lab-10.html",
    "href": "course-materials/starters/lab/lab-10-slr-course-evals/lab-10.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html",
    "title": "Lab 01 - Hello R",
    "section": "",
    "text": "library(tidyverse) \nlibrary(datasauRus)\nlibrary(usethis)"
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "title": "Lab 01 - Hello R",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nThe answers for this Exercise are given for you below. But you should clean up some of the narrative so that it only includes what you want to turn in.\nFirst let’s plot the data in the dino dataset:\n\ndino_data <- datasaurus_dozen %>%\n  filter(dataset == \"dino\")\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\nAnd next calculate the correlation between x and y in this dataset:\n\ndino_data %>%\n  summarize(r = cor(x, y))\n\n# A tibble: 1 × 1\n        r\n    <dbl>\n1 -0.0645\n\n\n\n\nExercise 3\nAdd code and narrative as needed. Note that the R chunks are labelled with plot-star and cor-star to provide spaces to place the code for plotting and calculating the correlation coefficient. To finish, clean up the narrative by removing these instructions.\nBlah blah blah…\n\n\n\nI’m some text, you should replace me with more meaningful text…\n\n\n\n\n\nExercise 4\nAdd code and narrative as needed. Note that two R chunks are given but they are not labeled. Use the convention from above to name them appropriately.\n\n\n\n\n\n\n\n\nExercise 5\nAdd code and narrative as needed. To add R chunks either type out the backticks, curly braces, and the letter r or use the Insert chunk button above, green C+."
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html",
    "title": "Lab 02 - Plastic waste",
    "section": "",
    "text": "library(tidyverse) \n\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "title": "Lab 02 - Plastic waste",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n# insert code here\n\n\n\nExercise 2\n\n# insert code here\n\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# insert code here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# insert code here\n\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here.\n\n# insert code here\n\n\n\nExercise 7\nRemove this text, and add your answer for Exercise 7 here.\n\n# insert code here\n\n\n# insert code here\n\n\n\nExercise 8\nRemove this text, and add your answer for Exercise 8 here.\n\n# insert code here"
  },
  {
    "objectID": "course-materials/starters/lab/lab-04-viz-sp-data/lab-04.html",
    "href": "course-materials/starters/lab/lab-04-viz-sp-data/lab-04.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-09-better-viz/lab-09.html",
    "href": "course-materials/starters/lab/lab-09-better-viz/lab-09.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-08-uoe-art/lab-08.html",
    "href": "course-materials/starters/lab/lab-08-uoe-art/lab-08.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "Exercise 9\n\nuoe_art <- uoe_art %>%\n  separate(title, into = c(\"title\", \"date\"), sep = \"\\\\(\") %>%\n  mutate(year = str_remove(date, \"\\\\)\") %>% as.numeric()) %>%\n  select(title, artist, year, ___)\n\nError: <text>:4:32: unexpected input\n3:   mutate(year = str_remove(date, \"\\\\)\") %>% as.numeric()) %>%\n4:   select(title, artist, year, __\n                                  ^\n\n\n\n\nExercise 10\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 11\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html",
    "href": "course-materials/starters/project/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#introduction",
    "href": "course-materials/starters/project/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#data",
    "href": "course-materials/starters/project/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#data-analysis-plan",
    "href": "course-materials/starters/project/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html",
    "href": "course-materials/starters/project/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "course-materials/starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html#plot-and-text",
    "href": "course-materials/starters/project/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[\n\n\n\n\n\n]"
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html",
    "title": "HW 06 - Money in politics",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "title": "HW 06 - Money in politics",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "title": "HW 08 - Exploring the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# remove this comment and add the code for Exercise 5 here"
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "title": "HW 04 - What should I major in?",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html#exercises",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html#exercises",
    "title": "HW 05 - Legos",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html",
    "title": "HW 10 - Wrap up",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "title": "HW 10 - Wrap up",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels."
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "title": "HW 01 - Pet names",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nThere are ___ pets in the dataset.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\nseattlepets %>%\n  count(animal_name, sort = TRUE)\n\n# A tibble: 13,930 × 2\n   animal_name     n\n   <chr>       <int>\n 1 <NA>          483\n 2 Lucy          439\n 3 Charlie       387\n 4 Luna          355\n 5 Bella         331\n 6 Max           270\n 7 Daisy         261\n 8 Molly         240\n 9 Jack          232\n10 Lily          232\n# … with 13,920 more rows\n\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here."
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-traffic-accident/hw-03.html",
    "href": "course-materials/starters/hw/hw-03-traffic-accident/hw-03.html",
    "title": "HW 03 - Road traffic accidents",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-traffic-accident/hw-03.html#exercises",
    "href": "course-materials/starters/hw/hw-03-traffic-accident/hw-03.html#exercises",
    "title": "HW 03 - Road traffic accidents",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here"
  },
  {
    "objectID": "supplement.html",
    "href": "supplement.html",
    "title": "Supplementary Documents",
    "section": "",
    "text": "Virtual poster\nPoster"
  },
  {
    "objectID": "computing-troubleshooting_depr.html",
    "href": "computing-troubleshooting_depr.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They’ll be able to help diagnose the issue."
  }
]