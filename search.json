[
  {
    "objectID": "course-faq_in_dev.html",
    "href": "course-faq_in_dev.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export‚Ä¶ If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you‚Äôve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder)."
  },
  {
    "objectID": "course-faq_in_dev.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq_in_dev.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you‚Äôll upload your PDF and them mark the page(s) where each question can be found. It‚Äôs OK if a question spans multiple pages, just mark them all. It‚Äôs also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq_in_dev.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq_in_dev.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I‚Äôd rather you didn‚Äôt, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we‚Äôre using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you‚Äôre working in the containers we have provided for you. If you‚Äôre working on your local setup, we can‚Äôt guarantee being able to resolve your issues, though we‚Äôre happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.1.2: https://cran.r-project.org/\nDownload and install a daily build of RStudio: https://dailies.rstudio.com/\nInstall Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I‚Äôd like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group‚Äôs interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team‚Äôs project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you‚Äôre interested in potentially using for the final project. If you‚Äôre unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you‚Äôre interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as ‚Äúname‚Äù, ‚Äúsocial security number‚Äù, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g.¬†‚Äústate abbreviation‚Äù and ‚Äústate name‚Äù), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you‚Äôre unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you‚Äôre interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you‚Äôre investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others‚Äô work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams‚Äôs projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams‚Äô GitHub repos. Provide your review in the form of GitHub issues to your partner team‚Äôs GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team‚Äôs report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team‚Äôs project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team‚Äôs repo.\nOpen the repo of the team you‚Äôre reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model‚Äôs predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you‚Äôll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the ‚Äú+‚Äù and select ‚ÄúUpload files‚Äù.\nLocate the video on your computer and click to upload.\nOnce you‚Äôve uploaded the video to Warpwire, click to share the video and copy the video‚Äôs URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick ‚ÄúStart a new conversation‚Äù.\nMake the title ‚ÄúYour Team Name: Project Title‚Äù. For example, ‚ÄúTeaching Team: Our Awesome Presentation‚Äù.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click ‚ÄúInsert 1 item.‚Äù This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou‚Äôre done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group‚Äôs video, then click ‚ÄúReply‚Äù to post a question for the group. You may not post a question that‚Äôs already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e.¬†it shouldn‚Äôt be ‚ÄúWhy did you use a bar plot instead of a pie chart‚Äù?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group‚Äôs specific presentation, i.e demonstrating that you‚Äôve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "course-instructor.html",
    "href": "course-instructor.html",
    "title": "Instructor",
    "section": "",
    "text": "Dr.¬†Tyler George (her/him) is a Assistant Professor of Statistics at Cornell College. He received his PhD in Statistics and Analytics at Central Michigan University. During his PhD I he also studied mathematics and statistics education. His dissertation work involved creating a new lack of fit test for linear regression models. His interests are broadly in statistics, data science and best pedagogy to teach them.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMonday - Friday 3:05 am - 4:05 am\nWest 311\n\n\nOther Times by Appointment\nWest\n\n\n\nOffice hours are for STUDENTS. Please take advantage of them to get help with class, advising, and/or getting to know your professor!"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nYou are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first few days of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of your professors office hours here."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\n\nQuantitative Reasoning Studio (QRS)\nThere are times you may need help outside of class or office hours. Or, maybe you need something explained in a different way. In those instances, I encourage you to visit the Quantitative Reasoning Studio in Cole Library room 322. The Quantitative Reasoning Studio (QRS) offers free tutoring to all students at Cornell College. There will be at least 1 peer tutor that has taken this course and will be able to help you, if you arrive at a time they are working. Feel free to email Jessica Johanningmeier at QRS@cornellcollege.edu to ask when the tutor for this class will be available. They often will have a schedule posted on the wall in the studio.\n\n\nQRS Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n3 p.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\n\n\n\nDungy Writing Studio\nFor help with your writing, visit the Dungy Writing Studio. You can make online appointments individual or groups to get help with items such as your group project. If you have any questions about the studio, email Dungy Writing Studio Director and Director of Fellowships and Scholarships, Laura Farmer, at lfarmer@cornellcollege.edu.\n\n\nWriting Studio Hours\n\n\n\nDay(s)\nTimes\n\n\n\n\nMonday-Thursday\n8 a.m. - 5 p.m. and 7 p.m. - 10 p.m.\n\n\nFriday\n8 a.m. - 5 p.m.\n\n\nSunday\n1 p.m. - 5 p.m."
  },
  {
    "objectID": "course-support.html#student-success-center",
    "href": "course-support.html#student-success-center",
    "title": "Course support",
    "section": "Student Success Center",
    "text": "Student Success Center\nThe Student Success Center is a resource for all students. Their staff serves as student success coaches for all students and welcome students to visit us to talk about academic concerns, study plans, finding their place at Cornell, or any questions you have and aren‚Äôt sure where to start! You can walk in to chat or contact a staff member directly to set up an appointment! See the website for more information."
  },
  {
    "objectID": "course-support.html#professor-email",
    "href": "course-support.html#professor-email",
    "title": "Course support",
    "section": "Professor Email",
    "text": "Professor Email\nIf you are not available during office hours times or have a questions later in the evening or other times outside of class, email your professor at tgeorge@cornellcollege.edu. If your question involves code - it is very likely you will need to meet with him to get help. Please reach out with any concerns you have during the course!"
  },
  {
    "objectID": "course-support.html#ebersole-health-and-wellbeing-center",
    "href": "course-support.html#ebersole-health-and-wellbeing-center",
    "title": "Course support",
    "section": "Ebersole Health and Wellbeing Center",
    "text": "Ebersole Health and Wellbeing Center\nThe mission of Cornell College Student Health Services complements the mission of the college by promoting the optimal well-being of students. We do this by:\n\nproviding and coordinating quality health care services\nadvocating for students in their pursuit of health and wellness\npreparing students to be their own health advocates and informed consumers of appropriate health care services\nproviding health education to promote the development of healthy lifestyles\n\nThe Student Health Center is located in the Ebersole Building, directly south of the Thomas Commons. Appointments are preferred. You can schedule an appointment online or by phone at 319-895-4292. Walk-ins will be accommodated as time permits. Appointments with the nurse are free."
  },
  {
    "objectID": "course-support.html#technology-support",
    "href": "course-support.html#technology-support",
    "title": "Course support",
    "section": "Technology Support",
    "text": "Technology Support\nIf you have issues with your computer during the block, IT may be able to help. Please submit a ticket."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSC 223: Introduction to Data Science",
    "section": "",
    "text": "Day\nDate\nTopic\nSlides\nAE\nLab\nHW\nExam\nProject\n\n\n\n\n1\nMon, Sep 26\nWelcome and Toolkit & Data Viz\nüñ•Ô∏èüñ•Ô∏èüñ•Ô∏è\nüìãüìãüìã\nüíª\nüìñChapter 2 R4ds & üìñ Sec 1.1,1.2 IMS & ‚úçÔ∏è\n\n\n\n\n2\nTue, Sep 27\nTidy Data & Data wrangling & Data Frame\n\n\n\n\n\n\n\n\n3\nWed, Sep 28\nNo afternoon class.\n\n\n\n\n\n\n\n\n4\nThu, Sep 29\nData types and classes\n\n\n\n\n\n\n\n\n5\nFri, Sep 30\n\n\n\n\n\n‚úÖ\nüìÇ\n\n\n6\nMon, Oct 3\n\n\n\n\n\n\n\n\n\n7\nTue, Oct 4\n\n\n\n\n\n\n\n\n\n8\nWed, Oct 5\n\n\n\n\n\n\n\n\n\n9\nThu, Oct 6\n\n\n\n\n\n\n\n\n\n10\nFri, Oct 7\n\n\n\n\n\n\nüìÇ\n\n\n11\nMon, Oct 10\n\n\n\n\n\n\n\n\n\n12\nTues, Oct 11\n\n\n\n\n\n\n\n\n\n13\nWed, Oct 12\n\n\n\n\n\n\n\n\n\n14\nThu, Oct 13\n\n\n\n\n\n\n\n\n\n15\nFri, Oct 14\n\n\n\n\n\n\nüìÇ\n\n\n16\nMon, Oct 17\n\n\n\n\n\n\n\n\n\n17\nTue, Oct 18\n\n\n\n\n\n\nüìÇ\n\n\n18\nWed, Oct 19\nFinal Exam\n\n\n\n\n‚úÖ"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio Server\nüîó on Cornell College Cluster\n\n\nCourse GitHub organization\nüîó on GitHub\n\n\nGradebook\nüîó on Moodle"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "Your account will be pre-created before the class begins and will use your Cornell College username. The default password will be shared in class and you will need to change it."
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(palmerpenguins)\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.3.6      ‚úî purrr   0.3.4 \n‚úî tibble  3.1.8      ‚úî dplyr   1.0.10\n‚úî tidyr   1.2.1      ‚úî stringr 1.4.1 \n‚úî readr   2.1.2      ‚úî forcats 0.5.2 \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 1.0.0 ‚îÄ‚îÄ\n‚úî broom        1.0.1     ‚úî rsample      1.1.0\n‚úî dials        1.0.0     ‚úî tune         1.0.0\n‚úî infer        1.0.3     ‚úî workflows    1.0.0\n‚úî modeldata    1.0.1     ‚úî workflowsets 1.0.0\n‚úî parsnip      1.0.1     ‚úî yardstick    1.1.0\n‚úî recipes      1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\n‚úñ scales::discard() masks purrr::discard()\n‚úñ dplyr::filter()   masks stats::filter()\n‚úñ recipes::fixed()  masks stringr::fixed()\n‚úñ dplyr::lag()      masks stats::lag()\n‚úñ yardstick::spec() masks readr::spec()\n‚úñ recipes::step()   masks stats::step()\n‚Ä¢ Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(knitr)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\n# A tibble: 2 √ó 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\nFormat model output as table:\n\ntidy(penguins_fit) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5780.831\n305.815\n-18.903\n0\n\n\nflipper_length_mm\n49.686\n1.518\n32.722\n0\n\n\n\n\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n# A tibble: 342 √ó 9\n   .rownames body_mass_g flippe‚Ä¶¬π .fitted  .resid    .hat .sigma .cooksd .std.‚Ä¶¬≤\n   <chr>           <int>    <int>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>   <dbl>\n 1 1                3750      181   3212.  538.   0.00881   394. 8.34e-3  1.37  \n 2 2                3800      186   3461.  339.   0.00622   394. 2.33e-3  0.863 \n 3 3                3250      195   3908. -658.   0.00344   393. 4.83e-3 -1.67  \n 4 5                3450      193   3808. -358.   0.00385   394. 1.60e-3 -0.911 \n 5 6                3650      190   3659.   -9.43 0.00469   395. 1.35e-6 -0.0240\n 6 7                3625      181   3212.  413.   0.00881   394. 4.91e-3  1.05  \n 7 8                4675      195   3908.  767.   0.00344   393. 6.56e-3  1.95  \n 8 9                3475      193   3808. -333.   0.00385   394. 1.39e-3 -0.847 \n 9 10               4250      190   3659.  591.   0.00469   394. 5.31e-3  1.50  \n10 11               3300      186   3461. -161.   0.00622   395. 5.23e-4 -0.409 \n# ‚Ä¶ with 332 more rows, and abbreviated variable names ¬π‚Äãflipper_length_mm,\n#   ¬≤‚Äã.std.resid\n\n\n\n\nStatistical inference"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "DSC 223: Introduction to Data Science",
    "section": "",
    "text": "At the end of this course I would like you to be to use software‚Äôs including RStudio and GitHub to respect, explore, understand, and utilize data in a way that is replicable. This course supports the Educational Priorities and Outcomes of Cornell College with emphasis on knowledge, inquiry, reasoning, and communication, ethical behavior, citizenship, and vocation. Your emphasis on knowledge is in the skills you will learn and apply in various interdisciplinary fields. You will inquire when investigating data ‚Äì seeing patters or trends and exploring them to. Your reasoning skills are built and tested when making decisions based on the data and your own programmed visualizations and numerical summaries. Your group work in class and group project presentations will help you practice your communication of statistical analysis. When you make decisions about what data to work with, how to treat the data, and how to talk about your results in an ethical way you practice good ethical behavior. Some of our analysis‚Äô will be with data from institutions such as governments or organizations that have an influence on the public ‚Äì these types of analysis‚Äô can inform public policies and are our way, as data scientists, to practice citizenship. Lastly, you will learn about the field of data science and the types of knowledge and training that would be required to support your vocation as a data scientist."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "DSC 223 - Fall 2022 - Block 2 ",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the FULL syllabus."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nData Science in a Box by Mine √áetinkaya-Rundel\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine √áetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you‚Äôre welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that‚Äôs fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called ‚ÄúReferences‚Äù at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called ‚ÄúAppendix‚Äù.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you‚Äôre using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n‚ùå NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n‚úÖ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon‚Äôt use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n‚ùå There is a negative linear relationship between mpg and hp.\n‚úÖ There is a negative linear relationship between a car‚Äôs fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don‚Äôt assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the ‚Äúso what‚Äù: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e.¬†what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n‚ùå For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n‚úÖ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it‚Äôs from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "",
    "text": "Given below are two data visualizations that violate many data visualization best practices. Improve these visualizations using R and the tips for effective visualizations that we introduced in class. You should produce one visualization per dataset. Your visualization should be accompanied by a brief paragraph describing the choices you made in your improvement, specifically discussing what you didn‚Äôt like in the original plots and why, and how you addressed them in the visualization you created.\nOn the due date you will give a brief presentation describing one of your improved visualizations and the reasoning for the choices you made."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#warm-up",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#warm-up",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#packages",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#packages",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#data",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#data",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Data",
    "text": "Data\nThe datasets we‚Äôll use are called instructors and fisheries from the dsbox package. Since the datasets are distributed with the package, we don‚Äôt need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?instructors and ?fisheries in the Console or using the Help menu in RStudio to search for instructors or fisheries. You can also find this information here and here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Instructional staff employment trends",
    "text": "Instructional staff employment trends\nThe American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.\n\n\n\n\n\nLet‚Äôs start by loading the data used to create this plot.\n\nstaff <- read_csv(\"data/instructional-staff.csv\")\n\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n\n\n# A tibble: 5 √ó 12\n  facult‚Ä¶¬π `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007` `2009`\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Full-Ti‚Ä¶   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2   16.8\n2 Full-Ti‚Ä¶   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8      7.6\n3 Full-Ti‚Ä¶   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9   15.1\n4 Part-Ti‚Ä¶   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5   41.1\n5 Graduat‚Ä¶   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5   19.4\n# ‚Ä¶ with 1 more variable: `2011` <dbl>, and abbreviated variable name\n#   ¬π‚Äãfaculty_type\n\n\nIn order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year. In other words, we will convert the data from wide format to long format.\nBut before we do so, a thought exercise: How many rows will the long-format data have? It will have a row for each combination of year and faculty type. If there are 5 faculty types and 11 years of data, how many rows will we have?\nWe do the wide to long conversion using a new function: pivot_longer(). The animation below show how this function works, as well as its counterpart pivot_wider().\n\n\n\n\n\nThe function has the following arguments:\n\npivot_longer(data, cols, names_to = \"name\")\n\n\nThe first argument is data as usual.\nThe second argument, cols, is where you specify which columns to pivot into longer format ‚Äì in this case all columns except for the faculty_type\nThe third argument, names_to, is a string specifying the name of the column to create from the data stored in the column names of data ‚Äì in this case year\n\n\nstaff_long <- staff %>%\n  pivot_longer(cols = -faculty_type, names_to = \"year\") %>%\n  mutate(year = as.numeric(year))\n\nLet‚Äôs take a look at what the new longer data frame looks like.\n\nstaff_long\n\n# A tibble: 55 √ó 3\n   faculty_type               year value\n   <chr>                     <dbl> <dbl>\n 1 Full-Time Tenured Faculty  1975  29  \n 2 Full-Time Tenured Faculty  1989  27.6\n 3 Full-Time Tenured Faculty  1993  25  \n 4 Full-Time Tenured Faculty  1995  24.8\n 5 Full-Time Tenured Faculty  1999  21.8\n 6 Full-Time Tenured Faculty  2001  20.3\n 7 Full-Time Tenured Faculty  2003  19.3\n 8 Full-Time Tenured Faculty  2005  17.8\n 9 Full-Time Tenured Faculty  2007  17.2\n10 Full-Time Tenured Faculty  2009  16.8\n# ‚Ä¶ with 45 more rows\n\n\nAnd now let‚Äôs plot is as a line plot. A possible approach for creating a line plot where we color the lines by faculty type is the following:\n\nstaff_long %>%\n  ggplot(aes(x = year, y = value, color = faculty_type)) +\n  geom_line()\n\n\n\n\nBut note that this results in a message as well as an unexpected plot. The message is saying that there is only one observation for each faculty type year combination. We can fix this using the group aesthetic following.\n\nstaff_long %>%\n  ggplot(aes(x = year, y = value, group = faculty_type, color = faculty_type)) +\n  geom_line()\n\n\n\n\n\nInclude the line plot you made above in your report and make sure the figure width is large enough to make it legible. Also fix the title, axis labels, and legend label.\nSuppose the objective of this plot was to show that the proportion of part-time faculty have gone up over time compared to other instructional staff types. What changes would you propose making to this plot to tell this story and why.\nImplement the changes you proposed in the previous exercise.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#fisheries",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#fisheries",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Fisheries",
    "text": "Fisheries\nFisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries. This Wikipedia page lists fishery production of countries for 2016. For each country tonnage from capture and aquaculture are listed. Note that countries whose total harvest was less than 100,000 tons are not included in the visualization.\nA researcher shared with you the following visualization they created based on these data. üò≥\n\n\n\n\n\n\nCan you help them make improve it? First, brainstorm how you would improve it. Then create the improved visualization and write up the changes/decisions you made as bullet points. It‚Äôs ok if some of your improvements are aspirational, i.e.¬†you don‚Äôt know how to implement it, but you think it‚Äôs a good idea.\n\nLoad the data.\n\nfisheries <- read_csv(\"data/fisheries.csv\")\n\n\nCreate a new data visualisation for these data that implements the improvements you proposed in the previous exercise (or many of them as you can).\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 1",
    "section": "",
    "text": "Have you ever taken a road trip in the US and thought to yourself ‚ÄúI wonder what La Quinta means‚Äù. Well, the late comedian Mitch Hedberg thinks it‚Äôs Spanish for next to Denny‚Äôs.\nIf you‚Äôre not familiar with these two establishments, Denny‚Äôs is a casual diner chain that is open 24 hours and La Quinta Inn and Suites is a hotel chain.\nThese two establishments tend to be clustered together, or at least this observation is a joke made famous by Mitch Hedberg. In this lab we explore the validity of this joke and along the way learn some more data wrangling and tips for visualizing spatial data.\nThe inspiration for this lab comes from a blog post by John Reiser on his new jersey geographer blog. You can read that analysis here. Reiser‚Äôs blog post focuses on scraping data from Denny‚Äôs and La Quinta Inn and Suites websites using Python. In this lab we focus on visualization and analysis of these data. However note that the data scraping was also done in R, and we we will discuss web scraping using R later in the course. But for now we focus on the data that has already been scraped and tidied for you."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#warm-up",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#warm-up",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#packages",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#packages",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#data",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#data",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 1",
    "section": "Data",
    "text": "Data\nThe datasets we‚Äôll use are called dennys and laquinta from the dsbox package. Note that these data were scraped from here and here, respectively.\nSince the datasets are distributed with the package, we don‚Äôt need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here.\nTo help with our analysis we will also use a dataset on US states, which is located in your repository‚Äôs data folder.\n\nstates <- read_csv(\"data/states.csv\")\n\nEach observation in this dataset represents a state, including DC. Along with the name of the state we have the two-letter abbreviation and we have the geographic area of the state (in square miles)."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "In this lab our goal is to reconstruct and improve a data visualisation on COVID and mask wearing."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#warm-up",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#warm-up",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Warm up",
    "text": "Warm up\nLet‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#packages",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#packages",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#data",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#data",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Data",
    "text": "Data\nIn this lab you‚Äôll construct the dataset!"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html",
    "title": "Lab 01 - Hello R!",
    "section": "",
    "text": "R is the name of the programming language itself and RStudio is a convenient interface.\nThe main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\nAn additional goal is to introduce you to Git and GitHub, which is the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nAnd to make versioning simpler, this is a solo lab. Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel. In future labs you‚Äôll learn about collaborating on GitHub and produce a single lab report for your team."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#warm-up",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#warm-up",
    "title": "Lab 01 - Hello R!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises.\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for \"YAML Ain't Markup Language\". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\nYAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.\n\n\n\n\n\n\n\nCommitting changes\nGo to the Git pane in your RStudio (top right) and click on Commit. This will bring up a new menu.\n\n\n\n\n\nIf you have made changes to your Rmd file (which you just changed your name), you should see it list on of the left. Diff shows you the difference between the last committed state of the document and its current state that includes your changes. Look over the files in the box that say they have been change. If agree with these changes, you will need to check the box to the left of each changed file, and in this case, write ‚ÄúUpdate author name‚Äù in the Commit message box. Then click Commit. It is important that you always describe what changes were made since your last commit in that box. This is how people in your team know what you changed without having to review thousands of lines of code.\n\n\n\n\n\nYou don‚Äôt have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the block progresses we will let you make these decisions. Committing does not save your progress to the web.\n\n\nPushing changes\nNow that you have made an update and committed this change, it‚Äôs time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean whoever you are working with.\nIn order to push your changes to GitHub, click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password, then your PAT. This might feel cumbersome. Bear with me‚Ä¶ We will teach you how to save your password so you don‚Äôt have to enter it every time. But for this one assignment you‚Äôll have to manually enter each time you push in order to gain some experience with it."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#packages",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#packages",
    "title": "Lab 01 - Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with two more packages: datasauRus which contains the dataset we‚Äôll be using and tidyverse which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way. These packages are already installed for you. You can load the packages by running the following in the Console.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\nNote that the packages are also loaded with the same commands in your R Markdown document."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#data",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#data",
    "title": "Lab 01 - Hello R!",
    "section": "Data",
    "text": "Data\n\nIf it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone! Have you heard of a [baker's dozen](https://en.wikipedia.org/wiki/Dozen#Baker's_dozen)?\n\nThe data frame we will be working with today is called datasaurus_dozen and it‚Äôs in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable.\nTo find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, ‚ÄúBeauty in the classroom: instructors‚Äô pulchritude and putative pedagogical productivity‚Äù (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings. (Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. http://www.sciencedirect.com/science/article/pii/S0272775704001165.)\nIn this lab you will analyze the data from this study in order to learn what goes into a positive professor evaluation.\nThe data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors‚Äô physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#warm-up",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#warm-up",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nLet‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#packages",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#packages",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#data",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#data",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it‚Äôs called evals. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nVisualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.\nVisualize and describe the relationship between score and bty_avg.\n\n\n**Hint:** See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.\n\n\nRecreate the scatterplot from Exercise 2, but this time use\ngeom_jitter()? What does ‚Äújitter‚Äù mean? What was misleading about the initial scatterplot?\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a numerical predictor",
    "text": "Linear regression with a numerical predictor\n\nLinear model is in the form $\\hat{y} = b_0 + b_1 x$.\n\n\nLet‚Äôs see if the apparent trend in the plot is something more than natural variation. Fit a linear model called score_bty_fit to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.\nRecreate the scatterplot from Exercise 2, and add the regression line to this plot in orange colour, with shading for the uncertainty of the line turned off.\nInterpret the slope of the linear model in context of the data.\nInterpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.\nDetermine the \\(R^2\\) of the model and interpret it in context of the data.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a categorical predictor",
    "text": "Linear regression with a categorical predictor\n\nFit a new linear model called score_gender_fit to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.\nWhat is the equation of the line corresponding to male professors? What is it for female professors?\nFit a new linear model called score_rank_fit to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.\nCreate a new variable called rank_relevel where \"tenure track\" is the baseline level.\nFit a new linear model called score_rank_relevel_fit to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 12. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\nCreate another new variable called tenure_eligible that labels \"teaching\" faculty as \"no\" and labels \"tenure track\" and \"tenured\" faculty as \"yes\".\nFit a new linear model called score_tenure_eligible_fit to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in the previous exercise. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the professor evaluations data we modelled in the previous lab. In the last lab we modelled evaluation scores using a single predictor at a time. This time we will use multiple predictors to model evaluation scores.\nFor context, review the previous lab‚Äôs introduction before continuing on to the exercises."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nLet‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#packages",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#packages",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#data",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#data",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it‚Äôs called evals. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nFit a linear model (one you have fit before): score_bty_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nFit a linear model (one you have fit before): score_bty_gen_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\nInterpret the slopes and intercept of score_bty_gen_fit in context of the data.\nWhat percent of the variability in score is explained by the model score_bty_gen_fit.\nWhat is the equation of the line corresponding to just male professors?\nFor two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?\nHow does the relationship between beauty and evaluation score vary between male and female professors?\nHow do the adjusted \\(R^2\\) values of score_bty_gen_fit and score_bty_fit compare? What does this tell us about how useful gender is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.\nCompare the slopes of bty_avg under the two models (score_bty_fit and score_bty_gen_fit). Has the addition of gender to the model changed the parameter estimate (slope) for bty_avg?\nCreate a new model called score_bty_rank_fit with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "",
    "text": "A study of conducted in Whickham, England recorded participants‚Äô age, smoking status at baseline, and then 20 years later recorded their health outcome. In this lab we analyse the relationships between these variables, first two at a time, and then controlling for the third."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#warm-up",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#warm-up",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#packages",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#packages",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the mosaicData package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(mosaicData)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#data",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#data",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Data",
    "text": "Data\nThe dataset we‚Äôll use is called Whickham from the mosaicData package. You can find out more about the dataset by inspecting their documentation, which you can access by running ?Whickham in the Console or using the Help menu in RStudio to search for Whickham."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html",
    "title": "Lab 02 - Global plastic waste",
    "section": "",
    "text": "Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health. Our World in Data has a lot of great data at various levels including globally, per country, and over time. For this lab we focus on data from 2010.\nAdditionally, National Geographic ran a data visualization communication contest on plastic waste as seen here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#packages",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#packages",
    "title": "Lab 02 - Global plastic waste",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for this analysis. Run the following code in the Console to load this package.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#data",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#data",
    "title": "Lab 02 - Global plastic waste",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following.\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "",
    "text": "This week you‚Äôll continue working on your projects. The first half of the workshop is structured, and you can use the second half to make progress on your projects."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Opening an issue",
    "text": "Opening an issue\n\nGo to your project repo and open a new issue titled ‚ÄúPractice issue‚Äù.\nAdd the following text to the issue:\n\n\nThis is not a real issue. This is just some placeholder text.\n\nAnd the following is a bulleted to-do list:\n- [ ] Do this\n- [ ] Then that\n- [ ] And finally this\n\nHit preview to make sure the issue looks like the following:\n\n\n\n\n\n\n\nSubmit the issue.\nThen, assign the issue to one or few members of the team."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Working on the issue",
    "text": "Working on the issue\nAs you work on the issue you can check the boxes.\n\n\n\n\n\nNote that this will also show progress on the issue on the issue dashboard.\n\n\n\n\n\n\nCheck some of the boxes on your practice issue and confirm that you can see the progress result on the issue dashboard."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Closing the issue",
    "text": "Closing the issue\nOnce you‚Äôre done with an issue, you should close it. You can do this in one of two ways: on GitHub by clicking on Close issue or via a commit that directly addresses the issue. We‚Äôll practice the second one. If you preface your commits with ‚ÄúFixes‚Äù, ‚ÄúFixed‚Äù, ‚ÄúFix‚Äù, ‚ÄúCloses‚Äù, ‚ÄúClosed‚Äù, or ‚ÄúClose‚Äù, the issue will be closed when you push the changes to your repo.\n\nTake a note of the issue number, which will show up next to the issue title.\n\n\n\n\n\n\n\nGo to your project on RStudio and make a change. This can be something silly like adding a new line to the issue README. Then commit this change. In your commit message, use one of the special words listed above and reference the issue. For example, if the change I made was to add a new line to the README I would say something like the following:\n\n\nAdd a new line to the README, closes #2\n\n\n\n\n\n\nPush your changes and observe that the issue is now closed on GitHub. Click on the referenced commit to confirm that it was your last commit that closed the issue."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "",
    "text": "In 2004, the state of North Carolina released a large data set containing information on births recorded in this state. This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children. We will work with a random sample of observations from this data set."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#warm-up",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#warm-up",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Warm up",
    "text": "Warm up\nLet‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#packages",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#packages",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for inference, and the data lives in the openintro package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#data",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#data",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it‚Äôs called ncbirths. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?ncbirths in the Console or using the Help menu in RStudio to search for ncbirths. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weights",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weights",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weights",
    "text": "Baby weights\nA 1995 study suggests that average weight of Caucasian babies born in the US is 3,369 grams (7.43 pounds).1 In this dataset we only have information on mother‚Äôs race, so we will make the simplifying assumption that babies of Caucasian mothers are also Caucasian, i.e.¬†whitemom = \"white\".\nWe want to evaluate whether the average weight of Caucasian babies has changed since 1995.\nOur null hypothesis should state ‚Äúthere is nothing going on‚Äù, i.e.¬†no change since 1995: \\(H_0: \\mu = 7.43~pounds\\).\nOur alternative hypothesis should reflect the research question, i.e.¬†some change since 1995. Since the research question doesn‚Äôt state a direction for the change, we use a two sided alternative hypothesis: \\(H_A: \\mu \\ne 7.43~pounds\\).\n\nCreate a filtered data frame called ncbirths_white that contain data only from white mothers. Then, calculate the mean of the weights of their babies.\nAre the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.\n\nLet‚Äôs discuss how this test would work. Our goal is to simulate a null distribution of sample means that is centred at the null value of 7.43 pounds. In order to do so, we\n\ntake a bootstrap sample of from the original sample,\ncalculate this bootstrap sample‚Äôs mean,\nrepeat these two steps a large number of times to create a bootstrap distribution of means centred at the observed sample mean,\nshift this distribution to be centred at the null value by subtracting / adding X to all bootstrap mean (X = difference between mean of bootstrap distribution and null value), and\ncalculate the p-value as the proportion of bootstrap samples that yielded a sample mean at least as extreme as the observed sample mean.\n\n\nRun the appropriate hypothesis test, visualize the null distribution, calculate the p-value, and interpret the results in context of the data and the hypothesis test."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-smoking",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-smoking",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weight vs.¬†smoking",
    "text": "Baby weight vs.¬†smoking\nConsider the possible relationship between a mother‚Äôs smoking habit and the weight of her baby. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.\n\nMake side-by-side boxplots displaying the relationship between habit and weight. What does the plot highlight about the relationship between these two variables?\nBefore moving forward, save a version of the dataset omitting observations where there are NAs for habit. You can call this version ncbirths_habitgiven.\n\nThe box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to first group the data by the habit variable, and then calculate the mean weight in these groups using.\n\nncbirths_habitgiven %>%\n  group_by(habit) %>%\n  summarise(mean_weight = mean(weight))\n\nThere is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test .\n\nWrite the hypotheses for testing if the average weights of babies born to smoking and non-smoking mothers are different.\nAre the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.\nRun the appropriate hypothesis test, calculate the p-value, and interpret the results in context of the data and the hypothesis test.\nConstruct a 95% confidence interval for the difference between the average weights of babies born to smoking and non-smoking mothers."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-mothers-age",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-mothers-age",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weight vs.¬†mother‚Äôs age",
    "text": "Baby weight vs.¬†mother‚Äôs age\nIn this portion of the analysis we focus on two variables. The first one is maturemom.\n\nFirst, a non-inference task: Determine the age cutoff for younger and mature mothers. Use a method of your choice, and explain how your method works.\n\nThe other variable of interest is lowbirthweight.\n\nConduct a hypothesis test evaluating whether the proportion of low birth weight babies is higher for mature mothers. State the hypotheses, verify the conditions, run the test and calculate the p-value, and state your conclusion in context of the research question. Use \\(\\alpha = 0.05\\). If you find a significant difference, construct a confidence interval, at the equivalent level to the hypothesis test, for the difference between the proportions of low birth weight babies between mature and younger mothers, and interpret this interval in context of the data."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article on why Nobel laureates show immigration is so important for American science. You can read the article here. In the article they show that while most living Nobel laureates in the sciences are based in the US, many of them were born in other countries. This is one reason why scientific leaders say that immigration is vital for progress. In this lab we will work with the data from this article to recreate some of their visualizations as well as explore new questions."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "title": "Lab 03 - Nobel laureates",
    "section": "Merges and merge conflicts",
    "text": "Merges and merge conflicts\nThis is the second week you‚Äôre working in teams, so we‚Äôre going to make things a little more interesting and let all of you make changes and push those changes to your team repository. Sometimes things will go swimmingly, and sometimes you‚Äôll run into merge conflicts. So our first task today is to walk you through a merge conflict!\n\nPushing to a repo replaces the code on GitHub with the code you have on your computer.\nIf a collaborator has made a change to your repo on GitHub that you haven‚Äôt incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator‚Äôs work!\nSo you need to explicitly ‚Äúmerge‚Äù your collaborator‚Äôs work before you can push.\nIf your and your collaborator‚Äôs changes are in different files or in different parts of the same file, git merges the work for you automatically when you *pull*.\nIf you both changed the same part of a file, git will produce a **merge conflict** because it doesn‚Äôt know how which change you want to keep and which change you want to overwrite.\n\nGit will put conflict markers in your code that look like:\n<<<<<<< HEAD \n\nSee also: [dplyr documentation](https://dplyr.tidyverse.org/)   \n\n======= \n\nSee also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  \n\n>>>>>>> some1alpha2numeric3string4\nThe ===s separate your changes (top) from their changes (bottom).\nNote that on top you see the word HEAD, which indicates that these are your changes.\nAnd at the bottom you see some1alpha2numeric3string4 (well, it probably looks more like 28e7b2ceb39972085a0860892062810fb812a08f).\nThis is the hash (a unique identifier) of the commit your collaborator made with the conflicting change.\nYour job is to reconcile the changes: edit the file so that it incorporates the best of both versions and delete the <<<, ===, and >>> lines. Then you can stage and commit the result."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#setup",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#setup",
    "title": "Lab 03 - Nobel laureates",
    "section": "Setup",
    "text": "Setup\n\nClone the repo and open the .Rmd file.\nAssign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "title": "Lab 03 - Nobel laureates",
    "section": "Let‚Äôs cause a merge conflict!",
    "text": "Let‚Äôs cause a merge conflict!\nOur goal is to see two different types of merges: first we‚Äôll see a type of merge that git can‚Äôt figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won‚Äôt be able to resist the urge to touch your computer when it‚Äôs not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: everyone should have the repo cloned and know which role number(s) they are.\nRole 1:\n\nChange the team name to your actual team name.\nKnit, commit, push.\n\nüõë Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange the team name to some other word.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nKnit.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\nüõë Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nChange the a label of the first code chunk\nKnit, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\nüõë Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nChange the label of the first code chunk to something other than previous role did.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Commit, and push.\n\nüõë Make sure the previous role has finished before moving on to the next step.\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "title": "Lab 03 - Nobel laureates",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (commit and push) before continuing your work. Never do new work while resolving a merge conflict.\nKnit, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don‚Äôt let it linger and get bigger."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#warm-up",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#warm-up",
    "title": "Lab 03 - Nobel laureates",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#packages",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#packages",
    "title": "Lab 03 - Nobel laureates",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#data",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSv (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nThe variable descriptions are as follows:\n\nid: ID number\nfirstname: First name of laureate\nsurname: Surname\nyear: Year prize won\ncategory: Category of prize\naffiliation: Affiliation of laureate\ncity: City of laureate in prize year\ncountry: Country of laureate in prize year\nborn_date: Birth date of laureate\ndied_date: Death date of laureate\ngender: Gender of laureate\nborn_city: City where laureate was born\nborn_country: Country where laureate was born\nborn_country_code: Code of country where laureate was born\ndied_city: City where laureate died\ndied_country: Country where laureate died\ndied_country_code: Code of country where laureate died\noverall_motivation: Overall motivation for recognition\nshare: Number of other winners award is shared with\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g.¬†in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix `_original`.\n\nborn_country_original: Original country where laureate was born\nborn_city_original: Original city where laureate was born\ndied_country_original: Original country where laureate died\ndied_city_original: Original city where laureate died\ncity_original: Original city where laureate lived at the time of winning the award\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\n\n\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code.\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 03 - Nobel laureates",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n‚Ä¶ says the Buzzfeed article. Let‚Äôs see if that‚Äôs true.\nFirst, we‚Äôll create a new variable to identify whether the laureate was in the US when they won their prize. We‚Äôll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we‚Äôre using to write this if statement is the condition we‚Äôre testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nNote that we can achieve the same result using the `fct_other()` function we've seen before (i.e. with `country_us = fct_other(country, \"USA\")`). We decided to use the `if_else()` here to show you one example of an if statement in R.\n\n\nnobel_living <- nobel_living %>%\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science <- nobel_living %>%\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the next exercise work with the nobel_living_science data frame you created above. This means you‚Äôll need to define this data frame in your R Markdown document, even though the next exercise doesn‚Äôt explicitly ask you to do so.\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.d"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 03 - Nobel laureates",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\n**Hint:** You should be able to ~~cheat~~ borrow from code you used earlier to create the `country_us` variable.\n\n\nCreate a new variable called born_country_us that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Based on your visualization, do the data appear to support Buzzfeed‚Äôs claim? Explain your reasoning in 1-2 sentences.\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be a bar for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "title": "Lab 03 - Nobel laureates",
    "section": "Here‚Äôs where those immigrant Nobelists were born",
    "text": "Here‚Äôs where those immigrant Nobelists were born\n\nNote that your bar plot won't exactly match the one from the Buzzfeed article. This is likely because the data has been updated since the article was published.\n\n\nIn a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work.\nNow go back through your write up to make sure you‚Äôve answered all questions and all of your R chunks are properly labelled. Once you decide as a team that you‚Äôre done with this lab, all members of the team should pull the changes and knit the R Markdown document to confirm that they can reproduce the report."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html",
    "href": "course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html",
    "title": "Lab 13 - Work on projects",
    "section": "",
    "text": "Remind yourself of the project assignment\nGo to the course organization on GitHub and clone your project repo titled project-TEAM_NAME\nAdd your project title and team name to the README.Rmd file in the repo and commit and push your changes. Observe that these are updated in the README of the repo.\nOpen the presentation.Rmd file, knit the document, and review the presentation format. This is where your presentation will go. Update the YAML with your project title, team name, etc. and commit and push your changes.\nGo to your project repo on GitHub, click on Settings on the top right corner, and scroll down to the section titled GiHub Pages. Under Source, select main branch and the root folder. This will give you a URL where the website for your project will be automatically built from the content in your README. This might take a few minutes.\n\nOnce the website is built, pull changes to your project in RStudio.\nTake a look at your rendered project website. Click on the link in the presentation section and you should be able to view the rendered slides. This is the link we will use to project your slides during the presentations.\nOn your repo you should see a text on top No description, website, or topics provided.. Next to it there‚Äôs an Edit button. Add a short description as well as the URL of your project website here.\nNote: This website is public, but your repository will remain private,unless‚Ä¶ you as a team decide you would like to feature your repos in your personal GitHub profiles. If so, I will help you convert your repo to a public repo at the end of the semester. I will not add any marks to your repos so that your public work won‚Äôt contain your score for the project.\n\nAdd your dataset to the data folder and add your codebook to the README in that folder.\n\nIf in your proposal you were advised to update your codebook, make sure to make those updates.\nIf you had R scripts you used to scrape your data, add them to this folder as well.\n\nAdd the content from your proposal to the proposal.Rmd file in the proposal folder. Knit the document to make sure everything works and commit and push your proposal to your project repo.\n\nImportant: Your data now lives in a folder called data that is not inside your proposal folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function.\nYou don‚Äôt need to make further updates to your proposal at this point, even if your plans for the project change slightly.\n\nLoad your data in your presentation.Rmd, knit, and make sure everything works. Commit and push your updated proposal to your project repo.\n\nImportant: Same note as above! Your data now lives in a folder called data that is not inside your presentation folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function.\n\nNow that all the logistical details are done, start working on your project.\n\nOpen issues for things you want to accomplish. Assign them to specific team member(s) if you like. And as you complete the tasks, close the issues. You can also use the issues for discussion on the specific tasks.\n\nStrongly recommended: Get a hold of the instructor or a TA and run your ideas by them."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the Denny‚Äôs and La Quinta Inn and Suites data we visualized in the previous lab."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#packages",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#packages",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#data",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#data",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 2",
    "section": "Data",
    "text": "Data\nRemember that the datasets we‚Äôll use are called dennys and laquinta from the dsbox package. Since the datasets are distributed with the package, we don‚Äôt need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "The University of Edinburgh Art Collection ‚Äúsupports the world-leading research and teaching that happens within the University. Comprised of an astonishing range of objects and ideas spanning two millennia and a multitude of artistic forms, the collection reflects not only the long and rich trajectory of the University, but also major national and international shifts in art history.‚Äù1.\nIn this lab we‚Äôll scrape data on all art pieces in the Edinburgh College of Art collection."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "R scripts vs.¬†R Markdown documents",
    "text": "R scripts vs.¬†R Markdown documents\nToday we will be using both R scripts and R Markdown documents:\n\n.R: R scripts are plain text files containing only code and brief comments,\n\nWe‚Äôll use R scripts in the web scraping stage and ultimately save the scraped data as a csv.\n\n.Rmd: R Markdown documents are plain text files containing.\n\nWe‚Äôll use an R Markdown document in the web analysis stage, where we start off by reading in the csv file we wrote out in the scraping stage.\n\n\nHere is the organization of your repo, and the corresponding section in the lab that each file will be used for:"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#warm-up",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#warm-up",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Warm up",
    "text": "Warm up\nLet‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#packages",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#packages",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we‚Äôre allowed to scrape the data, the rvest package for data scraping. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(robotstxt)\nlibrary(rvest)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#data",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#data",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you‚Äôll be scraping the data! But before doing so, let‚Äôs check that a bot has permissions to access pages on this domain.\n\npaths_allowed(\"https://collections.ed.ac.uk/art)\")\n\n\n collections.ed.ac.uk                      \n\n\n[1] TRUE"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Scraping a single page",
    "text": "Scraping a single page\n\n**Tip:** To run the code you can highlight or put your cursor next to the lines of code you want to run and hit Command+Enter.\n\n\nWork in scripts/01-scrape-page-one.R.\n\nWe will start off by scraping data on the first 10 pieces in the collection from here.\nFirst, we define a new object called first_url, which is the link above. Then, we read the page at this url with the read_html() function from the rvest package. The code for this is already provided in 01-scrape-page-one.R.\n\n# set url\nfirst_url <- \"https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0\"\n\n# read html page\npage <- read_html(first_url)\n\nFor the ten pieces on this page we will extract title, artist, and link information, and put these three variables in a data frame.\n\nTitles\nLet‚Äôs start with titles. We make use of the SelectorGadget to identify the tags for the relevant nodes:\n\n\n\n\n\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\")\n\n{xml_nodeset (10)}\n [1] <a href=\"./record/50523?highlight=*:*\">Unknown                           ...\n [2] <a href=\"./record/21172?highlight=*:*\">Portrait of a Seated Woman        ...\n [3] <a href=\"./record/21876?highlight=*:*\">Untitled                          ...\n [4] <a href=\"./record/21407?highlight=*:*\">Portrait of a Woman               ...\n [5] <a href=\"./record/22497?highlight=*:*\">Untitled                          ...\n [6] <a href=\"./record/22657?highlight=*:*\">Composition with Two Figures in L ...\n [7] <a href=\"./record/21960?highlight=*:*\">Porcus Omnivorous                 ...\n [8] <a href=\"./record/21134?highlight=*:*\">Portrait of a Man                 ...\n [9] <a href=\"./record/21746?highlight=*:*\">Untitled                          ...\n[10] <a href=\"./record/53782?highlight=*:*\">The Etiquette of Landscape and Fa ...\n\n\nThen we extract the text with html_text():\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text()\n\n [1] \"Unknown                                                                            (1957)\"                                       \n [2] \"Portrait of a Seated Woman                                                                            (1965-1966)\"               \n [3] \"Untitled                                                                            (1997)\"                                      \n [4] \"Portrait of a Woman                                                                            (02 Nov 1953)\"                    \n [5] \"Untitled                                                                            (1962)\"                                      \n [6] \"Composition with Two Figures in Lime Green                                    \"                                                  \n [7] \"Porcus Omnivorous                                                                            (1994)\"                             \n [8] \"Portrait of a Man                                                                            (1939)\"                             \n [9] \"Untitled                                                                            (1949)\"                                      \n[10] \"The Etiquette of Landscape and Face: Passage 2                                                                            (2015)\"\n\n\nAnd get rid of all the spurious white space in the text with str_squish(), which reduces repeated whitespace inside a string.\n\nTake a look at the help for `str_squish()` to find out more about how it works and how it's different from `str_trim()`.\n\n\npage %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text() %>%\n  str_squish()\n\n [1] \"Unknown (1957)\"                                       \n [2] \"Portrait of a Seated Woman (1965-1966)\"               \n [3] \"Untitled (1997)\"                                      \n [4] \"Portrait of a Woman (02 Nov 1953)\"                    \n [5] \"Untitled (1962)\"                                      \n [6] \"Composition with Two Figures in Lime Green\"           \n [7] \"Porcus Omnivorous (1994)\"                             \n [8] \"Portrait of a Man (1939)\"                             \n [9] \"Untitled (1949)\"                                      \n[10] \"The Etiquette of Landscape and Face: Passage 2 (2015)\"\n\n\nAnd finally save the resulting data as a vector of length 10:\n\ntitles <- page %>%\n  html_nodes(\".iteminfo\") %>%\n  html_node(\"h3 a\") %>%\n  html_text() %>%\n  str_squish()\n\n\n\nLinks\nThe same nodes that contain the text for the titles also contains information on the links to individual art piece pages for each title. We can extract this information using a new function from the rvest package, html_attr(), which extracts attributes.\nA mini HTML lesson! The following is how we define hyperlinked text in HTML:\n<a href=\"https://www.google.com\">Seach on Google</a>\nAnd this is how the text would look like on a webpage: Seach on Google.\nHere the text is Seach on Google and the href attribute contains the url of the website you‚Äôd go to if you click on the hyperlinked text: https://www.google.com.\nThe moral of the story is: the link is stored in the href attribute.\n\npage %>%\n  html_nodes(\".iteminfo\") %>%   # same nodes\n  html_node(\"h3 a\") %>%         # as before\n  html_attr(\"href\")             # but get href attribute instead of text\n\n [1] \"./record/50523?highlight=*:*\" \"./record/21172?highlight=*:*\"\n [3] \"./record/21876?highlight=*:*\" \"./record/21407?highlight=*:*\"\n [5] \"./record/22497?highlight=*:*\" \"./record/22657?highlight=*:*\"\n [7] \"./record/21960?highlight=*:*\" \"./record/21134?highlight=*:*\"\n [9] \"./record/21746?highlight=*:*\" \"./record/53782?highlight=*:*\"\n\n\nThese don‚Äôt really look like URLs as we know then though. They‚Äôre relative links.\n\nSee the help for `str_replace()` to find out how it works. Remember that the first argument is passed in from the pipeline, so you just need to define the `pattern` and `replacement` arguments.\n\n\nClick on one of art piece titles in your browser and take note of the url of the webpage it takes you to. Think about how that url compares to what we scraped above? How is it different? Using str_replace(), fix the URLs. You‚Äôll note something special happening in the pattern to replace. We want to replace the ., but we have it as \\\\.. This is because the period . is a special character and so we need to escape it first with backslashes, \\\\s.\n\n\n\nArtists\n\nFill in the blanks to scrape artist names.\n\n\n\nPut it altogether\n\nFill in the blanks to organize everything in a tibble.\n\n\n\nScrape the next page\n\nClick on the next page, and grab its url. Fill in the blank in to define a new object: second_url. Copy-paste code from top of the R script to scrape the new set of art pieces, and save the resulting data frame as second_ten.\n\n‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#functions",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#functions",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Functions",
    "text": "Functions\n\nWork in scripts/02-scrape-page-function.R.\n\nYou‚Äôve been using R functions, now it‚Äôs time to write your own!\nLet‚Äôs start simple. Here is a function that takes in an argument x, and adds 2 to it.\n\nadd_two <- function(x){\n  x + 2\n}\n\nLet‚Äôs test it:\n\nadd_two(3)\n\n[1] 5\n\nadd_two(10)\n\n[1] 12\n\n\nThe skeleton for defining functions in R is as follows:\n\nfunction_name <- function(input){\n  # do something with the input(s)\n  # return something\n}\n\nThen, a function for scraping a page should look something like:\n\n**Reminder:** Function names should be short but evocative verbs.\n\n\nfunction_name <- function(url){\n  # read page at url\n  # extract title, link, artist info for n pieces on page\n  # return a n x 3 tibble\n}\n\n\nFill in the blanks using code you already developed in the previous exercises. Name the function scrape_page.\n\nTest out your new function by running the following in the console. Does the output look right? Discuss with teammates whether you‚Äôre getting the same results as before.\n\nscrape_page(first_url)\nscrape_page(second_url)\n\n‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#iteration",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#iteration",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Iteration",
    "text": "Iteration\n\nWork in scripts/03-scrape-page-many.R.\n\nWe went from manually scraping individual pages to writing a function to do the same. Next, we will work on making our workflow a little more efficient by using R to iterate over all pages that contain information on the art collection.\n\n**Reminder:** The collection has 2970 pieces in total.\n\nThat means we give develop a list of URLs (of pages that each have 10 art pieces), and write some code that applies the scrape_page() function to each page, and combines the resulting data frames from each page into a single data frame with 2970 rows and 3 columns.\n\nList of URLs\nClick through the first few of the pages in the art collection and observe their URLs to confirm the following pattern:\n[sometext]offset=0     # Pieces 1-10\n[sometext]offset=10    # Pieces 11-20\n[sometext]offset=20    # Pieces 21-30\n[sometext]offset=30    # Pieces 31-40\n...\n[sometext]offset=2960  # Pieces 2961-2970\nWe can construct these URLs in R by pasting together two pieces: (1) a common (root) text for the beginning of the URL, and (2) numbers starting at 0, increasing by 10, all the way up to 2970. Two new functions are helpful for accomplishing this: glue() for pasting two pieces of text and seq() for generating a sequence of numbers.\n\nFill in the blanks to construct the list of URLs.\n\n\n\nMapping\nFinally, we‚Äôre ready to iterate over the list of URLs we constructed. We will do this by mapping the function we developed over the list of URLs. There are a series of mapping functions in R (which we‚Äôll learn about in more detail tomorrow), and they each take the following form:\nmap([x], [function to apply to each element of x])\nIn our case x is the list of URLs we constructed and the function to apply to each element of x is the function we developed earlier, scrape_page. And as a result we want a data frame, so we use map_dfr function:\n\nmap_dfr(urls, scrape_page)\n\n\nFill in the blanks to scrape all pages, and to create a new data frame called uoe_art.\n\n\n\nWrite out data\n\nFinally write out the data frame you constructed into the data folder so that you can use it in the analysis section.\n\n\nAim to make it to this point during the workshop.\n\n‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#analysis",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#analysis",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Analysis",
    "text": "Analysis\n\nWork in lab-08.Rmd for the rest of the lab.\n\nNow that we have a tidy dataset that we can analyze, let‚Äôs do that!\nWe‚Äôll start with some data cleaning, to clean up the dates that appear at the end of some title text in parentheses. Some of these are years, others are more specific dates, some art pieces have no date information whatsoever, and others have some non-date information in parentheses. This should be interesting to clean up!\nFirst thing we‚Äôll try is to separate the title column into two: one for the actual title and the other for the date if it exists. In human speak, we need to\n\n‚Äúseparate the title column at the first occurrence of ( and put the contents on one side of the ( into a column called title and the contents on the other side into a column called date‚Äù\n\nLuckily, there‚Äôs a function that does just this: separate()!\nAnd once we have completed separating the single title column into title and date, we need to do further clean-up in the date column to get rid of extraneous )s with str_remove(), capture year information, and save the data as a numeric variable.\n\n**Hint:** Remember escaping special characters from yesterday's lecture? You'll need to use that trick again.\n\n\nFill in the blanks in to implement the data wrangling we described above. Note that this will result in some warnings when you run the code, and that‚Äôs OK! Read the warnings, and explain what they mean, and why we are ok with leaving them in given that our objective is to just capture year where it‚Äôs convenient to do so.\nPrint out a summary of the data frame using the skim() function. How many pieces have artist info missing? How many have year info missing?\nMake a histogram of years. Use a reasonable binwidth. Do you see anything out of the ordinary?\n\n\n**Hint:** You'll want to use `mutate()` and `if_else()` or `case_when()` to implement the correction.\n\n\nFind which piece has the out of the ordinary year and go to its page on the art collection website to find the correct year for it. Can you tell why our code didn‚Äôt capture the correct year information? Correct the error in the data frame and visualize the data again.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è If you haven‚Äôt done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nWho is the most commonly featured artist in the collection? Do you know them? Any guess as to why the university has so many pieces from them?\n\n\n**Hint:** `str_subset()` can be helful here. You should consider how you might capture titles where the word appears as \"child\" and \"Child\".\n\n\nFinal question! How many art pieces have the word ‚Äúchild‚Äù in their title? Try to figure it out, and ask for help if you‚Äôre stuck.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.html",
    "href": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.html",
    "title": "Sales",
    "section": "",
    "text": "Read in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\n\n\n\n\n\n\n\n\nStretch goal: Manipulate the sales data such such that it looks like the following."
  },
  {
    "objectID": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "href": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "title": "Nobel winners",
    "section": "",
    "text": "Let‚Äôs first load the data:\n\nnobel <- ___(___)\n\nThen let‚Äôs split the data into two:\n\n# stem laureates\n___ <- nobel %>%\n  filter(___)\n\n# non-steam laureates\n___ <- nobel %>%\n  filter(___)\n\nAnd finally write out the data:\n\n# add code for writing out the two data frames here"
  },
  {
    "objectID": "course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html",
    "href": "course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html",
    "title": "Visualizing Starwars characters",
    "section": "",
    "text": "glimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       <chr> \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or‚Ä¶\n$ height     <int> 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2‚Ä¶\n$ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.‚Ä¶\n$ hair_color <chr> \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N‚Ä¶\n$ skin_color <chr> \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"‚Ä¶\n$ eye_color  <chr> \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",‚Ä¶\n$ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, ‚Ä¶\n$ sex        <chr> \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",‚Ä¶\n$ gender     <chr> \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini‚Ä¶\n$ homeworld  <chr> \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T‚Ä¶\n$ species    <chr> \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma‚Ä¶\n$ films      <list> <\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return‚Ä¶\n$ vehicles   <list> <\"Snowspeeder\", \"Imperial Speeder Bike\">, <>, <>, <>, \"Imp‚Ä¶\n$ starships  <list> <\"X-wing\", \"Imperial shuttle\">, <>, <>, \"TIE Advanced x1\",‚Ä¶\n\n\n\nModify the following plot to change the color of all points to \"pink\".\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"pink\")\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\nAdd labels for title, x and y axes, and size of points. Uncomment to see the effect.\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"#30509C\") +\n  labs(\n    #title = \"___\",\n    #x = \"___\", \n    #y = \"___\",\n    #___\n    )\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\nPick a single numerical variable and make a histogram of it. Select a reasonable binwidth for it.\n\n(A little bit of starter code is provided below, and the code chunk is set to not be evaluated with eval: false because the current code in there is not valid code and hence the document wouldn‚Äôt knit. Once you replace the code with valid code, set the chunk option to eval: true, or remove the eval option altogether since it‚Äôs set to true by default.)\n\nggplot(starwars, aes(___)) +\n  geom___\n\n\nPick a numerical variable and a categorical variable and make a visualization (you pick the type!) to visualization the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here‚Ä¶\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\n\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\n\n\nInterpretation goes here‚Ä¶\n\nPick two numerical variables and two categorical variables and make a visualization that incorporates all of them and provide an interpretation with your answer.\n\n(This time no starter code is provided, you‚Äôre on your own!)\n\n\n\nInterpretation goes here‚Ä¶"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html",
    "title": "Cumulative deaths from COVID-19",
    "section": "",
    "text": "Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries.\nThe data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily.\nFor our analysis, in addition to the coronavirus package, we will use the following packages for data wrangling and visualization.\n\ntidyverse for data wrangling and visualization\nlubridate package for handling dates\nglue package for constructing text strings\nscales package for formatting axis labels\nggrepel package for pretty printing of country labels\n\nWe will make use of the DT package for interactive display of tabular output in the Appendix.\n\nlibrary(coronavirus) # devtools::install_github(\"RamiKrispin/coronavirus\")\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(DT)"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#data-prep",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#data-prep",
    "title": "Cumulative deaths from COVID-19",
    "section": "Data prep",
    "text": "Data prep\nThe data frame called coronavirus in the coronavirus package provides a daily summary of the Coronavirus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). A full list of the countries in the data frame is provided in the Appendix. Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. For this report, we will focus on the deaths.\nWe will start by making our selection for the countries we want to explore.\n\ncountries <- c(\n  \"China\",\n  \"France\",\n  \"United Kingdom\",\n  \"US\",\n  \"Turkey\"\n)\n\nIn the following code chunk we filter the data frame for deaths in the countries we specified above and calculate cumulative number of deaths. We will only visualize data since 10th confirmed death.\n\ncountry_data <- coronavirus %>%\n  # filter for deaths in countries of interest\n  filter(\n    type == \"death\",\n    country %in% countries\n  ) %>%\n  # fix county labels for pretty plotting\n  mutate(\n    country = case_when(\n      country == \"United Kingdom\" ~ \"UK\",\n      TRUE ~ country\n    )\n  ) %>%\n  # calculate number of total cases for each country and date\n  group_by(country, date) %>%\n  summarise(tot_cases = sum(cases)) %>%\n  # arrange by date in ascending order\n  arrange(date) %>%\n  # record daily cumulative cases as cumulative_cases\n  mutate(cumulative_cases = cumsum(tot_cases)) %>%\n  # only use days since the 10th confirmed death\n  filter(cumulative_cases > 9) %>%\n  # record days elapsed, end date, and end label\n  mutate(\n    days_elapsed = as.numeric(date - min(date)),\n    end_date     = if_else(date == max(date), TRUE, FALSE),\n    end_label    = if_else(end_date, country, NULL)\n  ) %>%\n  # ungroup\n  ungroup()\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\nWe also need to take a note of the ‚Äúas of date‚Äù for the data so that we can properly label our visualization.\n\nas_of_date <- country_data %>% \n  summarise(max(date)) %>% \n  pull()\n\nas_of_date_formatted <- glue(\"{wday(as_of_date, label = TRUE)}, {month(as_of_date, label = TRUE)} {day(as_of_date)}, {year(as_of_date)}\")\n\nThese data are as of Thu, Jun 23, 2022."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#visualization",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#visualization",
    "title": "Cumulative deaths from COVID-19",
    "section": "Visualization",
    "text": "Visualization\nThe following visualization shows the number of cumulative cases vs.¬†days elapsed since the 10th confirmed death in each country. The time span plotted for each country varies since some countries started seeing (and reporting) deaths from COVID-19 much later than others.\n\nggplot(data = country_data,\n       mapping = aes(x = days_elapsed, \n                     y = cumulative_cases, \n                     color = country, \n                     label = end_label)) +\n  # represent cumulative cases with lines\n  geom_line(size = 0.7, alpha = 0.8) +\n  # add points to line endings\n  geom_point(data = country_data %>% filter(end_date)) +\n  # add country labels, nudged above the lines\n  geom_label_repel(nudge_y = 1, direction = \"y\", hjust = 1) + \n  # turn off legend\n  guides(color = \"none\") +\n  # use pretty colors\n  scale_color_viridis_d() +\n  # better formatting for y-axis\n  scale_y_continuous(labels = label_comma()) +\n  # use minimal theme\n  theme_minimal() +\n  # customize labels\n  labs(\n    x = \"Days since 10th confirmed death\",\n    y = \"Cumulative number of deaths\",\n    title = \"Cumulative deaths from COVID-19, selected countries\",\n    subtitle = glue(\"Data as of\", as_of_date_formatted, .sep = \" \"),\n    caption = \"Source: github.com/RamiKrispin/coronavirus\"\n  )"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#appendix",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#appendix",
    "title": "Cumulative deaths from COVID-19",
    "section": "Appendix",
    "text": "Appendix\nA list of countries in the coronavirus data frame is provided below."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we‚Äôre using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes <- un_votes %>%\n  inner_join(un_roll_calls, by = \"rcid\") %>%\n  inner_join(un_roll_call_issues, by = \"rcid\")"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet‚Äôs create a data visualisation that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes %>%\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) %>%\n  mutate(year = year(date)) %>%\n  group_by(country, year, issue) %>%\n  summarize(percent_yes = mean(vote == \"yes\")) %>%\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#references",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nDavid Robinson (2017). unvotes: United Nations General Assembly Voting Data. R package version 0.2.0.\nErik Voeten ‚ÄúData and Analyses of Voting in the UN General Assembly‚Äù Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#appendix",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html",
    "title": "Bechdel",
    "section": "",
    "text": "In this mini analysis we work with the data used in the FiveThirtyEight story titled ‚ÄúThe Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion of Women‚Äù. Your task is to fill in the blanks denoted by ___."
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "title": "Bechdel",
    "section": "Data and packages",
    "text": "Data and packages\nWe start with loading the packages we‚Äôll use.\n\nlibrary(fivethirtyeight)\nlibrary(tidyverse)\n\nThe dataset contains information on 1794 movies released between 1970 and 2013. However we‚Äôll focus our analysis on movies released between 1990 and 2013.\n\nbechdel90_13 <- bechdel %>% \n  filter(between(year, 1990, 2013))\n\nThere are ___ such movies.\nThe financial variables we‚Äôll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars\ndomgross_2013: Domestic gross (US) in 2013 inflation adjusted dollars\nintgross_2013: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars\n\nAnd we‚Äôll also use the binary and clean_test variables for grouping."
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "title": "Bechdel",
    "section": "Analysis",
    "text": "Analysis\nLet‚Äôs take a look at how median budget and gross vary by whether the movie passed the Bechdel test, which is stored in the binary variable.\n\nbechdel90_13 %>%\n  group_by(binary) %>%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 2 √ó 4\n  binary med_budget med_domgross med_intgross\n  <chr>       <dbl>        <dbl>        <dbl>\n1 FAIL    48385984.    57318606.    104475669\n2 PASS    31070724     45330446.     80124349\n\n\nNext, let‚Äôs take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result. This information is stored in the clean_test variable, which takes on the following values:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don‚Äôt talk to each other\nnowomen = fewer than two women\n\n\nbechdel90_13 %>%\n  #group_by(___) %>%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 1 √ó 3\n  med_budget med_domgross med_intgross\n       <int>        <dbl>        <dbl>\n1   37878971     52270207     93523336\n\n\nIn order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we‚Äôll first create a new variable called roi as the ratio of the gross to budget.\n\nbechdel90_13 <- bechdel90_13 %>%\n  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)\n\nLet‚Äôs see which movies have the highest return on investment.\n\nbechdel90_13 %>%\n  arrange(desc(roi)) %>% \n  select(title, roi, year)\n\n# A tibble: 1,615 √ó 3\n   title                     roi  year\n   <chr>                   <dbl> <int>\n 1 Paranormal Activity      671.  2007\n 2 The Blair Witch Project  648.  1999\n 3 El Mariachi              583.  1992\n 4 Clerks.                  258.  1994\n 5 In the Company of Men    231.  1997\n 6 Napoleon Dynamite        227.  2004\n 7 Once                     190.  2006\n 8 The Devil Inside         155.  2012\n 9 Primer                   142.  2004\n10 Fireproof                134.  2008\n# ‚Ä¶ with 1,605 more rows\n\n\nBelow is a visualization of the return on investment by test result, however it‚Äôs difficult to see the distributions due to a few extreme observations.\n\nggplot(data = bechdel90_13, \n       mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"___\",\n    color = \"Binary Bechdel result\"\n    )\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel90_13 %>%\n  filter(roi > 400) %>%\n  select(title, budget_2013, domgross_2013, year)\n\n# A tibble: 3 √ó 4\n  title                   budget_2013 domgross_2013  year\n  <chr>                         <int>         <dbl> <int>\n1 Paranormal Activity          505595     121251476  2007\n2 The Blair Witch Project      839077     196538593  1999\n3 El Mariachi                   11622       3388636  1992\n\n\nZooming in on the movies with roi < ___ provides a better view of how the medians across the categories compare:\n\nggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    subtitle = \"___\", # Something about zooming in to a certain level\n    x = \"Detailed Bechdel result\",\n    y = \"Return on investment\",\n    color = \"Binary Bechdel result\"\n    ) +\n  coord_cartesian(ylim = c(0, 15))"
  },
  {
    "objectID": "course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.html",
    "href": "course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.html",
    "title": "Brexit",
    "section": "",
    "text": "In September 2019, YouGov survey asked 1,639 GB adults the following question:\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon‚Äôt know\n\n\nThe data from the survey is in data/brexit.csv.\n\nbrexit <- read_csv(\"data/brexit.csv\")\n\nIn the course video we made the following visualisation.\n\nbrexit <- brexit %>%\n  mutate(\n    region = fct_relevel(region, \"london\", \"rest_of_south\", \"midlands_wales\", \"north\", \"scot\"),\n    region = fct_recode(region, London = \"london\", `Rest of South` = \"rest_of_south\", `Midlands / Wales` = \"midlands_wales\", North = \"north\", Scotland = \"scot\")\n  )\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\nIn this application exercise we tell different stories with the same data.\n\nExercise 1 - Free scales\nAdd scales = \"free_x\" as an argument to the facet_wrap() function. How does the visualisation change? How is the story this visualisation telling different than the story the original plot tells?\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region,\n    nrow = 1, labeller = label_wrap_gen(width = 12),\n    # ___\n  ) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\n\n\nExercise 2 - Comparing proportions across facets\nFirst, calculate the proportion of wrong, right, and don‚Äôt know answers in each category and then plot these proportions (rather than the counts) and then improve axis labeling. How is the story this visualisation telling different than the story the original plot tells? Hint: You‚Äôll need the scales package to improve axis labeling, which means you‚Äôll need to load it on top of the document as well.\n\n# code goes here\n\n\n\nExercise 3 - Comparing proportions across bars\nRecreate the same visualisation from the previous exercise, this time dodging the bars for opinion proportions for each region, rather than faceting by region and then improve the legend. How is the story this visualisation telling different than the story the previous plot tells?\n\n# code goes here"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "title": "Hotel bookings - data wrangling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "title": "Hotel bookings - data wrangling",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.\nWarm up! Take a look at an overview of the data with the skim() function.\nNote: I already gave you the answer to this exercise. You just need to knit the document and view the output. A definition of all variables is given in the Data dictionary section at the end, though you don‚Äôt need to familiarize yourself with all variables in order to work through these exercises.\n\nskim(hotels)\n\n\nData summary\n\n\nName\nhotels\n\n\nNumber of rows\n119390\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n1\n\n\nnumeric\n18\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n178\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n334\n0\n\n\ncompany\n0\n1\n1\n4\n0\n353\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nreservation_status\n0\n1\n7\n9\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÖ\n\n\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\n\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñÜ\n\n\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n‚ñÖ‚ñá‚ñá‚ñá‚ñÖ\n\n\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n‚ñá‚ñá‚ñá‚ñá‚ñÜ\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\n\n\nExercise 2.\nAre people traveling on a whim? Let‚Äôs see‚Ä¶\nFill in the blanks for filtering for hotel bookings where the guest is not from the US (country code \"USA\") and the lead_time is less than 1 day.\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %>%\n  filter(\n    country ____ \"USA\", \n    lead_time ____ ____\n    )\n\n\n\nExercise 3.\nHow many bookings involve at least 1 child or baby?\nIn the following chunk, replace\n\n[AT LEAST] with the logical operator for ‚Äúat least‚Äù (in two places)\n[OR] with the logical operator for ‚Äúor‚Äù\n\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %>%\n  filter(\n    children [AT LEAST] 1 [OR] babies [AT LEAST] 1\n    )\n\n\n\nExercise 4.\nDo you think it‚Äôs more likely to find bookings with children or babies in city hotels or resort hotels? Test your intuition. Using filter() determine the number of bookings in resort hotels that have more than 1 child or baby in the room? Then, do the same for city hotels, and compare the numbers of rows in the resulting filtered data frames.\n\n# add code here\n# pay attention to correctness and code style\n\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 5.\nCreate a frequency table of the number of adults in a booking. Display the results in descending order so the most common observation is on top. What is the most common number of adults in bookings in this dataset? Are there any surprising results?\nNote: Don‚Äôt forget to label your R chunk as well (where it says label-me-1). Your label should be short, informative, and shouldn‚Äôt include spaces. It also shouldn‚Äôt repeat a previous label, otherwise R Markdown will give you an error about repeated R chunk labels.\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 6.\nRepeat Exercise 5, once for canceled bookings (is_canceled coded as 1) and once for not canceled bookings (is_canceled coded as 0). What does this reveal about the surprising results you spotted in the previous exercise?\nNote: Don‚Äôt forget to label your R chunk as well (where it says label-me-2).\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 7.\nCalculate minimum, mean, median, and maximum average daily rate (adr) grouped by hotel type so that you can get these statistics separately for resort and city hotels. Which type of hotel is higher, on average?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 8.\nWe observe two unusual values in the summary statistics above ‚Äì a negative minimum, and a very high maximum). What types of hotels are these? Locate these observations in the dataset and find out the arrival date (year and month) as well as how many people (adults, children, and babies) stayed in the room. You can investigate the data in the viewer to locate these values, but preferably you should identify them in a reproducible way with some code.\nHint: For example, you can filter for the given adr amounts and select the relevant columns.\n\n# add code here\n# pay attention to correctness and code style"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "title": "Hotel bookings - data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the full data dictionary. Note that it is long (there are lots of variables in the data), but we will be using a limited set of the variables for our analysis.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:  Undefined/SC ‚Äì no meal package;BB ‚Äì Bed & Breakfast;  HB ‚Äì Half board (breakfast and one other meal ‚Äì usually dinner);  FB ‚Äì Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155‚Äì3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term ‚ÄúTA‚Äù means ‚ÄúTravel Agents‚Äù and ‚ÄúTO‚Äù means ‚ÄúTour Operators‚Äù\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term ‚ÄúTA‚Äù means ‚ÄúTravel Agents‚Äù and ‚ÄúTO‚Äù means ‚ÄúTour Operators‚Äù\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g.¬†overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:No Deposit ‚Äì no deposit was made;Non Refund ‚Äì a deposit was made in the value of the total stay cost;Refundable ‚Äì a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:Contract - when the booking has an allotment or other type of contract associated to it;Group ‚Äì when the booking is associated to a group;Transient ‚Äì when the booking is not part of a group or contract, and is not associated to other transient booking;Transient-party ‚Äì when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g.¬†twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:Canceled ‚Äì booking was canceled by the customer;Check-Out ‚Äì customer has checked in but already departed;No-Show ‚Äì customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.html",
    "href": "course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.html",
    "title": "Type coercion",
    "section": "",
    "text": "c(1, 1L, \"C\")\n\n[1] \"1\" \"1\" \"C\"\n\n\n\n1\n\n[1] 1\n\n1L\n\n[1] 1\n\n\"C\"\n\n[1] \"C\"\n\n\n\n#typeof(c(1, 1L, \"C\"))\n\n\nc(1L / 0, \"A\")\n\n\nc(1L / 0, \"A\")\n\n[1] \"Inf\" \"A\"  \n\n\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L/0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n\n\n#typeof(c(1L / 0, \"A\"))\n\n\nc(1:3, 5)\n\n\nc(1:3, 5)\n\n[1] 1 2 3 5\n\n\n\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n\n\n#typeof(c(1:3, 5))\n\n\nc(3, \"3+\")\n\n\nc(3, \"3+\")\n\n[1] \"3\"  \"3+\"\n\n\n\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n\n\n#typeof(c(3, \"3+\"))\n\n\nc(NA, TRUE)\n\n\nc(NA, TRUE)\n\n[1]   NA TRUE\n\n\n\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n#typeof(c(NA, TRUE))"
  },
  {
    "objectID": "course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.html",
    "href": "course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.html",
    "title": "Hotel bookings - factors",
    "section": "",
    "text": "# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nFirst, knit the document and view the following visualisation. How are the months ordered? What would be a better order? Then, reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g.¬†$80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\nhotels %>%\n  group_by(hotel, arrival_date_month) %>%   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr)) %>%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n    )\n\n`summarise()` has grouped output by 'hotel'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.html",
    "href": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.html",
    "title": "The Office - Solution",
    "section": "",
    "text": "Use theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16‚Ä¶\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",‚Ä¶\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis‚Ä¶\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky‚Ä¶\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha‚Ä¶\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6‚Ä¶\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,‚Ä¶\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-‚Ä¶\n\n\nFix air_date for later use.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don‚Äôt match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %>%\n  distinct(season, episode)\n\n# A tibble: 186 √ó 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# ‚Ä¶ with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\noffice_lines <- theoffice %>%\n  group_by(season, episode) %>%\n  mutate(\n    n_lines = n(),\n    lines_jim = sum(character == \"Jim\") / n_lines,\n    lines_pam = sum(character == \"Pam\") / n_lines,\n    lines_michael = sum(character == \"Michael\") / n_lines,\n    lines_dwight = sum(character == \"Dwight\") / n_lines,\n  ) %>%\n  ungroup() %>%\n  select(season, episode, episode_name, contains(\"lines_\")) %>%\n  distinct(season, episode, episode_name, .keep_all = TRUE)\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine‚Äôs Day, and Christmas.\n\ntheoffice <- theoffice %>%\n  mutate(text = tolower(text))\n\nhalloween_episodes <- theoffice %>%\n  filter(str_detect(text, \"halloween\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(halloween = 1) %>%\n  select(-n)\n\nvalentine_episodes <- theoffice %>%\n  filter(str_detect(text, \"valentine\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(valentine = 1) %>%\n  select(-n)\n\nchristmas_episodes <- theoffice %>%\n  filter(str_detect(text, \"christmas\")) %>% \n  count(episode_name) %>%\n  filter(n > 1) %>%\n  mutate(christmas = 1) %>%\n  select(-n)\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you‚Äôve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\noffice_df <- theoffice %>%\n  select(season, episode, episode_name, imdb_rating, total_votes, air_date) %>%\n  distinct(season, episode, .keep_all = TRUE) %>%\n  left_join(halloween_episodes, by = \"episode_name\") %>% \n  left_join(valentine_episodes, by = \"episode_name\") %>% \n  left_join(christmas_episodes, by = \"episode_name\") %>% \n  replace_na(list(halloween = 0, valentine = 0, christmas = 0)) %>%\n  mutate(michael = if_else(season > 7, 0, 1)) %>%\n  mutate(across(halloween:michael, as.factor)) %>%\n  left_join(office_lines, by = c(\"season\", \"episode\", \"episode_name\"))\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\noffice_split <- initial_split(office_df)\noffice_train <- training(office_split)\noffice_test <- testing(office_split)\n\n\n\nExercise 5 - Specify a linear regression model.\n\noffice_mod <- linear_reg() %>%\n  set_engine(\"lm\")\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, and removes all zero variance predictors.\n\noffice_rec <- recipe(imdb_rating ~ ., data = office_train) %>%\n  update_role(episode_name, new_role = \"id\") %>%\n  step_rm(air_date) %>%\n  step_dummy(all_nominal(), -episode_name) %>%\n  step_zv(all_predictors())\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\noffice_wflow <- workflow() %>%\n  add_model(office_mod) %>%\n  add_recipe(office_rec)\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\noffice_fit <- office_wflow %>%\n  fit(data = office_train)\n\ntidy(office_fit)\n\n# A tibble: 12 √ó 5\n   term           estimate std.error statistic  p.value\n   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)    6.34     0.298       21.2    1.24e-43\n 2 season         0.0542   0.0224       2.42   1.68e- 2\n 3 episode        0.0125   0.00439      2.85   5.05e- 3\n 4 total_votes    0.000372 0.0000390    9.55   1.25e-16\n 5 lines_jim      0.653    0.679        0.962  3.38e- 1\n 6 lines_pam      0.0329   0.696        0.0473 9.62e- 1\n 7 lines_michael  0.111    0.544        0.204  8.39e- 1\n 8 lines_dwight   0.806    0.522        1.54   1.25e- 1\n 9 halloween_X1  -0.00340  0.181       -0.0188 9.85e- 1\n10 valentine_X1  -0.0573   0.180       -0.318  7.51e- 1\n11 christmas_X1   0.285    0.129        2.22   2.82e- 2\n12 michael_X1     0.585    0.141        4.15   6.01e- 5\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\nset.seed(345)\nfolds <- vfold_cv(office_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 √ó 2\n  splits           id   \n  <list>           <chr>\n1 <split [111/28]> Fold1\n2 <split [111/28]> Fold2\n3 <split [111/28]> Fold3\n4 <split [111/28]> Fold4\n5 <split [112/27]> Fold5\n\nset.seed(456)\noffice_fit_rs <- office_wflow %>%\n  fit_resamples(folds)\n\ncollect_metrics(office_fit_rs)\n\n# A tibble: 2 √ó 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.367     5  0.0512 Preprocessor1_Model1\n2 rsq     standard   0.543     5  0.0386 Preprocessor1_Model1\n\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\noffice_test_pred <- predict(office_fit, new_data = office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, episode_name))\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 √ó 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.401\n\n\n\n\nOld model\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n# A tibble: 12 √ó 5\n   term                estimate std.error statistic  p.value\n   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)         7.20     0.188        38.4   9.92e-72\n 2 season             -0.0501   0.0140       -3.57  5.04e- 4\n 3 episode             0.0449   0.00877       5.11  1.13e- 6\n 4 total_votes         0.000360 0.0000404     8.89  4.99e-15\n 5 air_date_month_Feb -0.145    0.139        -1.04  2.99e- 1\n 6 air_date_month_Mar -0.376    0.134        -2.81  5.69e- 3\n 7 air_date_month_Apr -0.309    0.131        -2.36  1.96e- 2\n 8 air_date_month_May -0.128    0.162        -0.791 4.30e- 1\n 9 air_date_month_Sep  0.512    0.178         2.88  4.63e- 3\n10 air_date_month_Oct  0.270    0.139         1.95  5.38e- 2\n11 air_date_month_Nov  0.116    0.126         0.924 3.57e- 1\n12 air_date_month_Dec  0.407    0.165         2.47  1.49e- 2\n\noffice_test_pred_old <- predict(office_fit_old, new_data = office_test) %>%\n  bind_cols(office_test %>% select(imdb_rating, episode_name))\n\nrmse(office_test_pred_old, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 √ó 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.403"
  },
  {
    "objectID": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.html",
    "href": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.html",
    "title": "The Office",
    "section": "",
    "text": "Use theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16‚Ä¶\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",‚Ä¶\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis‚Ä¶\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky‚Ä¶\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha‚Ä¶\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How ‚Ä¶\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6‚Ä¶\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,‚Ä¶\n$ air_date         <fct> 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-‚Ä¶\n\n\nFix air_date for later use.\n\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don‚Äôt match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %>%\n  distinct(season, episode)\n\n# A tibble: 186 √ó 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# ‚Ä¶ with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\n\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine‚Äôs Day, and Christmas.\n\n\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you‚Äôve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\n\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\n\n\n\nExercise 5 - Specify a linear regression model.\n\n\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, uses season as a factor, and removes all zero variance predictors.\n\n\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\n\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\n#set.seed(345)\n#folds <- vfold_cv(___, v = ___)\n#folds\n#\n#set.seed(456)\n#office_fit_rs <- ___ %>%\n#  ___(___)\n#\n#___(office_fit_rs)\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\n\n\n\n\nOld model\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n___\n\nError: <text>:22:2: unexpected input\n21: \n22: __\n     ^"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#introduction",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data-analysis-plan",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html#plot-and-text",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[\n\n\n\n\n\n]"
  },
  {
    "objectID": "course-materials/project-instructions/project.html#data",
    "href": "course-materials/project-instructions/project.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset‚Äôs variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven‚Äôt encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nBelow are a list of data repositories that might be of interest to browse. You‚Äôre not limited to these resources, and in fact you‚Äôre encouraged to venture beyond them. But you might find something interesting there:\n\nTidyTuesday\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland‚Äôs official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we‚Äôll add here‚Ä¶"
  },
  {
    "objectID": "course-materials/project-instructions/project.html#deliverables",
    "href": "course-materials/project-instructions/project.html#deliverables",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal - due [ENTER DUE DATE]\nPresentation - due [ENTER DUE DATE]\nExecutive summary - due [ENTER DUE DATE]\n\n\nProposal\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset.\n\nSection 1 - Introduction: The introduction should introduce your general\nresearch question and your data (where it came from, how it was collected,\nwhat are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nThe outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)\nThe method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n3 pts\n\n\nProposal\n5 pts\n\n\nWorkflow, organization, code quality\n1 pt\n\n\nTeamwork\n1 pt\n\n\n\n\n\nPresentation\n5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop.\nPrepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn‚Äôt a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (‚Äúthen we did this, then we did this, etc.‚Äù), instead it should convey what choices you made, and why, and what you found.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\nPresentations will take place during the last workshop of the semester. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly.\nThe grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n50 pts\n\n\n\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use appropriate statistical procedures and interpretations of results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n10 pts\n\n\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n10 pts\n\n\n\n\n\nExecutive summary\nAlong with your presentation slides, we want you to provide a brief summary of your project in the README of your repository.\nThis executive summary should provide information on the dataset you‚Äôre using, your research question(s), your methodology, and your findings.\nThe executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it‚Äôs concise but detailed enough.\n\n\nRepo organization\nThe following folders and files in your project repository:\n\npresentation.Rmd + presentation.html: Your presentation slides\nREADME.Rmd + README.md: Your write-up\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#tips",
    "href": "course-materials/project-instructions/project.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou‚Äôre working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that‚Äôs fine Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nSet aside time to work together and apart (physically).\nWhen you‚Äôre done, review the documents on GitHub to make sure you‚Äôre happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you‚Äôre welcomed to show that portion.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#marking",
    "href": "course-materials/project-instructions/project.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal\n10 pts\n\n\nPresentation\n50 pts\n\n\nExecutive summary\n15 pts\n\n\nReproducibility and organization\n10 pts\n\n\nTeam peer evaluation\n10 pts\n\n\nClassmates‚Äô evaluation\n5 pts\n\n\n\n\nCriteria\nYour project will be assessed on the following criteria:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations.\nThe late work policy for the write-up is 5% of the maximum obtainable mark per calendar day up to seven calendar days after the deadline. If you intend to submit work late for the project, you must notify the course organizer before the original deadline as well as as soon as the completed work is submitted on GitHub."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html",
    "title": "HW 03 - Road traffic accidents",
    "section": "",
    "text": "Photo by Clark Van Der Beken on Unsplash\nIn this assignment we‚Äôll look at traffic accidents in Edinburgh. The data are made available online by the UK Government. It covers all recorded accidents in Edinburgh in 2018 and some of the variables were modified for the purposes of this assignment."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#warm-up",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#warm-up",
    "title": "HW 03 - Road traffic accidents",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#packages",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#packages",
    "title": "HW 03 - Road traffic accidents",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#data",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#data",
    "title": "HW 03 - Road traffic accidents",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it‚Äôs called accidents. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?accidents in the Console or using the Help menu in RStudio to search for accidents. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "Photo by Marleena Garris on Unsplash\nThe first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story ‚ÄúThe Economic Guide To Picking A College Major‚Äù.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don‚Äôt tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#warm-up",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#warm-up",
    "title": "HW 04 - What should I major in?",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#packages",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#packages",
    "title": "HW 04 - What should I major in?",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the scales package for better formatting of labels on visualisations, and the data lives in the fivethirtyeight package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#data",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#data",
    "title": "HW 04 - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found in the fivethirtyeight package, and it‚Äôs called college_recent_grads. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?college_recent_grads in the Console or using the Help menu in RStudio to search for college_recent_grads. You can also find this information here.\nYou can also take a quick peek at your data frame and view its dimensions with the glimpse function.\n\nglimpse(college_recent_grads)\n\nThe college_recent_grads data frame is a trove of information. Let‚Äôs think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all we need to do is sort the data. We use the arrange function to do this, and sort it by the unemployment_rate variable. By default arrange sorts in ascending order, which is what we want here ‚Äì we‚Äôre interested in the major with the lowest unemployment rate.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate)\n\nThis gives us what we wanted, but not in an ideal form. First, the name of the major barely fits on the page. Second, some of the variables are not that useful (e.g.¬†major_code, major_category) and some we might want front and center are not easily viewed (e.g.¬†unemployment_rate).\nWe can use the select function to choose which variables to display, and in which order:\n\nNote how easily we expanded our code with adding another step to our pipeline,\nwith the pipe operator: `%>%`.\n\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate) %>%\n  select(rank, major, unemployment_rate)\n\nOk, this is looking better, but do we really need to display all those decimal places in the unemployment variable? Not really!\nWe can use the percent() function to clean up the display a bit.\n\ncollege_recent_grads %>%\n  arrange(unemployment_rate) %>%\n  select(rank, major, unemployment_rate) %>%\n  mutate(unemployment_rate = percent(unemployment_rate))"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nThe `desc` function specifies that we want `unemployment_rate` in descending order.\n\n\ncollege_recent_grads %>%\n  arrange(desc(unemployment_rate)) %>%\n  select(rank, major, unemployment_rate)\n\n\nUsing what you‚Äôve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding top_n(3) at the end of the pipeline."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW 04 - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\n\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)\n\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer ‚ÄúHow do the distributions of median income compare across major categories?‚Äù. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nWe use the ggplot() function to do this. The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the aesthetic elements of the plot.\nLet‚Äôs start simple and take a look at the distribution of all median incomes, without considering the major categories.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram()\n\nAlong with the plot, we get a message:\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nThis is telling us that we might want to reconsider the binwidth we chose for our histogram ‚Äì or more accurately, the binwidth we didn‚Äôt specify. It‚Äôs good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: ‚ÄúWhat would be a meaningful difference in median incomes?‚Äù $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\n\nWe can also calculate summary statistics for this distribution using the summarise function:\n\ncollege_recent_grads %>%\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we‚Äôve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you‚Äôll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.\n\n\ncollege_recent_grads %>%\n  group_by(major_category) %>%\n  summarise(___ = ___(median)) %>%\n  arrange(___)\n\n\nWhich major category is the least popular in this sample? To answer this question we use a new function called count, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.\n\n\ncollege_recent_grads %>%\n  count(major_category)\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "title": "HW 04 - What should I major in?",
    "section": "All STEM fields aren‚Äôt the same",
    "text": "All STEM fields aren‚Äôt the same\nOne of the sections of the FiveThirtyEight story is ‚ÄúAll STEM fields aren‚Äôt the same‚Äù. Let‚Äôs see if this is true.\nFirst, let‚Äôs create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads <- college_recent_grads %>%\n  mutate(major_type = ifelse(major_category %in% stem_categories, \"stem\", \"not stem\"))\n\nLet‚Äôs unpack this: with mutate we create a new variable called major_type, which is defined as \"stem\" if the major_category is in the vector called stem_categories we created earlier, and as \"not stem\" otherwise.\n%in% is a logical operator. Other logical operators that are commonly used are\n\n\n\nOperator\nOperation\n\n\n\n\nx < y\nless than\n\n\nx > y\ngreater than\n\n\nx <= y\nless than or equal to\n\n\nx >= y\ngreater than or equal to\n\n\nx != y\nnot equal to\n\n\nx == y\nequal to\n\n\nx %in% y\ncontains\n\n\nx | y\nor\n\n\nx & y\nand\n\n\n!x\nnot\n\n\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors‚Äô median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads %>%\n  filter(\n    major_type == \"stem\",\n    median < 36000\n  )\n\n\nWhich STEM majors have median salaries equal to or less than the median for all majors‚Äô median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW 04 - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs.¬†proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#further-exploration",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#further-exploration",
    "title": "HW 04 - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s).\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "Photo by Madeleine Kohler on Unsplash\nOnce upon a time, people travelled all over the world, and some stayed in hotels and others chose to stay in other people‚Äôs houses that they booked through Airbnb. Recent developments in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed. Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighbourhood."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#warm-up",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#warm-up",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#packages",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#packages",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#data",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#data",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it‚Äôs called edibnb. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package.\nYou can view the dataset as a spreadsheet using the View() function. Note that you should not put this function in your R Markdown document, but instead type it directly in the Console, as it pops open a new window (and the concept of popping open a window in a static document doesn‚Äôt really make sense‚Ä¶). When you run this in the console, you‚Äôll see the following data viewer window pop up.\n\nView(edibnb)\n\nYou can find out more about the dataset by inspecting its documentation, which you can access by running ?edibnb in the Console or using the Help menu in RStudio to search for edibnb. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "Photo by Jovana Askrabic on Unsplash\nThe goal of this assignment is to introduce you to R, RStudio, Git, and GitHub, which you‚Äôll be using throughout the course both to learn the data science concepts discussed in the course and to analyze real data and come to informed conclusions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#prerequisites",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#prerequisites",
    "title": "HW 01 - Pet names",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis assignment assumes that you have reviewed the lectures titled ‚ÄúMeet the toolkit: Programming‚Äù and ‚ÄúMeet the toolkit: version control and collaboration‚Äù. If you haven‚Äôt yet done so, please pause and complete the following before continuing."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#terminology",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#terminology",
    "title": "HW 01 - Pet names",
    "section": "Terminology",
    "text": "Terminology\nWe‚Äôve already thrown around a few new terms, so let‚Äôs define them before we proceed.\n\nR: Name of the programming language we will be using throughout the course.\nRStudio: An integrated development environment for R. In other words, a convenient interface for writing and running R code.\nGit: A version control system.\nGitHub: A web platform for hosting version controlled files and facilitating collaboration among users.\nRepository: A Git repository contains all of your project‚Äôs files and stores each file‚Äôs revision history. It‚Äôs common to refer to a repository as a repo.\n\nIn this course, each assignment you work on will be contained in a Git repo.\nFor individual assignments, only you will have access to the repo. For team assignments, all team members will have access to a single repo where they work collaboratively.\nAll repos associated with this course are housed in the course GitHub organization. The organization is set up such that students can only see repos they have access to, but the course staff can see all of them."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#starting-slow",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#starting-slow",
    "title": "HW 01 - Pet names",
    "section": "Starting slow",
    "text": "Starting slow\nAs the course progresses, you are encouraged to explore beyond what the assignments dictate; a willingness to experiment will make you a much better programmer! Before we get to that stage, however, you need to build some basic fluency in R. First, we will explore the fundamental building blocks of all of these tools.\nBefore you can get started with the analysis, you need to make sure you:\n\nhave a GitHub account\nare a member of the course GitHub organization\nare a member of the course RStudio Cloud space\n\nIf you failed to confirm any of these, it means you have not yet completed the prerequisites for this assignment. Please go back to Prerequisites and complete them before continuing the assignment."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "title": "HW 01 - Pet names",
    "section": "Step 1. Update the YAML",
    "text": "Step 1. Update the YAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-2-commit",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-2-commit",
    "title": "HW 01 - Pet names",
    "section": "Step 2: Commit",
    "text": "Step 2: Commit\nThen Go to the Git pane in your RStudio.\nYou should see that your Rmd (R Markdown) file and its output, your md file (Markdown), are listed there as recently changed files.\nNext, click on Diff. This will pop open a new window that shows you the difference between the last committed state of the document and its current state that includes your changes. If you‚Äôre happy with these changes, click on the checkboxes of all files in the list, and type ‚ÄúUpdate author name‚Äù in the Commit message box and hit Commit.\n\n\n\n\n\n\n\n\n\nYou don‚Äôt have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-3.-push",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-3.-push",
    "title": "HW 01 - Pet names",
    "section": "Step 3. Push",
    "text": "Step 3. Push\nNow that you have made an update and committed this change, it‚Äôs time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only). In order to push your changes to GitHub, click on Push.\n\n\n\n\n\nThis will prompt a dialogue box where you first need to enter your user name, and then your password. This might feel cumbersome. Bear with me‚Ä¶ I will teach you how to save your password so you don‚Äôt have to enter it every time. But for this one assignment you‚Äôll have to manually enter each time you push in order to gain some experience with it.\nThought exercise: Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?1"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "Photo by Viktor Kern on Unsplash\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\nSource: UCI Machine Learning Repository - Bike Sharing Dataset"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#packages",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#packages",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it‚Äôs called dcbikeshare. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?dcbikeshare in the Console or using the Help menu in RStudio to search for dcbikeshare. You can also find this information here.\nThe data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days. The original data sources are http://capitalbikeshare.com/system-data and http://www.freemeteo.com."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nRecode the season variable to be a factor with meaningful level names as outlined in the codebook, with spring as the baseline level.\nRecode the binary variables holiday and workingday to be factors with levels no (0) and yes (1), with no as the baseline level.\nRecode the yr variable to be a factor with levels 2011 and 2012, with 2011 as the baseline level.\nRecode the weathersit variable as 1 - clear, 2 - mist, 3 - light precipitation, and 4 - heavy precipitation, with clear as the baseline.\nCalculate raw temperature, feeling temperature, humidity, and windspeed as their values given in the dataset multiplied by the maximum raw values stated in the codebook for each variable. Instead of writing over the existing variables, create new ones with concise but informative names.\nCheck that the sum of casual and registered adds up to cnt for each record. Hint: One way of doing this is to create a new column that takes on the value TRUE if they add up and FALSE if not, and then checking if all values in that column are TRUEs. But this is only one way, you might come up with another.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nRecreate the following visualization, and interpret it in context of the data. Hint: You will need to use one of the variables you created above. The temperature plotted is the feeling temperature.\n\n\n\n\n\n\n\nCreate a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Modelling",
    "text": "Modelling\n\nFit a linear model predicting total daily bike rentals from daily temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\).\nFit another linear model predicting total daily bike rentals from daily feeling temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\). Is temperature or feeling temperature a better predictor of bike rentals? Explain your reasoning.\nFit a model predicting total daily bike rentals from season, year, whether the day is holiday or not, whether the day is a workingday or not, the weather category, temperature, feeling temperature, humidity, and windspeed, as well as the interaction between feeling temperature and holiday. Record adjusted \\(R^2\\) of the model.\nWrite the linear models for holidays and non-holidays. Is the slope of temperature the same or different for these two models? How about the slope for feeling temperature? Why or why not?\nInterpret the slopes of season and feeling temperature. If the slopes are different for holidays and non-holidays, make sure to interpret both. If the variable has multiple levels, make sure you interpret all of the slope coefficients associated with it.\nInterpret the intercept. If the intercept is different for holidays and non-holidays, make sure to interpret both.\nAccording to this model, assuming everything else is the same, in which season does the model predict total daily bike rentals to be highest and which to be the lowest?\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "Photo by Daniel Cheung on Unsplash\nThis week we‚Äôll do some data gymnastics to refresh and review what we learned over the past few weeks using (simulated) data from Lego sales in 2018 for a sample of customers who bought Legos in the US."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#warm-up",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#warm-up",
    "title": "HW 05 - Legos",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#packages",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#packages",
    "title": "HW 05 - Legos",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#data",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#data",
    "title": "HW 05 - Legos",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it‚Äôs called lego_sales. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?lego_sales in the Console or using the Help menu in RStudio to search for lego_sales. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html",
    "title": "HW 10 - Wrap up!",
    "section": "",
    "text": "Photo by Kari Shea on Unsplash\nIt‚Äôs almost time to wrap up the course! In this three part assignment you get to practice what we learned this week, try something new, and get creative!"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#warm-up",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#warm-up",
    "title": "HW 10 - Wrap up!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#packages",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#packages",
    "title": "HW 10 - Wrap up!",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for the first part of this assignment. For the second part you get to choose which package to use.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "title": "HW 10 - Wrap up!",
    "section": "Part 1 - Mirror, mirror on the wall, who‚Äôs the ugliest of them all?",
    "text": "Part 1 - Mirror, mirror on the wall, who‚Äôs the ugliest of them all?\nHere is a simple plot using the mpg dataset, which contains information on fuel economy of cars. We‚Äôre plotting highway miles per gallon vs.¬†city miles per gallon, coloured by whether the car is front-wheel drive, rear wheel drive, or four-wheel drive.\n\nggplot(data = mpg, aes(x = cty, y = hwy, color = drv)) +\n  geom_point()\n\n\nI realize that \"ugly\" is subjective, so we're mostly looking to see if you can figure out how to change the look of a plot using help files of functions you haven't learned before.\n\n\nMake this plot as ugly as possible by changing colours, background color, fonts, or anything else you can think of. You will probably want to play around with theme options, but you can do more. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "title": "HW 10 - Wrap up!",
    "section": "Part 2 - You gotta pick a package or two",
    "text": "Part 2 - You gotta pick a package or two\nBut really, one is enough. Pick a package from the list below, and use it to do something. If you want to use a package not on this list, that‚Äôs also ok, but it needs to be a package we haven‚Äôt used in class. If you start with a package and are struggling to get it to work, ask for help on Piazza or just move to another one.\n\n**Remember:** You *install* the package in the Console, not in the R Markdown document since you don't want to keep reinstalling it every time you knit the document.\n\nYour task is to install the package you pick. Depending on where the package comes from, how you install the package differs:\n\nIf the package is on CRAN (Comprehensive R Archive Network), you can install it with install.packages.\nIf the package is only on Github (most likely because it is still under development), you need to use the install_github function.\n\nThen, load the package. Regardless of how you installed the package you can load it with the library function.\nFinally, do something with the package. It doesn‚Äôt have to be complicated. In fact, keep it simple. The goal is for you to read and understand the package documentation to carry out a simple task.\n\n**Note:** For the output generated by some of these packages to show up properly, you might need to change the output of your R Markdown document from `github_document` to `html_document` in the YAML of your R Markdown document.\n\n\nWhich package are you using? State the name of the package, whether it was on CRAN or GitHub, and include the code for loading it. Also include a one sentence description of what the package does.Then, do something with the package and provide a brief narrative including code and output. Also comment on difficulties you had, if any, figuring out how to use the package.\n\n\nPackages on CRAN\nThese packages can be installed with:\n\ninstall.packages(\"PACKAGENAME\")\n\n\n\n\nPackage\nDescription\n\n\n\n\ncowsay\nAllows printing of character strings as messages/warnings/etc. with ASCII animals, including cats, cows, frogs, chickens, ghosts, and more\n\n\nbabynames\nUS Baby Names 1880-2015\n\n\ndragracer\nThese are data sets for the hit TV show, RuPaul‚Äôs Drag Race. Data right now include episode-level data, contestant-level data, and episode-contestant-level data\n\n\ndatapasta\nRStudio addins and R functions that make copy-pasting vectors and tables to text painless\n\n\nDiagrammeR\nGraph/Network Visualization\n\n\njaneaustenr\nFull texts for Jane Austen‚Äôs 6 completed novels, ready for text analysis. These novels are ‚ÄúSense and Sensibility‚Äù, ‚ÄúPride and Prejudice‚Äù, ‚ÄúMansfield Park‚Äù, ‚ÄúEmma‚Äù, ‚ÄúNorthanger Abbey‚Äù, and ‚ÄúPersuasion‚Äù\n\n\nggimage\nSupports image files and graphic objects to be visualized in ‚Äòggplot2‚Äô graphic system\n\n\ngganimate\nCreate easy animations with ggplot2\n\n\ngt\nEasily Create Presentation-Ready Display Tables\n\n\nleaflet\nCreate Interactive Web Maps with the JavaScript ‚ÄòLeaflet‚Äô Library\n\n\npraise\nBuild friendly R packages that praise their users if they have done something good, or they just need it to feel better\n\n\nplotly\nCreate interactive web graphics from ggplot2 graphs and/or a custom interface to the JavaScript library plotly.js inspired by the grammar of graphics\n\n\nsuncalc\nR interface to suncalc.js library, part of the SunCalc.net project, for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), moon position and lunar phase for the given location and time\n\n\nschrute\nThe complete scripts from the American version of the Office television show in tibble format\n\n\nstatebins\nThe cartogram heatmaps generated by the included methods are an alternative to choropleth maps for the United States and are based on work by the Washington Post graphics department in their report on ‚ÄúThe states most threatened by trade‚Äù\n\n\nttbbeer\nAn R data package of beer statistics from U.S. Department of the Treasury, Alcohol and Tobacco Tax and Trade Bureau (TTB)\n\n\nukbabynames\nFull listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994\n\n\n\n\n\nPackages on GitHub only\nThese packages can be installed with:\n\nlibrary(devtools)\ninstall_github(\"USERNAME/PACKAGENAME\")\n\nUSERNAME refers to the user name of the developer of the package. For example, for the first package listed below, USERNAME is hadley and PACKAGENAME is emo.\n\n\n\nPackage\nDescription\n\n\n\n\nbingo\nGenerate Bingo cards\n\n\nBRRR\nBRRR extends the beepr package to include a number of rap adlibs\n\n\nCatterPlots\nPlots with Cats\n\n\ncooking\nChopping, peeling, frying, and cooking various ingredients, and combining them to a delicious ragout. Also includes buying them from a local supermarket\n\n\ndadjoke\nThe goal of dadjoke is to make you laugh in spite of yourself\n\n\nemo\nThe goal of emo(ji) is to make it very easy to insert emoji into RMarkdown documents\n\n\nemoGG\nUse Emoji in ggplot2\n\n\nemokid\nFor those times when you‚Äôre having trouble expressing how you feel about your broken code\n\n\nflametree\nThe goal of flametree is to make pretty pictures\n\n\nggbarf\nMake isotype bars using the vomit emoji\n\n\nggCyberPunk\nCreate Cyberpunk area and line plots\n\n\nggiraph\nCreate interactive ggplot2 graphics using htmlwidgets\n\n\nggkeyboard\nPlot a Keyboard Using ggplot2\n\n\njasmines\nMake generative art\n\n\nkandinsky\nTurn any dataset into a Kandinsky painting\n\n\nlego\nThis R data package contains information about every Lego set manufactured from 1970 to 2015, a total of 6172 sets\n\n\nlinkinpark\nData package that contains a few different datasets about the band\n\n\nprenoms\nFirst names given to babies in metropolitan France between 1900 and 2015\n\n\nraybonsai\nGenerate 3D procedural trees in R, rendered with rayrender! Procedural generation code based on the flametree package by Danielle Navarro.\n\n\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "Photo Mauro Mora on Unsplash\nIn this assignment we continue our exploration of the 2016 GSS dataset from the previous homework."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#warm-up",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#warm-up",
    "title": "HW 09 - Modeling the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#packages",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#packages",
    "title": "HW 09 - Modeling the GSS",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#data",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#data",
    "title": "HW 09 - Modeling the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it‚Äôs called gss16. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#scientific-research",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#scientific-research",
    "title": "HW 09 - Modeling the GSS",
    "section": "Scientific research",
    "text": "Scientific research\nIn this section we‚Äôre going to build a model to predict whether someone agrees or doesn‚Äôt agree with the following statement:\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nThe responses to the question on the GSS about this statement are in the advfront variable.\n\nIt's important that you don't recode the NAs, just the remaining levels.\n\n\nRe-level the advfront variable such that it has two levels: Strongly agree and ‚ÄúAgree\" combined into a new level called agree and the remaining levels (except NAs) combined into‚ÄùNot agree\". Then, re-order the levels in the following order: \"Agree\" and \"Not agree\". Finally, count() how many times each new level appears in the advfront variable.\n\n\nYou can do this in various ways. One option is to use the `str_detect()` function to detect the existence of words like liberal or conservative. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the `str_detect()` function, you can use \"[Ll]iberal\" and \"[Cc]onservative\". But feel free to solve the problem however you like, this is just one option!\n\n\nCombine the levels of the polviews variable such that levels that have the word ‚Äúliberal‚Äù in them are lumped into a level called \"Liberal\" and those that have the word conservative in them are lumped into a level called \"Conservative\". Then, re-order the levels in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame. Sample code is provided below.\n\n\ngss16_advfront <- gss16 %>%\n  select(___, ___, ___, ___) %>%\n  drop_na()\n\n\nSplit the data into training (75%) and testing (25%) data sets. Make sure to set a seed before you do the initial_split(). Call the training data gss16_train and the testing data gss16_test. Sample code is provided below. Use these specific names to make it easier to follow the rest of the instructions.\n\n\nset.seed(___)\ngss16_split <- initial_split(gss16_advfront)\ngss16_train <- training(gss16_split)\ngss16_test  <- testing(gss16_split)\n\n\nCreate a recipe with the following steps for predicting advfront from polviews, wrkstat, and educ. Name this recipe gss16_rec_1. (We‚Äôll create one more recipe later, that‚Äôs why we‚Äôre naming this recipe _1.) Sample code is provided below.\n\nstep_other() to pool values that occur less than 10% of the time (threshold = 0.10) in the wrkstat variable into \"Other\".\nstep_dummy() to create dummy variables for all_nominal() variables that are predictors, i.e.¬†all_predictors()\n\n\n\ngss16_rec_1 <- recipe(___ ~ ___, data = ___) %>%\n  step_other(wrkstat, threshold = ___, other = \"Other\") %>%\n  step_dummy(all_nominal(), -all_outcomes())\n\n\nSpecify a logistic regression model using \"glm\" as the engine. Name this specification gss16_spec. Sample code is provided below.\n\n\ngss16_spec <- ___() %>%\n  set_engine(\"___\")\n\n\nBuild a workflow that uses the recipe you defined (gss16_rec) and the model you specified (gss16_spec). Name this workflow gss16_wflow_1. Sample code is provided below.\n\n\ngss16_wflow_1 <- workflow() %>%\n  add_model(___) %>%\n  add_recipe(___)\n\n\nPerform 5-fold cross validation. specifically,\n\nsplit the training data into 5 folds (don‚Äôt forget to set a seed first!),\napply the workflow you defined earlier to the folds with fit_resamples(), and\ncollect_metrics() and comment on the consistency of metrics across folds (you can get the area under the ROC curve and the accuracy for each fold by setting summarize = FALSE in collect_metrics())\nreport the average area under the ROC curve and the accuracy for all cross validation folds collect_metrics()\n\n\n\nset.seed(___)\ngss16_folds <- vfold_cv(___, v = ___)\n\ngss16_fit_rs_1 <- gss16_wflow_1 %>%\n  fit_resamples(___)\n\ncollect_metrics(___, summarize = FALSE)\ncollect_metrics(___)\n\n\nNow, try a different, simpler model: predict advfront from only polviews and educ. Specifically,\n\nupdate the recipe to reflect this simpler model specification (and name it gss16_rec_2),\nredefine the workflow with the new recipe (and name this new workflow gss16_wflow_2),\nperform cross validation, and\nreport the average area under the ROC curve and the accuracy for all cross validation folds collect_metrics().\n\nComment on which model performs better (one including wrkstat, model 1, or the one excluding wrkstat, model 2) on the training data based on area under the ROC curve.\nFit both models to the testing data, plot the ROC curves for the predictions for both models, and calculate the areas under the ROC curve. Does your answer to the previous exercise hold for the testing data as well? Explain your reasoning. Note: If you haven‚Äôt yet done so, you‚Äôll need to first train your workflows on the training data with the following, and then use these fit objects to calculate predictions for the test data.\n\n\ngss16_fit_1 <- gss16_wflow_1 %>%\n  fit(gss16_train)\n\ngss16_fit_2 <- gss16_wflow_2 %>%\n  fit(gss16_train)\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#harassment-at-work",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#harassment-at-work",
    "title": "HW 09 - Modeling the GSS",
    "section": "Harassment at work",
    "text": "Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nCreate a subset of the data that only contains Yes and No answers for the harassment question. How many responses chose each of these answers?\nDescribe how bootstrapping can be used to estimate the proportion of Americans who have been harassed by their superiors or co-workers at their job.\nCalculate a 95% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Interpret this interval in context of the data.\nWould you expect a 90% confidence interval to be wider or narrower than the interval you calculated above? Explain your reasoning.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "Photo by Mauro Mora on Unsplash\nThe GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes. Hundreds of trends have been tracked since 1972. In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.\nThe GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.\nIn this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.1"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#warm-up",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#warm-up",
    "title": "HW 08 - Exploring the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#packages",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#packages",
    "title": "HW 08 - Exploring the GSS",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#data",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#data",
    "title": "HW 08 - Exploring the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it‚Äôs called gss16. Since the dataset is distributed with the package, we don‚Äôt need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 1: Harassment at work",
    "text": "Part 1: Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nWhat are the possible responses to this question and how many respondents chose each of these answers?\nWhat percent of the respondents for whom this question is applicable\n(i.e.¬†excluding NAs and Does not applys) have been harassed by their superiors or co-workers at their job.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 2: Time spent on email",
    "text": "Part 2: Time spent on email\nThe 2016 GSS also asked respondents how many hours and minutes they spend on email weekly. The responses to these questions are recorded in the emailhr and emailmin variables. For example, if the response is 2.5 hrs, this would be recorded as emailhr = 2 and emailmin = 30.\n\nCreate a new variable called email that combines these two variables to reports the number of minutes the respondents spend on email weekly.\nVisualize the distribution of this new variable. Find the mean and the median number of minutes respondents spend on email weekly. Is the mean or the median a better measure of the typical among of time Americans spend on email weekly? Why?\nCreate another new variable, snap_insta that is coded as ‚ÄúYes‚Äù if the respondent reported using any of Snapchat (snapchat) or Instagram (instagrm), and ‚ÄúNo‚Äù if not. If the recorded value was NA for both of these questions, the value in your new variable should also be NA.\nCalculate the percentage of Yes‚Äôs for snap_insta among those who answered the question, i.e.¬†excluding NAs.\nWhat are the possible responses to the question Last week were you working full time, part time, going to school, keeping house, or what? and how many respondents chose each of these answers? Note that this information is stored in the wrkstat variable.\nFit a model predicting email (number of minutes per week spent on email) from educ (number of years of education), wrkstat, and snap_insta. Interpret the slopes for each of these variables.\nCreate a predicted values vs.¬†residuals plot for this model. Are there any issues with the model? If yes, describe them.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 3: Political views and science research",
    "text": "Part 3: Political views and science research\nThe 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (polviews) and whether they think science research is necessary and should be supported by the federal government (advfront).\n\nThe question on science research is worded as follows:\n\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nAnd possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don‚Äôt know, No answer, Not applicable.\n\nThe question on political views is worded as follows:\n\n\nWe hear a lot of talk these days about liberals and conservatives. I‚Äôm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal‚Äìpoint 1‚Äìto extremely conservative‚Äìpoint 7. Where would you place yourself on this scale?\n\n\n**Note:** The levels of this variables are spelled inconsistently: \"Extremely liberal\" vs. \"Extrmly conservative\". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.\n\nAnd possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative. Responses that were originally Don‚Äôt know, No answer and Not applicable are already mapped to NAs upon data import.\n\nIn a new variable, recode advfront such that Strongly Agree and Agree are mapped to \"Yes\", and Disagree and Strongly disagree are mapped to \"No\". The remaining levels can be left as is. Don‚Äôt overwrite the existing advfront, instead pick a different, informative name for your new variable.\nIn a new variable, recode polviews such that Extremely liberal, Liberal, and Slightly liberal, are mapped to \"Liberal\", and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to \"Conservative\". The remaining levels can be left as is. Make sure that the levels are in a reasonable order. Don‚Äôt overwrite the existing polviews, instead pick a different, informative name for your new variable.\nCreate a visualization that displays the relationship between these two new variables and interpret it.\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html",
    "title": "HW 06 - Money in US politics",
    "section": "",
    "text": "Photo by Sharon McCutcheon on Unsplash\nEvery election cycle brings its own brand of excitement ‚Äì and lots of money. Political donations are of particular interest to political scientists and other researchers studying politics and voting patterns. They are also of interest to citizens who want to stay informed of how much money their candidates raise and where that money comes from.\nIn the United States, ‚Äúonly American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees.‚Äù1\nIn this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns. First, we will get data foreign connected PAC contributions in the 2022 election cycle. Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.\nIn order to complete this assignment you will need a Chrome browser with the Selector Gadget extension installed."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#warm-up",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#warm-up",
    "title": "HW 06 - Money in US politics",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let‚Äôs warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#packages",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#packages",
    "title": "HW 06 - Money in US politics",
    "section": "Packages",
    "text": "Packages\nWe‚Äôll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we‚Äôre allowed to scrape the data, the rvest package for data scraping, and the scales package for better formatting of labels on visualisations. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(robotstxt)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data",
    "title": "HW 06 - Money in US politics",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you‚Äôll be scraping the data!"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "title": "HW 06 - Money in US politics",
    "section": "Data collection via web scraping",
    "text": "Data collection via web scraping\n\n\n\n\n\nThe data come from OpenSecrets.org, a ‚Äúwebsite tracking the influence of money on U.S. politics, and how that money affects policy and citizens‚Äô lives‚Äù. This website is hosted by The Center for Responsive Politics, which is a nonpartisan, independent nonprofit that ‚Äútracks money in U.S. politics and its effect on elections and public policy.‚Äù2\nBefore getting started, let‚Äôs check that a bot has permissions to access pages on this domain.\n\nlibrary(robotstxt)\npaths_allowed(\"https://www.opensecrets.org\")\n\n[1] TRUE\n\n\nOur goal is to scrape data for contributions in all election years Open Secrets has data for. Since that means repeating a task many times, let‚Äôs first write a function that works on the first page. Confirm it works on a few others. Then iterate it over pages for all years.\n\nComplete the following set of steps in the scrape-pac.R file in the scripts folder of your repository. This file already contains some starter code to help you out.\n\n\nWrite a function called scrape_pac() that scrapes information from the Open Secrets webpage for foreign-connected PAC contributions in a given year. This function should\n\nhave one input: the URL of the webpage and should return a data frame.\nrename variables scraped, using snake_case naming.\nclean up the Country of Origin/Parent Company variable with str_squish().\nadd a new column to the data frame for year. We will want this information when we ultimately have data from all years, so this is a good time to keep track of it. Our function doesn‚Äôt take a year argument, but the year is embedded in the URL, so we can extract it out of there, and add it as a new column. Use the str_sub() function to extract the last 4 characters from the URL. You will probably want to look at the help for this function to figure out how to specify ‚Äúlast 4 characters‚Äù.\n\nDefine the URLs for 2022, 2020, and 2000 contributions. Then, test your function using these URLs as inputs. Does the function seem to do what you expected it to do?\nConstruct a vector called urls that contains the URLs for each webpage that contains information on foreign-connected PAC contributions for a given year.\nMap the scrape_pac() function over urls in a way that will result in a data frame called pac_all.\nWrite the data frame to a csv file called pac-all.csv in the data folder.\n\n‚úÖ‚¨ÜÔ∏è If you haven‚Äôt yet done so, now is definitely a good time to commit and push your changes to GitHub with an appropriate commit message (e.g.¬†‚ÄúData scraping complete‚Äù). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nComplete the following set of steps in the hw-06.Rmd file in your repository.\n\n\nIn your R Markdown file, load pac-all.csv and report its number of observations and variables using inline code."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "title": "HW 06 - Money in US politics",
    "section": "Data cleaning",
    "text": "Data cleaning\nIn this section we clean the pac_all data frame to prepare it for analysis and visualization. We have two goals in data cleaning:\n\nSeparate the country_parent into two such that country and parent company appear in different columns for country-level analysis.\nConvert contribution amounts in total, dems, and repubs from character strings to numeric values.\n\nThe following exercises walk you through how to make these fixes to the data.\n\nUse the separate() function to separate country_parent into country and parent columns. Note that country and parent company names are separated by \\ (which will need to be specified in your function) and also note that there are some entries where the \\ sign appears twice and in these cases we want to only split the value at the first occurrence of \\. This can be accomplished by setting the extra argument in to \"merge\" so that the cell is split into only 2 segments, e.g.¬†we want \"Denmark/Novo Nordisk A/S\" to be split into \"Denmark\" and \"Novo Nordisk A/S\". (See help for separate() for more on this.) End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you).\nRemove the character strings including $ and , signs in the total, dems,and repubs columns and convert these columns to numeric. End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you). A couple hints to help you out:\n\nThe $ character is a special character so it will need to be escaped.\nSome contribution amounts are in the millions (e.g.¬†Anheuser-Busch contributed a total of $1,510,897 in 2008). In this case we need to remove all occurrences of ,, which we can do by using str_remove_all() instead of str_remove().\n\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Now is a good time to knit your document, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "title": "HW 06 - Money in US politics",
    "section": "Data visualization and interpretation",
    "text": "Data visualization and interpretation\n\nCreate a line plot of total contributions from all foreign-connected PACs in the Canada and Mexico over the years. Once you have made the plot, write a brief interpretation of what the graph reveals. Few hints to help you out:\n\nFilter for only Canada and Mexico.\nCalculate sum of total contributions from PACs for each year for each country by using a sequence of group_by() then summarise().\nMake a plot of total contributions (y-axis) by year (x-axis) where two lines identified by different colours represent each of Canada and Mexico.\n\n\n\n**Note:** The figure you create might look slightly different than this one if the data on the website has been updated recently.\n\n\nRecreate the following visualisation. Once you have made the plot, write a brief interpretation of what the graph reveals. Note that these are only UK contributions. You will need to make use of functions from the scales package for axis labels as well as from ggplot2.\n\n\n\n\n\n\nüß∂ ‚úÖ ‚¨ÜÔ∏è Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you‚Äôre happy with the final state of your work."
  },
  {
    "objectID": "course-materials/starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "href": "course-materials/starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 2",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n‚Ä¶\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "href": "course-materials/starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html",
    "href": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "library(tidyverse) \n\n\nnobel <- read_csv(\"data/nobel.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "href": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "title": "Lab 03 - Nobel laureates",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶"
  },
  {
    "objectID": "course-materials/starters/lab/lab-07-simpsons-paradox/lab-07.html",
    "href": "course-materials/starters/lab/lab-07-simpsons-paradox/lab-07.html",
    "title": "Lab 07 - Simpson‚Äôs paradox",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-06-sad-plots/lab-06.html",
    "href": "course-materials/starters/lab/lab-06-sad-plots/lab-06.html",
    "title": "Lab 06 - Sad plots",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-10-slr-course-evals/lab-10.html",
    "href": "course-materials/starters/lab/lab-10-slr-course-evals/lab-10.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html",
    "title": "Lab 01 - Hello R",
    "section": "",
    "text": "library(tidyverse) \nlibrary(datasauRus)\nlibrary(usethis)"
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "title": "Lab 01 - Hello R",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nThe answers for this Exercise are given for you below. But you should clean up some of the narrative so that it only includes what you want to turn in.\nFirst let‚Äôs plot the data in the dino dataset:\n\ndino_data <- datasaurus_dozen %>%\n  filter(dataset == \"dino\")\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\nAnd next calculate the correlation between x and y in this dataset:\n\ndino_data %>%\n  summarize(r = cor(x, y))\n\n# A tibble: 1 √ó 1\n        r\n    <dbl>\n1 -0.0645\n\n\n\n\nExercise 3\nAdd code and narrative as needed. Note that the R chunks are labelled with plot-star and cor-star to provide spaces to place the code for plotting and calculating the correlation coefficient. To finish, clean up the narrative by removing these instructions.\nBlah blah blah‚Ä¶\n\n\n\nI‚Äôm some text, you should replace me with more meaningful text‚Ä¶\n\n\n\n\n\nExercise 4\nAdd code and narrative as needed. Note that two R chunks are given but they are not labeled. Use the convention from above to name them appropriately.\n\n\n\n\n\n\n\n\nExercise 5\nAdd code and narrative as needed. To add R chunks either type out the backticks, curly braces, and the letter r or use the Insert chunk button above, green C+."
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html",
    "title": "Lab 02 - Plastic waste",
    "section": "",
    "text": "library(tidyverse) \n\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "title": "Lab 02 - Plastic waste",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n# insert code here\n\n\n\nExercise 2\n\n# insert code here\n\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# insert code here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# insert code here\n\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here.\n\n# insert code here\n\n\n\nExercise 7\nRemove this text, and add your answer for Exercise 7 here.\n\n# insert code here\n\n\n# insert code here\n\n\n\nExercise 8\nRemove this text, and add your answer for Exercise 8 here.\n\n# insert code here"
  },
  {
    "objectID": "course-materials/starters/lab/lab-04-viz-sp-data/lab-04.html",
    "href": "course-materials/starters/lab/lab-04-viz-sp-data/lab-04.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny‚Äôs, Pt. 1",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n‚Ä¶\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-12-inference-smoking/lab-12.html",
    "href": "course-materials/starters/lab/lab-12-inference-smoking/lab-12.html",
    "title": "Lab 12 - Smoking during pregnancy",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-09-better-viz/lab-09.html",
    "href": "course-materials/starters/lab/lab-09-better-viz/lab-09.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "Exercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-08-uoe-art/lab-08.html",
    "href": "course-materials/starters/lab/lab-08-uoe-art/lab-08.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "Exercise 9\n\nuoe_art <- uoe_art %>%\n  separate(title, into = c(\"title\", \"date\"), sep = \"\\\\(\") %>%\n  mutate(year = str_remove(date, \"\\\\)\") %>% as.numeric()) %>%\n  select(title, artist, year, ___)\n\nError: <text>:4:32: unexpected input\n3:   mutate(year = str_remove(date, \"\\\\)\") %>% as.numeric()) %>%\n4:   select(title, artist, year, __\n                                  ^\n\n\n\n\nExercise 10\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 11\n‚Ä¶\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html",
    "href": "course-materials/starters/project/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#introduction",
    "href": "course-materials/starters/project/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#data",
    "href": "course-materials/starters/project/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#data-analysis-plan",
    "href": "course-materials/starters/project/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html",
    "href": "course-materials/starters/project/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "course-materials/starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html#plot-and-text",
    "href": "course-materials/starters/project/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[\n\n\n\n\n\n]"
  },
  {
    "objectID": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html",
    "href": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html#exercises",
    "href": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html#exercises",
    "title": "HW 09 - Modeling the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\n\n\nExercise 7\n‚Ä¶\n\n\nExercise 8\n‚Ä¶\n\n\nExercise 9\n‚Ä¶\n\n\nExercise 10\n‚Ä¶\n\n\nExercise 11\n‚Ä¶\n\n\nExercise 12\n‚Ä¶\n\n\nExercise 13\n‚Ä¶\n\n\nExercise 14\n‚Ä¶\n\n\nExercise 15\n‚Ä¶"
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html",
    "title": "HW 06 - Money in politics",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "title": "HW 06 - Money in politics",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "title": "HW 08 - Exploring the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\n\n\nExercise 7\n‚Ä¶\n\n\nExercise 8\n‚Ä¶\n\n\nExercise 9\n‚Ä¶\n\n\nExercise 10\n‚Ä¶\n\n\nExercise 11\n‚Ä¶\n\n\nExercise 12\n‚Ä¶"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# remove this comment and add the code for Exercise 5 here"
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "title": "HW 04 - What should I major in?",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\n\n\nExercise 7\n‚Ä¶\n\n\nExercise 8\n‚Ä¶\n\n\nExercise 9\n‚Ä¶\n\n\nExercise 10\n‚Ä¶"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html#exercises",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html#exercises",
    "title": "HW 05 - Legos",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\n\n\nExercise 7\n‚Ä¶\n\n\nExercise 8\n‚Ä¶\n\n\nExercise 9\n‚Ä¶"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html",
    "title": "HW 10 - Wrap up",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "title": "HW 10 - Wrap up",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels."
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "title": "HW 01 - Pet names",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nThere are ___ pets in the dataset.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\nseattlepets %>%\n  count(animal_name, sort = TRUE)\n\n# A tibble: 13,930 √ó 2\n   animal_name     n\n   <chr>       <int>\n 1 <NA>          483\n 2 Lucy          439\n 3 Charlie       387\n 4 Luna          355\n 5 Bella         331\n 6 Max           270\n 7 Daisy         261\n 8 Molly         240\n 9 Jack          232\n10 Lily          232\n# ‚Ä¶ with 13,920 more rows\n\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here."
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html",
    "href": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html",
    "title": "HW 02 - Road traffic accidents",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html#exercises",
    "href": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html#exercises",
    "title": "HW 02 - Road traffic accidents",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here"
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don‚Äôt forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n‚Ä¶\n\n\nExercise 5\n‚Ä¶\n\n\nExercise 6\n‚Ä¶\n\n\nExercise 7\n‚Ä¶\n\n\nExercise 8\n‚Ä¶\n\n\nExercise 9\n‚Ä¶\n\n\nExercise 10\n‚Ä¶\n\n\nExercise 11\n‚Ä¶\n\n\nExercise 12\n‚Ä¶\n\n\nExercise 13\n‚Ä¶\n\n\nExercise 14\n‚Ä¶\n\n\nExercise 15\n‚Ä¶"
  },
  {
    "objectID": "computing-troubleshooting_depr.html",
    "href": "computing-troubleshooting_depr.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it‚Äôs been resolved. If there‚Äôs a deadline coming up soon, post on the course forum to let us know that there‚Äôs an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don‚Äôt anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you‚Äôve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They‚Äôll be able to help diagnose the issue."
  }
]